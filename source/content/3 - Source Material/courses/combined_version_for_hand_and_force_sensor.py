# -*- coding: utf-8 -*-
"""Combined Version for Hand and Force Sensor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CBr2VrJ_E4DDDXAQUsh_ADIHlsySbTGx

## Initialization
"""

from google.colab import drive

import numpy as np
import matplotlib.pyplot as plt
import io
from scipy.interpolate import interp1d
from scipy.signal import find_peaks
from scipy.signal import stft
from scipy.integrate import trapz

import os
import pandas as pd
import math
import copy
from sklearn.preprocessing import minmax_scale

from datetime import datetime
pd.set_option('display.max_rows', None)
import warnings
warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)

drive.mount('/content/drive', force_remount=True)

dir = '/content/drive/My Drive/Bionics Lab Research/Grace/'

testnames = ["Massfingerflexion", "Massfingerextension", "Hookgrasp", "Thumbadduction",  "Pincergrasp", "Cylindricalgrasp", "Sphericalgrasp"]
testnames_alt = ['MassFlexion', 'MassExtension', 'HookGrasp', 'ThumbAdduction', 'PencilGrasp', 'CylinderGrasp', 'SphericalGrasp']
hands = ['Left', 'Right']
axes = ['x', 'y', 'z']
fingers = ['Index01', 'Index02','Thumb01']

jump_threshold = 10
ratio_jump_threshold = 0.005
degree_cols = [finger + axis for finger in fingers for axis in axes]
nonredundant_degree_cols = ['Index01y', 'Index01z', 'Index02z', 'Thumb01x', 'Thumb01y', 'Thumb01z']
force_cols = [' hook', ' paper', ' pencilThumb',' pencilFinger',' bottleVert', ' bottleRadial',' sphereThumb', ' sphereF_L1', ' sphereF_L2', ' sphereF_M', ' sphereF_R2', ' sphereF_R1']
dist_cols = ['Hand_pos—ThumbCMC_dist', 'Hand_pos—ThumbMCP_dist', 'Hand_pos—IndexMCP_dist', 'Hand_pos—IndexPIP_dist', 'ThumbMCP—IndexMCP_dist', 'ThumbMCP—IndexPIP_dist', 'Hand_pos—IndexPIP_dist', 'Hand_pos—IndexDIP_dist', 'ThumbMCP—IndexDIP_dist']
ratio_cols = ['Thumb_Hand_dist_ratio', 'Hand_Index1-2_dist_ratio', 'Thumb_Index1-2_dist_ratio', 'Hand_Index2-3_dist_ratio', 'Thumb_Index2-3_dist_ratio']
og_cols_for_ratio = [name + axis for name in ['Hand_pos_', 'ThumbCMC', 'ThumbMCP', 'IndexMCP', 'IndexPIP', 'IndexDIP'] for axis in axes]
og_cols = degree_cols + force_cols + og_cols_for_ratio
new_cols = dist_cols + ratio_cols
used_cols = degree_cols + force_cols + new_cols
flip_direction = {'Thumb01x': [1, -1, 1, 1, 1, 1, 1], 'Thumb01y': [-1, 1, 1, 1, -1, -1, -1], 'Thumb01z': [-1, 1, 1, -1, -1, 1, 1]}

data_path = dir + 'data/7-18-2024 new joint data/AK_score2_thumb_open (both hands)/'
test_to_force = [[], [], [force_cols[0]], [force_cols[1]], force_cols[2:4], force_cols[4:6], force_cols[6:]]

today_date = datetime.today().strftime("%-m-%-d-%Y")
colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

def sort_titles(unsorted_dict, leadtext=""):
    sorted_dict = dict(sorted(unsorted_dict.items()))
    print(leadtext)
    for key in sorted_dict.keys(): print(key)
    return sorted_dict

task_names = ["Hookgrasp", "Cylindricalgrasp", "Thumbadduction", "Sphericalgrasp",
              "Pincergrasp", "Massfingerextension", "Massfingerflexion"]

def get_task_name(title, task_names):
    for task in task_names:
        if task in title: return task
    return title

def rename_titles(file_dict, leadtext=""):
    print(leadtext)
    title_count = {}
    new_title_list = []
    for key in file_dict.keys():
        task = get_task_name(key, task_names)
        if task not in title_count:  title_count[task] = 0
        title_count[task] += 1

        if "Right" in key or "RIGHT" in key:  # Case-sensitive check for "Right"
            new_title = f"{task} R Trial {title_count[task]}"
        elif "Left" in key or "LEFT" in key:  # Case-sensitive check for "Left"
            new_title = f"{task} L Trial {title_count[task]}"
        else: new_title = f"{task} Trial {title_count[task]}"

        new_title_list.append(new_title)
    renamed_dict= dict(zip(new_title_list, file_dict.values()))
    for key in renamed_dict.keys(): print(key)
    return renamed_dict

"""### for Experiment Data
(eg. ID04, ID05)
"""

## Add "BionicsLab_Colab" as a shortcut to My Drive
## Create new folder for experiment, add shortcuts to folders with data (shortcut names should match folder paths below)

## Change the subjectID, subjectID_full and affected_hand for each experiment

subjectID = 'ID03'
subjectID_full = 'ID03R'
#ID03R
#ID04_CDML_E20240815
#ID05_MPFL_E20240820

affected_hand = 'Right'                                 # 'Left' or 'Right'

## --------------------------------------

dir2 = '/content/drive/MyDrive/BionicsLab_Colab/' + subjectID_full
if affected_hand == 'Left': unaff_hand = 'Right'
elif affected_hand == 'Right': unaff_hand = 'Left'

unaff_wh_folder_path = os.path.join(dir2, f'WH_Unaffected_{unaff_hand}Hand')
unaff_woh_folder_path = os.path.join(dir2, f'WOH_Unaffected_{unaff_hand}Hand')
aff_wh_folder_path = os.path.join(dir2, f'WH_Affected_{affected_hand}Hand')
aff_woh_folder_path = os.path.join(dir2, f'WOH_Affected_{affected_hand}Hand')

output_folder_path = os.path.join(dir2, f'{subjectID}_Figures')
force_tsi_folder_path = os.path.join(output_folder_path, 'Force Sensor TSI')
hand_tsi_folder_path = os.path.join(output_folder_path, 'Hand & Force TSI')
hand_3x4_4x3_folder_path = os.path.join(output_folder_path, 'Hand & Force - 3x4 and 4x3')
new_csv_folder_path = os.path.join(output_folder_path, 'New CSV Files')

if not os.path.exists(output_folder_path): os.makedirs(output_folder_path)
if not os.path.exists(force_tsi_folder_path): os.makedirs(force_tsi_folder_path)
if not os.path.exists(hand_tsi_folder_path): os.makedirs(hand_tsi_folder_path)
if not os.path.exists(hand_3x4_4x3_folder_path): os.makedirs(hand_3x4_4x3_folder_path)
if not os.path.exists(new_csv_folder_path): os.makedirs(new_csv_folder_path)


"""
Define 4 dictionaries (file_groups)
1. Unaffected with hand sensor (unaff_wh)
2. Unaffected without hand (unaff_woh)
3. Affected with hand sensor (aff_wh)
4. Affected without hand (aff_woh)
Sort them based on file name, and add in the file_path to the respective folders as defined above
loadExperimentData = True will trigger certain functions meant for Experiment Data (ID01, ID02 etc.)
"""

loadExperimentData = True
loadTendencyData = False

unaff_wh_files = [file for file in os.listdir(unaff_wh_folder_path) if file.endswith('.csv')]
unaff_woh_files = [file for file in os.listdir(unaff_woh_folder_path) if file.endswith('.csv')]
aff_wh_files = [file for file in os.listdir(aff_wh_folder_path) if file.endswith('.csv')]
aff_woh_files = [file for file in os.listdir(aff_woh_folder_path) if file.endswith('.csv')]

# Initialize dictionaries to store titles and file paths
unaff_wh_dict = {}
unaff_woh_dict = {}
aff_wh_dict = {}
aff_woh_dict = {}

folders = [unaff_wh_folder_path, unaff_woh_folder_path, aff_wh_folder_path, aff_woh_folder_path]
files_list = [unaff_wh_files, unaff_woh_files, aff_wh_files, aff_woh_files]
dicts = [unaff_wh_dict, unaff_woh_dict, aff_wh_dict, aff_woh_dict]

for folder, files, d in zip(folders, files_list, dicts):
  for file in files:
    file_path = os.path.join(folder, file)
    d[file] = file_path

# ------ # delete any files here if needed

unaff_wh_dict_sorted = sort_titles(unaff_wh_dict, "unaff_wh_dict_sorted")
unaff_woh_dict_sorted = sort_titles(unaff_woh_dict, "\n unaff_woh_dict_sorted")
aff_wh_dict_sorted = sort_titles(aff_wh_dict, "\n aff_wh_dict_sorted")
aff_woh_dict_sorted = sort_titles(aff_woh_dict, "\n aff_woh_dict_sorted")

#Rename the title of each trial to <task> <R/L> <Trial #>
unaff_wh_sorted = rename_titles(unaff_wh_dict_sorted, "unaff_wh_sorted")
unaff_woh_sorted = rename_titles(unaff_woh_dict_sorted, "\n unaff_woh_sorted")
aff_wh_sorted = rename_titles(aff_wh_dict_sorted, "\n aff_wh_sorted")
aff_woh_sorted = rename_titles(aff_woh_dict_sorted, "\n aff_woh_sorted")

# Initialize dictionary to group files by task
unaff_wh_task_files = {task: [] for task in task_names}
unaff_woh_task_files = {task: [] for task in task_names}
aff_wh_task_files = {task: [] for task in task_names}
aff_woh_task_files = {task: [] for task in task_names}

sorted_dicts = [unaff_wh_sorted, unaff_woh_sorted, aff_wh_sorted, aff_woh_sorted]
task_files_dicts = [unaff_wh_task_files, unaff_woh_task_files, aff_wh_task_files, aff_woh_task_files]

for d, task_files_d in zip(sorted_dicts, task_files_dicts):
  for file, file_path in d.items():
    task = get_task_name(file, task_names)
    if task: task_files_d[task].append((file, file_path))


""" Combine all file_groups into a list to loop through """
# For all file groups with hand & force sensor data
force_sets = [(unaff_wh_task_files, 'unaff_wh'),
              (unaff_woh_task_files, 'unaff_woh'),
              (aff_wh_task_files, 'aff_wh'),
              (aff_woh_task_files, 'aff_woh')]

# For all file group with hand sensor data only
hand_sets = [ (unaff_wh_task_files, 'unaff_wh'),
              (aff_wh_task_files, 'aff_wh')]

# Only for tasks with force sensor
unaff_wh_force_only = {}
unaff_woh_force_only = {}
aff_wh_force_only = {}
aff_woh_force_only = {}

force_dicts = [unaff_wh_force_only, unaff_woh_force_only, aff_wh_force_only, aff_woh_force_only]

for d, force_d in zip(sorted_dicts, force_dicts):
  for file, file_path in d.items():
    task = get_task_name(file, task_names)
    if task == "Massfingerextension" or task == "Massfingerflexion": continue
    force_d[file] = file_path

"""### for Tendency Data"""

## Add "BionicsLab_Colab" as a shortcut to My Drive
## Create new folder for tendency test, name it as subjectID_fulll
## Add shortcuts to folders with data (organized by score 0, 1, 2 and shortcut names should match folder paths below)
## Change subjectID and subjectID_full

subjectID_full = '080624_SY'
subjectID = 'SY'

# 091824_ZE
# 080624_SY
# 080524_SN
# 080524_AK
# 080424_SM new sensors after this

# SN 080524
# SN 080124
# ignore 072624 data   # this & before, no score in file_names
# 072624_SN           # ignore this and before
# 072424_AK

dir2 = '/content/drive/MyDrive/BionicsLab_Colab/' + subjectID_full

score_two_folder_path = os.path.join(dir2, f'{subjectID_full}_Score2')
score_one_folder_path = os.path.join(dir2, f'{subjectID_full}_Score1')
score_zero_folder_path = os.path.join(dir2, f'{subjectID_full}_Score0')

output_folder_path = os.path.join(dir2, f'{subjectID_full}_Figures')
force_tsi_folder_path = os.path.join(output_folder_path, 'Force Sensor TSI')
hand_tsi_folder_path = os.path.join(output_folder_path, 'Hand & Force TSI')
hand_3x4_4x3_folder_path = os.path.join(output_folder_path, 'Hand & Force - 3x4 and 4x3')
new_csv_folder_path = os.path.join(output_folder_path, 'New CSV Files')

if not os.path.exists(output_folder_path): os.makedirs(output_folder_path)
if not os.path.exists(force_tsi_folder_path): os.makedirs(force_tsi_folder_path)
if not os.path.exists(hand_tsi_folder_path): os.makedirs(hand_tsi_folder_path)
if not os.path.exists(hand_3x4_4x3_folder_path): os.makedirs(hand_3x4_4x3_folder_path)
if not os.path.exists(new_csv_folder_path): os.makedirs(new_csv_folder_path)


"""
Define 3 dictionaries (file_groups)
1. Score Two
2. Score One
3. Score Zero
Sort them based on file name, and add in the file_path to the respective folders as defined above
loadTendencyData = True will trigger certain functions meant for Tendency Data
"""

loadTendencyData = True
loadExperimentData = False

score_two_files = [file for file in os.listdir(score_two_folder_path) if file.endswith('.csv')]
score_one_files = [file for file in os.listdir(score_one_folder_path) if file.endswith('.csv')]
score_zero_files = [file for file in os.listdir(score_zero_folder_path) if file.endswith('.csv')]

score_two_dict = {}
score_one_dict = {}
score_zero_dict = {}

folders = [score_two_folder_path, score_one_folder_path, score_zero_folder_path]
files_list = [score_two_files, score_one_files, score_zero_files]
dicts = [score_two_dict, score_one_dict, score_zero_dict]

for folder, files, d in zip(folders, files_list, dicts):
  for file in files:
    file_path = os.path.join(folder, file)
    d[file] = file_path

# ------ # delete any files here if needed

score_two_dict_sorted = sort_titles(score_two_dict, "score_two_dict_sorted")
score_one_dict_sorted = sort_titles(score_one_dict, "\n score_one_dict_sorted")
score_zero_dict_sorted = sort_titles(score_zero_dict, "\n score_zero_dict_sorted")

#Rename the title of each trial to <task> <R/L> <Trial #>
score_two_sorted = rename_titles(score_two_dict_sorted, "score_two_sorted")
score_one_sorted = rename_titles(score_one_dict_sorted, "\n score_one_sorted")
score_zero_sorted = rename_titles(score_zero_dict_sorted, "\n score_zero_sorted")

# Initialize dictionary to group files by task
score_two_task_files = {task: [] for task in task_names}
score_one_task_files = {task: [] for task in task_names}
score_zero_task_files = {task: [] for task in task_names}

sorted_dicts = [score_two_sorted, score_one_sorted, score_zero_sorted]
task_files_dicts = [score_two_task_files, score_one_task_files, score_zero_task_files]

for d, task_files_d in zip(sorted_dicts, task_files_dicts):
  for file, file_path in d.items():
    task = get_task_name(file, task_names)
    if task: task_files_d[task].append((file, file_path))

""" Combine all file_groups into a list to loop through """
# For all file groups with hand & force sensor data
force_sets = [(score_two_task_files, 'score_two'),
              (score_one_task_files, 'score_one'),
              (score_zero_task_files, 'score_zero')]

# For all file group with hand sensor data only
hand_sets = [ (score_two_task_files, 'score_two'),
              (score_one_task_files, 'score_one'),
              (score_zero_task_files, 'score_zero')]

# Only for tasks with force sensor (remove Massfingerextension and Massfingerflexion)
score_two_force_only = {}
score_one_force_only = {}
score_zero_force_only = {}

force_dicts = [score_two_force_only, score_one_force_only, score_zero_force_only]

for d, force_d in zip(sorted_dicts, force_dicts):
  for file, file_path in d.items():
    task = get_task_name(file, task_names)
    if task == "Massfingerextension" or task == "Massfingerflexion": continue    # remove these 2 tasks
    force_d[file] = file_path

"""## Functions

### Helpers
"""

def get_testno(filename):
  """
  Returns 0-indexed integer for FM hand test given filename
  works for older names too (i.e. PencilGrasp vs Pincergrasp)
  """
  if testnames[0] in filename or testnames_alt[0] in filename: return 0
  elif testnames[1] in filename or testnames_alt[1] in filename: return 1
  elif testnames[2] in filename or testnames_alt[2] in filename: return 2
  elif testnames[3] in filename or testnames_alt[3] in filename: return 3
  elif testnames[4] in filename or testnames_alt[4] in filename: return 4
  elif testnames[5] in filename or testnames_alt[5] in filename: return 5
  elif testnames[6] in filename or testnames_alt[6] in filename: return 6
  else: raise Exception(f"test name not found for '{filename}'")

def get_hand(filename):
  """
  same idea as get_testno, to make sure left hand consistently first when processing
  """
  if hands[0].lower() in filename.lower(): return hands[0]
  elif hands[1].lower() in filename.lower(): return hands[1]
  else: raise Exception("hand not found")

def interpolate_to_0_2(df):
  """
  Takes input dataframe, stretches/interpolates/scales all cols to length 200
  (not 201) and Timestamp column starting at 0, ending at 2.
  """
  # make df_untrimmed 0-2:
  df['Timestamp'] = minmax_scale(df[['Timestamp']], feature_range=(0, 2))  # minmax

  # interpolate
  interp_prefft_duration = 2
  interp_prefft_step = 0.01
  #interp_prefft_time = np.linspace(0, interp_prefft_duration, num=int(interp_prefft_duration/interp_prefft_step)+1)
  interp_prefft_time = np.linspace(0, interp_prefft_duration, num=200)

  # Store interpolated columns in a dictionary first
  interpolated_cols = {'Timestamp': interp_prefft_time}

  for col in df.columns:
      if col != 'Timestamp':
          interpolated_cols[col] = np.interp(interp_prefft_time, df['Timestamp'], df[col])

  # Concatenate all columns at once to avoid fragmentation
  interp_df = pd.concat([pd.DataFrame({k: v}) for k, v in interpolated_cols.items()], axis=1)
  #print(len(interp_df))
  return interp_df

from colorsys import hls_to_rgb
def generate_colors(num_colors, plot_colors=False):
    """
    Given a desired number of colors, generate colormap of fixed saturation & lightness
    to avoid confusion when plotting each color with full opacity and 50% opacity.
    Excludes hard-to-see colors like yellow.
    """
    fixed_lightness = 0.5
    fixed_saturation = 0.8

    # Custom hue distribution avoiding yellow (0.1667 - 0.25)
    hues = np.linspace(0, 1, num_colors + 1)
    hues = hues[(hues < 1/6) | (hues > 1/3)]  # Exclude the yellow range
    colors = [hls_to_rgb(hue, fixed_lightness, fixed_saturation) for hue in hues]

    if plot_colors:
        for i, color in enumerate(colors):
            plt.plot([0, 1], [i, i], color=color, lw=3)
        plt.show()

    return colors

#Example:
generate_colors(3, plot_colors=True)

def mean_smooth(y, window_size=15):
  """
  Given 1D array y, compute moving average of y given window size.
  If window_size=0, return y unchanged.
  Output: 1D array of same length as y

  Example: [1,1,1,1,1,2,2,2,2,3], window_size=3
  1. pad y by window_size/2=1 by repeating first and last vals:
    [1] + [1,1,1,1,1,2,2,2,2,3] + [3]
  2. compute moving average with convolution:
    [1 , 1 ,  1 , 1 , 1 ,  1 ,   2 ,  2 ,  2 ,  2 ,  3 , 3 ]
      [3/3, 3/3, 3/3, 3/3, 4/3, 5/3, 6/3, 6/3, 7/3, 8/3]
  """
  if window_size == 0: return y
  padded_y = np.pad(y, (window_size//2, window_size-1-window_size//2), mode='edge')
  weights = np.ones(window_size) / window_size
  smoothed_y = np.convolve(padded_y, weights, mode='valid')
  return smoothed_y

def smooth_data(df, col_name, threshold):
    """
    Takes the file dataframe and desired column to smooth (i.e. Thumb01x)
    iterates through each number and smooths any jumps in the data.
    "Jumps" = two consecutive nums are more than inputted threshold apart.
    Output: smoothed column of the dataframe (NOT in-place)
    """
    # if col_name is a list:
    if isinstance(col_name, list):
      for name in col_name:
        df[name] = smooth_data(df, name, threshold)
      return df
    if col_name not in df.columns and col_name in force_cols:
        #print(f"Column '{col_name}' not found in the DataFrame. Skipping.")
        return None

    data = df[col_name].copy()  # Create a copy of the column data
    for i in range(1, len(data)):
      if abs(data[i-1] - data[i]) > threshold:  # Jump detected
        constant = data[i-1] - data[i]
        data[i:] += constant
    #data -= data[0]
    return data

# general func to compute dist(base, joint2) / dist(base, joint1)
def compute_ratio(df, base, joint1, joint2, output_col_name, smooth_output=True):
  """
  Given file df and names of base, joint1, and joint cols, smooth jumps in them
  and use to compute:
    dist(base, joint2) / dist(base, joint1),
  or if denominator is 0, set ratio to 0. Then smooth computed distance and
  outputed ratio by ratio_jump_threshold IF smooth_output=True and add to df
  """
  for joint in [base, joint1, joint2]:
    for axis in axes:
      smooth_data(df, joint+axis,jump_threshold)

  base_dfs = [df[base+axis] for axis in axes]
  joint1_dfs = [df[joint1+axis] for axis in axes]
  joint2_dfs = [df[joint2+axis] for axis in axes]

  dist1 = np.sqrt((joint1_dfs[0] - base_dfs[0])**2 + (joint1_dfs[1] - base_dfs[1])**2 + (joint1_dfs[2] - base_dfs[2])**2)
  dist2 = np.sqrt((joint2_dfs[0] - base_dfs[0])**2 + (joint2_dfs[1] - base_dfs[1])**2 + (joint2_dfs[2] - base_dfs[2])**2)

  # remove any trailing underscores in the 3 names (i.e. 'Hand_pos_' --> 'Hand_pos')
  base = base[0:-1] if base[-1] == '_' else base
  joint1 = joint1[0:-1] if joint1[-1] == '_' else joint1
  joint2 = joint2[0:-1] if joint2[-1] == '_' else joint2

  df[base + "—" + joint1 + "_dist"] = dist1
  df[base + "—" + joint2 + "_dist"] = dist2

  if smooth_output:
    df[base + "—" + joint1 + "_dist"]= smooth_data(df, base + "—" + joint1 + "_dist", ratio_jump_threshold)
    df[base + "—" + joint2 + "_dist"] = smooth_data(df, base + "—" + joint2 + "_dist", ratio_jump_threshold)
  df[output_col_name] = np.where(dist1 != 0, dist2 / dist1, 0)
  if smooth_output:  df[output_col_name] = smooth_data(df, output_col_name, ratio_jump_threshold)

def no_scroll():
    """
    avoid scrolling within constrained sub-window, i.e. to display many plots:
    """
    from google.colab import output
    output.no_vertical_scroll()

def allow_scroll():
    """
    re-enable vertical scrolling within constrained sub-window
    """
    from google.colab import output
    output.clear()

"""### Graphers"""

def graph_files(files, files_untrimmed, is_affected, testno, hand, output_name, deg_min_max=[-100,100], ratio_min_max=[0.7,1.3], dist_min_max=[-.025,0.1],
                save_path = None, hide_plot = False):
  """
  Inputs:
  files, a dictionary with keys 'Right' and 'Left' with a list of dfs as the value of each key
  files_untrimmed, same as files but the original untrimmed files.
  If the given dfs in files and files_untrimmed are stretched, it will plot stretched. If not, not etc.
  is_affected: False if tendency test. 'L' if left is affected. 'R' if right is affected.
  testno: where 0 = mass finger flexion
  hand: 'Left' or 'Right' or 'both'
  output_name: name of the plot title and if save_path, plot image filename
  min_maxes: y axis range for each type of plot (degree, ratio, distance)
  save_path: path to save the plot image to, if None then do not save
  hide_plot: displays plot within notebook by default (False)

  Outputs:
  One 9 x 4 graph for a given test (testno) where:
    first 3 rows is for Index01, Index02, and Thumb01 respectively
      with the 4 cols featuring their x,y,z and absolute sum of that finger's x,y,z.
    next 5 rows being various combinations of a base joint position and two other joint positions
      where 4 cols feature base-joint1 distance, base-joint2 distance, and ratio (latter distance / former distance)
    last row includes force sensor data (if applicable). For sphere test with 6 rows, two additional force cols are
    plotted right above the last row, 4th col.
  Each trial is plotted in full color for trimmed, and same color but semi-transparent for untrimmed.
  There are 3 choices.
    hand='Left': plots only left hand trials. each trial has unique color.
    hand='Right': plots only right hand trials. each trial has unique color.
    hand='Unaffected' or 'Affected': for non tendency tests
    hand='both': plots both hands. left hand is blue, right hand is green

  """
  #print(f"num_trials={num_trials} Left, {sum('Right' in file for file in files.keys())} Right")
  if files is None: files = files_untrimmed

  if hand.lower() == 'both':
    is_both = True
    if is_affected:
      if is_affected == 'R': is_unaffected = 'L'
      elif is_affected == 'L': is_unaffected = 'R'
      else: raise Exception("is_affected must equal 'L' for left hand being affected or 'R' for right or False for tendency test")
      dfs = files[testno]['Unaffected'] + files[testno]['Affected']
      dfs_untrimmed = files_untrimmed[testno]['Unaffected'] + files_untrimmed[testno]['Affected']
      num_trials = len(files[testno]['Unaffected'])
    else:
      dfs = files[testno][hands[0]] + files[testno][hands[1]]
      dfs_untrimmed = files_untrimmed[testno][hands[0]] + files_untrimmed[testno][hands[1]]
      num_trials = len(files[testno][hands[0]])
  else:
    is_both = False
    dfs = files[testno][hand] # retrieve all processed dfs of the filenames
    dfs_untrimmed = files_untrimmed[testno][hand] # retrieve all processed dfs of the filenames

  alpha=0.2
  colors = generate_colors(len(dfs))

  fig, subplts = plt.subplots(9, 4, figsize=(10, 22))
  plt.suptitle(output_name, fontsize='xx-large')
  fig.tight_layout()
  fig.subplots_adjust(top=0.94)
  plt.subplots_adjust(hspace=0.5)
  plt.subplots_adjust(wspace=1.2)

  # degrees
  for finger, plts in zip(fingers, [subplts[0],subplts[1], subplts[2]]):
    for axis, plt_id in zip(axes, plts):
      for i, (df, df_untrimmed) in enumerate(zip(dfs, dfs_untrimmed)):
        if is_affected:
          label = f'Unaff({is_unaffected})' if is_both and i < num_trials else f'Aff({is_affected})'
          color = 'green' if is_both and i < num_trials else 'red'
        else:
          label = 'L' if is_both and i < num_trials else 'R'
          color = 'blue' if label == 'L' else 'green'
        #print(df[finger + axis].unique())
        plt_id.plot(df['Timestamp'], df[finger + axis], label=str(i+1) if not is_both else label, color=colors[i] if not is_both else color)
        plt_id.plot(df['Timestamp'], df_untrimmed[finger + axis], label=str(i+1) if not is_both else label, color=colors[i] if not is_both else color, alpha=alpha)
      plt_id.set(xlabel ='time', ylabel = 'degrees')
      plt_id.set_title(finger + ' ' + axis + '-axis')

  # Plot sum of x, y, z for each joint
  for finger, plt_id in zip(fingers, [subplts[0][-1],subplts[1][-1], subplts[2][-1]]):
    for i, (df, df_untrimmed) in enumerate(zip(dfs, dfs_untrimmed)):
      if is_affected:
          label = f'Unaff({is_unaffected})' if is_both and i < num_trials else f'Aff({is_affected})'
          color = 'green' if is_both and i < num_trials else 'red'
      else:
        label = 'L' if is_both and i < num_trials else 'R'
        color = 'blue' if label == 'L' else 'green'
      abs_sum= np.abs(df[[finger + 'x', finger + 'y', finger + 'z']]).sum(axis=1)
      abs_sum_untrimmed= np.abs(df_untrimmed[[finger + 'x', finger + 'y', finger + 'z']]).sum(axis=1)
      plt_id.plot(df['Timestamp'], abs_sum, label=str(i + 1) if not is_both else label, color=colors[i] if not is_both else color)
      plt_id.plot(df_untrimmed['Timestamp'], abs_sum_untrimmed, label=str(i + 1) if not is_both else label, color=colors[i] if not is_both else color, alpha=alpha)
    plt_id.set(xlabel='time', ylabel='Sum of x, y, z')
    plt_id.set_title('Sum of x, y, z')

  #if not is_affected:
    #print("PLOTTING RATIOS NOW")
    # ratios
  for names, plts in zip([['Hand_pos—ThumbCMC_dist','Hand_pos—ThumbMCP_dist','Thumb_Hand_dist_ratio'], \
    ['Hand_pos—IndexMCP_dist','Hand_pos—IndexPIP_dist','Hand_Index1-2_dist_ratio'], \
    ['ThumbMCP—IndexMCP_dist', 'ThumbMCP—IndexPIP_dist','Thumb_Index1-2_dist_ratio'],\
    #['IndexMCP—IndexPIP_dist', 'IndexMCP—IndexDIP_dist','Index1_Index2-3_dist_ratio'], \
    ['Hand_pos—IndexPIP_dist', 'Hand_pos—IndexDIP_dist','Hand_Index2-3_dist_ratio'],\
    ['ThumbMCP—IndexPIP_dist', 'ThumbMCP—IndexDIP_dist','Thumb_Index2-3_dist_ratio']], \
      [subplts[3], subplts[4], subplts[5], subplts[6], subplts[7]]):
    for ratio,plt_id,ylabel in zip(names, plts, ['jointA','jointB','ratio']):
      for i, (df, df_untrimmed) in enumerate(zip(dfs, dfs_untrimmed)):
        if is_affected:
          label = f'Unaff({is_unaffected})' if is_both and i < num_trials else f'Aff({is_affected})'
          color = 'green' if is_both and i < num_trials else 'red'
        else:
          label = 'L' if is_both and i < num_trials else 'R'
          color = 'blue' if label == 'L' else 'green'
        plt_id.plot(df['Timestamp'], df.get(ratio), label=str(i+1) if not is_both else label, color=colors[i] if not is_both else color)
        plt_id.plot(df_untrimmed['Timestamp'], df_untrimmed.get(ratio), label=str(i+1) if not is_both else label, color=colors[i] if not is_both else color, alpha=alpha)
      plt_id.set(xlabel ='time', ylabel = ylabel)
      plt_id.set_title(ratio)

  # join degree rows
  degree_axes = np.concatenate((subplts[0][:-1], subplts[1][:-1], subplts[2][:-1]))
  #for ax1, ax2 in zip(degree_axes[1:],degree_axes[0:-1]): ax1.sharey(ax2)
  for ax in degree_axes:
    ax.set_ylim([deg_min_max[0], deg_min_max[1]])

  for i in range(3,8):
    subplts[i][2].set_ylim([ratio_min_max[0], ratio_min_max[1]]) # join ratio rows
    subplts[i][0].set_ylim([dist_min_max[0], dist_min_max[1]]) #dist rows
    subplts[i][1].set_ylim([dist_min_max[0], dist_min_max[1]]) #dist rows

  # join force rows
  for i in range(3): subplts[-1][i].sharey(subplts[-1][3])

  # force sensor plot
  invert_axis =False
  start_index = (testno-4)*2
  print(test_to_force[testno])
  for ratio, plt_id in zip(test_to_force[testno], np.concatenate([subplts[-1], subplts[-2][3:], subplts[-3][3:]])):
    ylabel = 'force data'
    for i, (df, df_untrimmed) in enumerate(zip(dfs, dfs_untrimmed)):
      if is_affected:
          label = f'Unaff({is_unaffected})' if is_both and i < num_trials else f'Aff({is_affected})'
          color = 'green' if is_both and i < num_trials else 'red'
      else:
        label = 'L' if is_both and i < num_trials else 'R'
        color = 'blue' if label == 'L' else 'green'
      plt_id.plot(df['Timestamp'], df[ratio], label=str(i+1) if not is_both else label, color=colors[i] if not is_both else color)
      plt_id.plot(df_untrimmed['Timestamp'], df_untrimmed[ratio], label=str(i+1) if not is_both else label, color=colors[i] if not is_both else color, alpha=alpha)
    plt_id.set(xlabel ='time', ylabel = ylabel)
    plt_id.set_title(ratio)
    if invert_axis: plt_id.invert_yaxis()

  # adjust legend and visibility
  for row in subplts:
    for ax in row:
      if ax.has_data():
        if (is_both):
          if is_affected:
            custom_lines = [Line2D([0], [0], color='red', lw=2), Line2D([0], [0], color='green', lw=2)]
            ax.legend(custom_lines, [f'Aff({is_affected})', f'Unaff({is_unaffected})'], fontsize='x-small', bbox_to_anchor=(1.05, 1.0), loc='upper left')
          else:
            custom_lines = [Line2D([0], [0], color='blue', lw=2), Line2D([0], [0], color='green', lw=2)]
            ax.legend(custom_lines, ['L', 'R'], fontsize='x-small', bbox_to_anchor=(1.05, 1.0), loc='upper left')
        else:
          custom_lines = []
          for i in range (0, len(dfs)):
            custom_lines.append(Line2D([0], [0], color=colors[i], lw=2))
          labels = [str(i + 1) for i in range(len(dfs))]
          ax.legend(custom_lines, labels, fontsize='x-small', bbox_to_anchor=(1.05, 1.0), loc='upper left')
      else: ax.axis('off')

  # save the image:
  if save_path is not None:
      save_file_path = os.path.join(save_path, f"{output_name}.png")
      os.makedirs(save_path, exist_ok=True)
      print(f"saving to {save_file_path}")
      plt_id.figure.savefig(save_file_path)

  if hide_plot: plt.close()
  else: plt.show()

#def graph_files(files, files_untrimmed, testno, hand, output_name, deg_min_max=[-100,100], ratio_min_max=[0.7,1.3], dist_min_max=[-.025,0.1],
                #save_path = None, normalize = True, trim = True, hide_plot = False):

def graph_all_scores(score2_files, score1_files, score0_files, score2_files_untrimmed, score1_files_untrimmed, score0_files_untrimmed,
                     hand, output_name, deg_min_max, save_path=None, hide_plot=False):
  """
  Inputs:
  score<x>_files, a dictionary with keys 'Right' and 'Left' with a list of dfs as the value of each key
  score<x>_files_untrimmed, same as files but the original untrimmed files.
  If the given dfs in files and files_untrimmed are stretched, it will plot stretched. If not, not etc.
  hand: 'Left' or 'Right' or 'both'
  output_name: name of the plot title and if save_path, plot image filename
  deg_min_max: y axis range for degree plots
  save_path: path to save the plot image to, if None then do not save
  hide_plot: displays plot within notebook by default (False)

  Outputs:
  One 6 x 3 graph for a given test where:
    each row is a degree sensor (Index01y, Index01z, Index02z, Thumb01x, Thumb01y, Thumb01z)
      with the 3 cols featuring Score 0, Score 1, Score 2 (left to right)
  Each trial is plotted in full color for trimmed, and same color but semi-transparent for untrimmed.
  There are 3 choices.
    hand='Left': plots only left hand trials. each trial has unique color.
    hand='Right': plots only right hand trials. each trial has unique color.
    hand='both': plots both hands. left hand is blue, right hand is green
  """
  if 'both' in hand.lower():
    is_both = True
    all_dfs = {
        2: (score2_files[hands[0]] + score2_files[hands[1]], score2_files_untrimmed[hands[0]] + score2_files_untrimmed[hands[1]]),
        1: (score1_files[hands[0]] + score1_files[hands[1]], score1_files_untrimmed[hands[0]] + score1_files_untrimmed[hands[1]]),
        0: (score0_files[hands[0]] + score0_files[hands[1]], score0_files_untrimmed[hands[0]] + score0_files_untrimmed[hands[1]])
    }
    num_trials = {
          2: len(score2_files[hands[0]]),
          1: len(score1_files[hands[0]]),
          0: len(score0_files[hands[0]])
        }
  else:
    is_both = False
    hand = get_hand(hand)
    all_dfs = {
        2: (score2_files[hand], score2_files_untrimmed[hand]),
        1: (score1_files[hand], score1_files_untrimmed[hand]),
        0: (score0_files[hand], score0_files_untrimmed[hand])
    }

  alpha=0.2
  colors = generate_colors(25)


  fig, subplts = plt.subplots(6, 3, figsize=(7, 15))

  # column and row labels:
  cols = ['Score {}'.format(col) for col in range(0,3)]
  rows = nonredundant_degree_cols
  for ax, col in zip(subplts[0], cols):
      ax.set_title(col)

  for ax, row in zip(subplts[:,0], rows):
      ax.set_ylabel(row, rotation=0, size='large')

  # set main title and image name:
  plt.suptitle(output_name, fontsize='xx-large')

  fig.tight_layout()
  fig.subplots_adjust(top=0.94)
  plt.subplots_adjust(hspace=0.3)
  plt.subplots_adjust(wspace=1)

  # degrees
  for score in range(2,-1,-1):
    for degree_col, j in zip(nonredundant_degree_cols, range(6)):
      dfs = all_dfs[score][0]
      dfs_untrimmed = all_dfs[score][1]
      for i, (df, df_untrimmed) in enumerate(zip(dfs, dfs_untrimmed)):
        label = ''
        color = ''

        if is_both:
          label = 'L' if i < num_trials[score] else 'R'
          color = 'blue' if label == 'L' else 'green'
        else:
          label = str(i+1)
          color = colors[i]

        #print(label, color)
        subplts[j][score].plot(df['Timestamp'], df[degree_col], label=label, color=color)
        subplts[j][score].plot(df['Timestamp'], df_untrimmed[degree_col], label=label, color=color, alpha=0.14)
        #subplts[j][score].set(ylabel = degree_col)
        subplts[j][score].set_title('Score ' + str(score))

  # join degree rows
  for i in range(6):
    for j in range(3):
      subplts[i][j].set_ylim([deg_min_max[0], deg_min_max[1]])

  # adjust legend and visibility

  for row in subplts:
    for ax in row:
      if ax.has_data():
        if (is_both):
          custom_lines = [Line2D([0], [0], color='blue', lw=2), Line2D([0], [0], color='green', lw=2)]
          ax.legend(custom_lines, ['L', 'R'], fontsize='x-small', bbox_to_anchor=(1.05, 1.0), loc='upper left')
        else:
          custom_lines = []
          for i in range (0, len(dfs)):
            custom_lines.append(Line2D([0], [0], color=colors[i], lw=2))
          labels = [str(i + 1) for i in range(len(dfs))]
          ax.legend(custom_lines, labels, fontsize='x-small', bbox_to_anchor=(1.05, 1.0), loc='upper left')
      else: ax.axis('off')

  # save the image:
  if save_path is not None:
    save_file_path = os.path.join(save_path, f"{output_name}.png")
    os.makedirs(save_path, exist_ok=True)
    print(f"saving to {save_file_path}")
    fig.savefig(save_file_path)

  if hide_plot: plt.close()
  else: plt.show()

"""### process file

#### force-trimming algorithm
"""

def force_process_file(path):
  """
  Wrapper function to call force-trimming algorithm given a single input, filepath
  returns start and end indices to trim by and data with processed force col,
  "sum_data", as the corresponding force col used to decide the trimming depending
  on which test the path directs to.
  """
  testno = get_testno(path)
  task = testnames[testno]

  df = pd.read_csv(path)
  df.columns = df.columns.str.strip()
  time_hand = df.iloc[:, 0].values

  # Identify relevant columns
  present_labels = [col for col in df.columns if col in sensor_labels]
  sensor_data = {col: df[col].values for col in present_labels}

  curr_task_sensors = task_sensor.get(task, [])
  file_group = find_file_group(path)                         #  file_group needed to define start & end gap
  force_start_idx, force_end_idx, sum_data = find_trim_idx_force(sensor_data, curr_task_sensors, task, time_hand, df, file_group)
  df['force'] = sum_data
  return force_start_idx, force_end_idx, df


def find_file_group(file_path):
    file_name = os.path.basename(file_path)
    if loadExperimentData:                               # for with_hand files only
        if "right" in file_name.lower(): return "right_wh"
        elif "left" in file_name.lower(): return "left_wh"
    elif loadTendencyData:
        if "S2" in file_name: return "score_two"
        elif "S1" in file_name: return "score_one"
        elif "S0" in file_name: return "score_zero"

"""#### degree-trimming algorithm"""

import pandas as pd
from warnings import simplefilter
simplefilter(action="ignore", category=pd.errors.PerformanceWarning)

from matplotlib.lines import Line2D
import pandas as pd
import numpy as np
import math

pd.options.mode.chained_assignment = None  # default='warn'

def trimmer(time, smoothed_deg, threshold_a, threshold_b, window_size=10, isThumbAdduction=False, percent_range = 0.05):
  """
  Inputs:
  time: Timestamp column of df
  smoothed_deg: mean-smoothed degree cols
  smoothed_forces: mean-smoothed force cols
  threshold_a: % of absolute max gradient to trim beginning
  threshold_b: % of absolute max gradient to trim end
  window_size: degree_window_size to mean-smooth (moving average) the gradient of smoothed_deg input to trimming.
  isThumbAdduction: if thumb adduction, trim at peak of thumb01z special case.
  percent_range: ensure preserving 95% of range on each end after trimming.
    df[:end_idx] range >= 95% of df range
    df[start_idx:end_idx] range >= 95% of df[:end_idx] range

  Outputs: start_idx, end_idx in which to trim based on degree algorithm only

  Algorithm:
    1. computes gradient to trim.
  """
  #print(f"{len(smoothed_deg)}")
  min_trim_array_length = 10  # minimum no. of datapoints after trimming

  gradient = np.gradient(smoothed_deg, time)
  gradient_threshold_a = threshold_a * max(abs(max(gradient)), abs(min(gradient)))
  gradient_threshold_b = threshold_b * max(abs(max(gradient)), abs(min(gradient)))
  interp_prefft_time = np.linspace(0, 2, num=int(2/0.01)+1)

  # CUT ENDING
  original_range = smoothed_deg.max() - smoothed_deg.min()
  if original_range == 0: end_idx = 0
  else:
    moving_avg_gradient = mean_smooth(abs(gradient), window_size)
    end_idx = len(smoothed_deg)-1
    for i in range(len(moving_avg_gradient) - 1, -1, -1):
      if moving_avg_gradient[i] > gradient_threshold_b:
        new_range = smoothed_deg[:end_idx].max() - smoothed_deg[:end_idx].min()
        if new_range/original_range > (1-percent_range):  # if cut, >95% of original range?
          end_idx = i  # Adjust for window size
          continue
        else: break
  end_idx = len(gradient)-1 if end_idx >= len(gradient) else end_idx

  # CUT BEGINNING
  start_idx = 0
  if isThumbAdduction:
    for i in range(1, min(end_idx, len(smoothed_deg) // 2)):  # find index of local y peak at first half of data
      if smoothed_deg[start_idx] <= smoothed_deg[i]:
          start_idx = i
  else:
    #print(f"end_idx={end_idx}")
    original_range = smoothed_deg[:end_idx].max() - smoothed_deg[:end_idx].min()
    if original_range == 0: start_idx = 0
    else:
      #print(f"original_range={original_range}")
      moving_avg_gradient = mean_smooth(abs(gradient), window_size)
      moving_avg_threshold_a = gradient_threshold_a
      #moving_avg = mean_smooth(abs(smoothed_deg), window_size)
      for i in range(1, min(end_idx, len(moving_avg_gradient))):
        #cut_range = abs(moving_avg[0] - moving_avg[i])
        cut_shorterm_range = abs(smoothed_deg[i-5 if i > 5 else 0] - smoothed_deg[i])
        cut_range = max(smoothed_deg[:i]) - min(smoothed_deg[:i])
        if math.isnan(cut_shorterm_range):
          #print(f"cut_shorterm_range=nan")
          cut_shorterm_range=0
        if math.isnan(cut_range):
          #print(f"cut_range=nan")
          cut_range=0
        #print(f"cut_range={max(smoothed_deg[:i])}-{min(smoothed_deg[:i])}={cut_range:0,.2f}")
        #print(f"\tis cut/og {cut_range:0,.2f}/{original_range:0,.2f}={cut_range/original_range:0,.2f} of range <= {(2*percent_range):0,.2f}?")
        #print(f"\tis cut-short/og {cut_shorterm_range:0,.2f}/{original_range:0,.2f}={cut_shorterm_range/original_range:0,.2f} of range <= {(percent_range):0,.2f}?")
        if cut_shorterm_range/original_range <= percent_range and cut_range/original_range <= 2*percent_range:
          start_idx = i
          #print(f"start_idx={start_idx}")
        else: break # skip no matter what if not ok

  # Ensure start_idx is less than end_idx
  if start_idx >= end_idx:
    print(f"SHOOT! start_idx >= end_idx D {start_idx}-{end_idx}")
    return 0, len(smoothed_deg)-1

  #print(f"is end_idx D {end_idx}")
  return start_idx, end_idx

def basic_processing(df):
  # smooth jumping
  for col_name in og_cols:
    col = smooth_data(df, col_name, jump_threshold)
    if col is not None: df[col_name] = col

  # compute ratios
  compute_ratio(df, 'Hand_pos_', 'ThumbCMC', 'ThumbMCP', 'Thumb_Hand_dist_ratio')
  compute_ratio(df, 'Hand_pos_', 'IndexMCP', 'IndexPIP', 'Hand_Index1-2_dist_ratio')
  compute_ratio(df, 'ThumbMCP', 'IndexMCP', 'IndexPIP', 'Thumb_Index1-2_dist_ratio')
  compute_ratio(df, 'IndexMCP', 'IndexPIP', 'IndexDIP', 'Index1_Index2-3_dist_ratio')
  compute_ratio(df, 'Hand_pos_', 'IndexPIP', 'IndexDIP', 'Hand_Index2-3_dist_ratio')
  compute_ratio(df, 'ThumbMCP', 'IndexPIP', 'IndexDIP', 'Thumb_Index2-3_dist_ratio')

  # shift to start on 0 or 1
  for col in df:
    if col in ratio_cols:
      df[col] = df[col] - df[col][0] + 1 # starts at 1
    else: df[col] -= df[col][0] # starts at 0

def degree_process_file(path, normalize=True, threshold_a=0.1, threshold_b=0.1, window_size=12, percent_range=0.05):
  """
  Inputs:
  path: full path to csv
  threshold_a: % of absolute max gradient to trim beginning
  threshold_b: % of absolute max gradient to trim end
  window_size: degree_window_size, to mean-smooth (moving average) the input.

  Outputs:
  df: untrimmed unstretched data with ratio and dist cols and mean-smoothed force + degree col
    degree col is absolute sum of all 9 degree cols unless thumb adduction test, which
    is fixed at Thumb01z to trim peak due to leaving thumb close starting position to take paper
  picked_deg: abs_sum_deg or Thumb01z, see above
  trim_idxes: [start_idx, end_idx] in which to trim based on degree-trimming algorithm
  """
  df = pd.read_csv(path)
  testno = get_testno(path)
  isThumbAdduction = testno==3
  trim_idxes = None

  basic_processing(df)

  # compute mean smoothed data cols and pick col to trim by max range of mean-smoothed degs
  if isThumbAdduction:
    picked_deg = 'Thumb01z' #only cut by peak of thumb01z
    df[picked_deg+'_mean_smooth'] = mean_smooth(df[picked_deg], window_size=window_size)
  else: # cut by sum of ALL (mean-smoothed) deg cols
    df['abs_sum_deg'] = 0 #initialize sum
    df['abs_sum_deg_mean_smooth'] = 0 #initialize sum mean smoothed
    for col in degree_cols:
      df[col+'_mean_smooth'] = mean_smooth(df[col], window_size=window_size)
      df['abs_sum_deg_mean_smooth'] += np.abs(df[col+'_mean_smooth'])
      df['abs_sum_deg'] += np.abs(df[col])
    picked_deg = 'abs_sum_deg'

  # 0. GET NORMALIZED UNTRIMMED VERSION
  if (normalize):
    for c in degree_cols + new_cols + test_to_force[testno]:
      if c not in df.columns: continue
      if 'ratio' in c: df.loc[:, c] -= df[c].iloc[0] - 1 #normalize to 1
      else: df.loc[:, c] -= df[c].iloc[0]  # normalize to 0

  # 2. clip the data
  #trimmer(time, smoothed_deg, threshold_a, threshold_b, window_size=10, isThumbAdduction=False, percent_range = 0.05):
  if window_size != 0 and threshold_a != 0 and threshold_b != 0 and percent_range != 0:
    start,end = trimmer(df['Timestamp'], df[picked_deg+'_mean_smooth'], threshold_a, threshold_b, window_size, isThumbAdduction, percent_range)
    trim_idxes = [start,end]
    #print(f"trim: {start}-{end} instead of 0-{len(df['Timestamp'])}")

  for col_name in degree_cols + new_cols + test_to_force[testno] + og_cols_for_ratio:
    # normalize cols
    if (normalize):
      if 'ratio' in col_name: df.loc[:, col_name] -= df[col_name].iloc[0] - 1 #normalize to 1
    elif col_name in force_cols:
      if col_name not in df.columns: continue
      if df[col_name].iloc[0] >= 900:
        df.loc[:, col_name] = -1 * df[col_name] # flip the force col
    else:
      if (normalize): df.loc[:, col_name] -= df[col_name].iloc[0] #normalize to 0

  # Flip the thumb data based on the sum of positive and negative values
  for col in ['Thumb01x', 'Thumb01y', 'Thumb01z']:
    # Calculate sum of negative and positive values
    sum_neg = df[col][df[col] < 0].sum()
    sum_pos = df[col][df[col] > 0].sum()

    f = 1
    # If the sum of negatives is greater than the sum of positives, flip the column
    if abs(sum_neg) > abs(sum_pos):
        df[col] *= -1

    # Multiply by the flip direction after ensuring the data is flipped correctly
    df[col] *= flip_direction[col][testno]

  return df, picked_deg,trim_idxes

"""#### combined"""

import copy

def process_file_combined(path, threshold_a=0.1, threshold_b=0.1, window_size=12, percent_range=0.05):
  """
  Inputs:
  path: full path to csv
  threshold_a: % of absolute max gradient to trim beginning
  threshold_b: % of absolute max gradient to trim end
  window_size: degree_window_size to mean-smooth (moving average) the input.

  Outputs: both dfs are stretched to 0-2 and interpolated by 0.01 step size
  df: trimmed by combination of degree-trimming and force-trimming algorithms, then stretched & interpolated to 0-2
    if first two tests, only trim by degree-trimming
    otherwise, take the most lenient trimming (minimum start idx and maximum end idx of the two trimmers)
      if score 0, no force data and force trimmer defaults to no trimming (0-len(df)) and thus chosen as most lenient trimming
  df_untrimmed: stretched to 0-2
  final_trim_idxes: [start_idx, end_idx] in which to trim based on both algorithms
  picked_deg: col name added to df used to trim by degree:
    is absolute sum of all 9 degree cols unless thumb adduction test, which
    is fixed at Thumb01z to trim peak due to leaving thumb close starting position to take paper
  """
  # get and process degree trim idx, df, and trim x vals
  deg_df_untrimmed, picked_col, deg_trim_idxes = degree_process_file(path, threshold_a=threshold_a, threshold_b=threshold_b, window_size=window_size, percent_range=percent_range)
  deg_df_untrimmed[picked_col] -= deg_df_untrimmed[picked_col][0]  # normalize:
  #deg_trim_vals = [deg_df_untrimmed['Timestamp'][deg_trim_idxes[0]], deg_df_untrimmed['Timestamp'][deg_trim_idxes[1]]]

  # get and process force trim idx, df, and force x vals
  force_trim_idxes=[None, None]
  force_trim_idxes[0], force_trim_idxes[1], force_df_untrimmed = force_process_file(path)
  #force_trim_vals = [force_df_untrimmed['Timestamp'][force_trim_idxes[0]], force_df_untrimmed['Timestamp'][force_trim_idxes[1]]]

  # get final trim idx and force x vals
  final_trim_idxes = [None, None]
  #final_trim_vals = [None, None]
  testno = get_testno(path)
  if testno == 0 or testno == 1: # no force
    final_trim_idxes = deg_trim_idxes
    #final_trim_vals = deg_trim_vals
  else:
    final_trim_idxes[1] = force_trim_idxes[1] # always cut end with force
    #final_trim_vals[1] = force_trim_vals[1]
    if deg_trim_idxes[0] <= force_trim_idxes[0]: # cut beginning by earliest index
      final_trim_idxes[0] = deg_trim_idxes[0]
      #final_trim_vals[0] = deg_trim_vals[0]
    else:
      final_trim_idxes[0] = force_trim_idxes[0]
      #final_trim_vals[0] = force_trim_vals[0]

  df = copy.deepcopy(deg_df_untrimmed) # copy
  df = df.iloc[final_trim_idxes[0]:final_trim_idxes[1]] # trim
  df = interpolate_to_0_2(df)
  deg_df_untrimmed = interpolate_to_0_2(deg_df_untrimmed)

  return df, deg_df_untrimmed, final_trim_idxes, picked_col

"""# More Functions"""

# Start, end gaps for force sensor trimming for different file_groups (used in find_trim_indices_list)
# Gaps can be edited as needed to improve trimming for a particular dataset

if loadExperimentData:
    file_group_gap = {'unaff_wh': (30, 30),
                      'right_wh': (30, 30),          # right_wh and left_wh defined for force_process_file
                      'unaff_woh': (30, 30),
                      'aff_wh': (30, 30),
                      'left_wh': (30, 30),
                      'aff_woh': (30, 30) }

if loadTendencyData:
    file_group_gap = {'score_two': (30, 30),
                      'score_one': (30, 30),
                      'score_zero': (30, 30)}

if loadExperimentData and loadTendencyData: print("Error: Tendency Data and Experiment Data both loaded")

# ----------------------------------------------

# Sensors for each task
task_sensor = {
    "Hookgrasp": ["hook"],
    "Thumbadduction": ["paper"],
    "Pincergrasp": ["pencilThumb", "pencilFinger"],
    "Cylindricalgrasp": ["bottleVert", "bottleRadial"],
    "Sphericalgrasp": ["sphereThumb", "sphereF_L1", "sphereF_L2", "sphereF_M", "sphereF_R1","sphereF_R2", "sphereFingers", "sphereThumb"],
    "Massfingerextension": [],
    "Massfingerflexion": [] }


sensor_labels = ['paper',
                 'sphereThumb', 'sphereF_L1','sphereF_L2',
                 'sphereF_M', 'sphereF_R1', 'sphereF_R2',
                 'bottleVert', 'bottleRadial',
                 'pencilThumb','pencilFinger',
                 'hook',
                 'sphereThumb', 'sphereFingers']     #for older

for key in sensor_labels: sensor_labels = [label.strip() for label in sensor_labels]
sensor_labels_normalized = [label.strip().lower() for label in sensor_labels]

cylindrical_sensors = ['bottleVert','bottleRadial']
cylindrical_sensors_norm = [sensor.strip().lower() for sensor in cylindrical_sensors]

# Define as spherical_sensors = [col for col in df.columns if 'sphere' in col] within functions
# (NOT USED) spherical_sensors = ["sphereThumb", "sphereF_L1", "sphereF_L2", "sphereF_M", "sphereF_R1","sphereF_R2"]

pencil_sensors = ['pencilThumb', 'pencilFinger']
pencil_sensors_norm = [sensor.strip().lower() for sensor in pencil_sensors]

sensor_colors = plt.colormaps['tab20']
colors2 = plt.colormaps['Set1']


thumb_columns = ['Thumb01x', 'Thumb01y', 'Thumb01z']
index01_columns = ['Index01x', 'Index01y', 'Index01z']
chosen_index01_columns = ['Index01y', 'Index01z']
index02_columns = ['Index02x', 'Index02y', 'Index02z']

angle_columns =  ['Thumb01x', 'Thumb01y', 'Thumb01z',
                  'Index01x', 'Index01y', 'Index01z',
                  'Index02x', 'Index02y', 'Index02z']

handpos_columns = ['Hand_pos_x', 'Hand_pos_y', 'Hand_pos_z']
thumbCMC_columns = ['ThumbCMCx', 'ThumbCMCy', 'ThumbCMCz']
thumbMCP_columns = ['ThumbMCPx', 'ThumbMCPy', 'ThumbMCPz']
indexMCP_columns = ['IndexMCPx', 'IndexMCPy', 'IndexMCPz']
indexPIP_columns = ['IndexPIPx', 'IndexPIPy', 'IndexPIPz']
indexDIP_columns = ['IndexDIPx', 'IndexDIPy', 'IndexDIPz']


joint_dist_col_triples = [
    (handpos_columns, thumbCMC_columns, thumbMCP_columns),
    (handpos_columns, indexMCP_columns, indexPIP_columns),
    (thumbMCP_columns, indexMCP_columns, indexPIP_columns),
    (indexMCP_columns, indexPIP_columns, indexDIP_columns),]

joint_dist_titles = [
    ['dist_handpos_thumbCMC', 'dist_handpos_thumbMCP', 'ratio_thumbCMC_thumbMCP'],
    ['dist_handpos_indexMCP', 'dist_handpos_indexPIP', 'ratio_indexMCP_indexPIP'],
    ['dist_thumbMCP_indexMCP', 'dist_thumbMCP_indexPIP', 'ratio_thumbMCP_indexPIP'],
    ['dist_indexMCP_indexPIP', 'dist_indexMCP_indexDIP', 'ratio_indexMCP_indexDIP']]
joint_dist_titles_2 = np.array(joint_dist_titles).flatten()

# dist_ratio_cols =  ['Hand_pos—ThumbCMC_dist', 'Hand_pos—ThumbMCP_dist', 'Thumb_Hand_dist_ratio',       # "Hand_ThumbCMC_ThumbMCP_ratio"
#                     'Hand_pos—IndexMCP_dist', 'Hand_pos—IndexPIP_dist', 'Hand_Index1-2_dist_ratio',
#                     'ThumbMCP—IndexMCP_dist', 'ThumbMCP—IndexPIP_dist', 'Thumb_Index1-2_dist_ratio',
#                     hand - indexpip, 'Hand_pos—IndexDIP_dist',  'Hand_Index2-3_dist_ratio',
#                     thumbmcp - indexpip, 'ThumbMCP—IndexDIP_dist', 'Thumb_Index2-3_dist_ratio']

linestyles = ['-', '--', '-.', ':']



# Section 0: Compare time_hand and time_force
def compare_time(file_group_sorted):
    num_plots = len(file_group_sorted)
    rows = (num_plots // 4) + (num_plots % 4 > 0)
    fig, axes = plt.subplots(rows, 4, figsize=(15, 3 * rows))
    axes = axes.flatten()

    for i, (title, file_path) in enumerate(file_group_sorted.items()):
        df = pd.read_csv(file_path)
        df.columns = [col.strip().lower() for col in df.columns]

        time_hand = df.iloc[:, 0].values
        time_force = df['time'].values
        time_force = time_force - time_force[0]
        smooth_time_force = smooth_time(time_force)

        ax = axes[i]
        ax.plot(time_hand, time_hand, color="red", linestyle = "dashed")
        ax.plot(time_hand, time_force, color="blue", label="time_force")
        ax.plot(time_hand, smooth_time_force, color="green", label="smooth_t_force")
        ax.set_ylim(0, time_hand[-1])
        ax.set_title(title)
        ax.legend()

    plt.tight_layout()
    plt.show()

# Smooth any jumps >1s in time data
def smooth_time(TimeData):
    data = TimeData.copy()
    i = 1
    while i < len(data):
      if abs(data[i-1] - data[i]) > 1:     # for any jumps > 1 second
        constant = data[i-1] - data[i]
        data[i:] += constant
      i += 1
    return data


#Section 1: Hand Sensor Overview

#Plot x, y, z angle data in first 3 and combined xyz in 4th
def plot_joint_angle_overview(ax, data, time_hand, title_prefix, linestyle, file_no):
    for i, (col, values) in enumerate(data.items()):
        if (i==0): ax[i].plot(time_hand, smooth_normalise(values), color=colors2(i), linestyle = linestyle, label=f'Trial {file_no}')
        else: ax[i].plot(time_hand, smooth_normalise(values), color=colors2(i), linestyle = linestyle)
        ax[i].set_title(f'{col}')
    for i, (col, values) in enumerate(data.items()):
        ax[3].plot(time_hand, smooth_normalise(values), color=colors2(i), linestyle = linestyle)
    ax[3].set_title(f'{title_prefix} xyz')
    ax[0].legend()


#Plot distance and ratio, 3 plots per row
def plot_joint_dist_overview(axs, time_hand, joint_dist_col_triples, joint_dist_titles, linestyle, file_no):
    colors2 = plt.colormaps['Set1']

    for row, (col1, col2, col3) in enumerate(joint_dist_col_triples):
        # Compute distances
        dist_joint1_joint2 = joint_dist(col1, col2)
        dist_joint1_joint3 = joint_dist(col1, col3)
        ratio = dist_joint1_joint2 / dist_joint1_joint3

        # Scatter plot of distances and ratio
        axs[row, 0].plot(time_hand, dist_joint1_joint2, color=colors2(0), linestyle = linestyle, label=f'Trial {file_no}')
        axs[row, 0].set_title(f'{joint_dist_titles[row][0]}')
        axs[row, 0].legend()
        axs[row, 1].plot(time_hand, dist_joint1_joint3, color=colors2(1), linestyle = linestyle)
        axs[row, 1].set_title(f'{joint_dist_titles[row][1]}')
        axs[row, 2].plot(time_hand, ratio, color=colors2(2), linestyle = linestyle)
        axs[row, 2].set_title(f'{joint_dist_titles[row][2]}')

        # Set labels
        for ax in axs.flat:
            ax.set(xlabel='time_hand')

#Smooth any jumps >100 in hand sensor data, normalize y-axis start at 0
def smooth_normalise(MotionData):
    data = MotionData.copy()
    i = 1
    while i < len(data):
      if abs(data[i-1] - data[i]) > 100:     # for any jumps > 100
        constant = data[i-1] - data[i]
        data[i:] += constant
      i += 1
      data = data - data[0]                   # Normalize y-axis to start at 0
    return data


#Calculate distance beteen two joints
def joint_dist(joint_one_col, joint_two_col):
    joint_one_data = {col:df[col].values for col in joint_one_col if col in df.columns}
    joint_two_data = {col:df[col].values for col in joint_two_col if col in df.columns}

    dist = np.sqrt((joint_one_data[f'{joint_one_col[0]}'] - joint_two_data[f'{joint_two_col[0]}'])**2 + \
                    (joint_one_data[f'{joint_one_col[1]}'] - joint_two_data[f'{joint_two_col[1]}'])**2 + \
                    (joint_one_data[f'{joint_one_col[2]}'] - joint_two_data[f'{joint_two_col[2]}'])**2)
    return dist

#joint_dist() but diff processing of column names
def joint_dist_2(joint_one_col, joint_two_col, df):
    # joint_one_col = [col.strip().lower() for col in joint_one_col]    #here
    # joint_two_col = [col.strip().lower() for col in joint_two_col]

    joint_one_data = {col:df[col].values for col in joint_one_col if col in df.columns}
    joint_two_data = {col:df[col].values for col in joint_two_col if col in df.columns}

    dist = np.sqrt((joint_one_data[f'{joint_one_col[0]}'] - joint_two_data[f'{joint_two_col[0]}'])**2 + \
                    (joint_one_data[f'{joint_one_col[1]}'] - joint_two_data[f'{joint_two_col[1]}'])**2 + \
                    (joint_one_data[f'{joint_one_col[2]}'] - joint_two_data[f'{joint_two_col[2]}'])**2)
    return dist

#Section 3: Hand and Force Sensor Data, by trial
"""
Inputs:
task - "Hookgrasp", "Thumbadduction", "Pincergrasp", "Cylindricalgrasp", "Sphericalgrasp"
df - original dataframe
hand_start_idx, hand_end_idx - hand start index and hand end index, from degree_process_file()
folder_path = path to save figures
saveGraph = if True, save figures in folder_path

Output:
3x4 plot of joint angles
Row 1: Thumb01x, Thumb01y, Thumb01z, Combined (Thumb01 xyz)
Row 2: Index01x, Index01y, Index01z, Combined (Index01 xyz)
Row 3: Index02x, Index02y, Index02z, Combined (Index02 xyz)
Also prints a line with hand_start_idx, force_start_idx, force_end_idx, hand_end_idx
"""

def plot_joint_angles(task, df, hand_start_idx, hand_end_idx, folder_path, saveGraph):
    print(f"{title}")
    fig, axs = plt.subplots(3, 4, figsize=(15, 8))
    colors2 = plt.colormaps['Set1']

    time_hand = df.iloc[:, 0].values
    thumb_data = {col: df[col].values for col in thumb_columns if col in df.columns}
    index01_data = {col: df[col].values for col in index01_columns if col in df.columns}
    index02_data = {col: df[col].values for col in index02_columns if col in df.columns}

    #Plot hand angle data
    plot_hand_angle_data_for_3x4(axs[0], thumb_data, time_hand, 'Thumb01')
    plot_hand_angle_data_for_3x4(axs[1], index01_data, time_hand, 'Index01')
    plot_hand_angle_data_for_3x4(axs[2], index02_data, time_hand, 'Index02')

    present_labels = [col for col in df.columns if col in sensor_labels]
    sensor_data = {col: df[col].values for col in present_labels}
    curr_task_sensors = task_sensor.get(task, [])
    df.columns = [col.strip() for col in df.columns]

    #Overlay force data
    for (i, ax) in enumerate(axs.flat):
        color = "black"
        ax4 = ax.twinx()
        ax4.get_yaxis().set_visible(False)
        ax4.spines['right'].set_visible(False)
        if task == "Hookgrasp":
          sensor_values = df['hook'].values
          force_start_idx, force_end_idx = plot_force_data_find_trim(sensor_values, time_hand, ax4, title, file_group)
        if task == "Thumbadduction":
          sensor_values = df['paper'].values
          force_start_idx, force_end_idx = plot_force_data_find_trim(sensor_values, time_hand, ax4, title, file_group)
        if task == "Sphericalgrasp":
          spherical_sensors = [col for col in df.columns if 'sphere' in col]
          force_start_idx, force_end_idx = plot_sum_data_find_trim(spherical_sensors, time_hand, 'sphereSum', df, ax4, title, file_group)
        if task == "Cylindricalgrasp":
          force_start_idx, force_end_idx = plot_sum_data_find_trim(cylindrical_sensors, time_hand, 'cylSum', df, ax4, title, file_group)
        if task == "Pincergrasp":
          force_start_idx, force_end_idx = plot_sum_data_find_trim(pencil_sensors, time_hand, 'pencilSum', df, ax4, title, file_group)

        ax.axvline(x=time_hand[hand_start_idx], color="purple", linestyle = "dotted")
        ax.axvline(x=time_hand[hand_end_idx], color="purple", linestyle = "dotted")
        ax.axvline(x=time_hand[force_start_idx], color="black", linestyle = "dotted")
        ax.axvline(x=time_hand[force_end_idx], color="black", linestyle = "dotted")

    print(f'HS: {hand_start_idx}, {time_hand[hand_start_idx]}s\
            FS: {force_start_idx}, {time_hand[force_start_idx]}s --- FE: {force_end_idx}, {time_hand[force_end_idx]}s\
            HE: {hand_end_idx}, {time_hand[hand_end_idx]}s')

    fig.tight_layout()
    figure_path = os.path.join(folder_path, f'{title}_3x4_angles.png')
    if saveGraph: plt.savefig(figure_path)


def plot_joint_distances(task, df, hand_start_idx, hand_end_idx, folder_path, saveGraph):
    fig, axs = plt.subplots(4, 3, figsize=(15, 10))
    colors2 = plt.colormaps['Set1']

    time_hand = df.iloc[:, 0].values
    present_labels = [col for col in df.columns if col.strip() in sensor_labels]
    sensor_data = {col: df[col].values for col in present_labels}
    curr_task_sensors = task_sensor.get(task, [])
    df.columns = [col.strip() for col in df.columns]

    for row_idx, joint_triple in enumerate(joint_dist_col_triples):
        col1, col2, col3 = joint_triple

        # Compute distances
        dist_joint1_joint2 = joint_dist_2(col1, col2, df)
        dist_joint1_joint3 = joint_dist_2(col1, col3, df)
        ratio = dist_joint1_joint2 / dist_joint1_joint3

        # Plot distance / ratio data
        values_list = [dist_joint1_joint2, dist_joint1_joint3, ratio]
        for col_idx, values in enumerate(values_list):
            hand_sensor_values = smooth_normalise(values)
            axs[row_idx, col_idx].plot(time_hand, hand_sensor_values, color=colors2(col_idx))
            axs[row_idx, col_idx].set_title(f'{joint_dist_titles[row_idx][col_idx]}', fontsize=8)

    #Overlay force data
    for (i, ax) in enumerate(axs.flat):
        color = "black"
        ax4 = ax.twinx()
        ax4.get_yaxis().set_visible(False)
        ax4.spines['right'].set_visible(False)
        if task == "Hookgrasp":
          sensor_values = df['hook'].values
          force_start_idx, force_end_idx = plot_force_data_find_trim(sensor_values, time_hand, ax4, title, file_group)
        if task == "Thumbadduction":
          sensor_values = df['paper'].values
          force_start_idx, force_end_idx = plot_force_data_find_trim(sensor_values, time_hand, ax4, title, file_group)
        if task == "Sphericalgrasp":
          spherical_sensors = [col for col in df.columns if 'sphere' in col]
          force_start_idx, force_end_idx = plot_sum_data_find_trim(spherical_sensors, time_hand, 'sphereSum', df, ax4, title, file_group)
        if task == "Cylindricalgrasp":
          force_start_idx, force_end_idx = plot_sum_data_find_trim(cylindrical_sensors, time_hand, 'cylSum', df, ax4, title, file_group)
        if task == "Pincergrasp":
          force_start_idx, force_end_idx = plot_sum_data_find_trim(pencil_sensors, time_hand, 'pencilSum', df, ax4, title, file_group)

        ax.axvline(x=time_hand[hand_start_idx], color="purple", linestyle = "dotted")
        ax.axvline(x=time_hand[hand_end_idx], color="purple", linestyle = "dotted")
        ax.axvline(x=time_hand[force_start_idx], color="black", linestyle = "dotted")
        ax.axvline(x=time_hand[force_end_idx], color="black", linestyle = "dotted")

    # print(f'hand: {hand_start_idx}, {time_hand[hand_start_idx]}s ---  start: {force_start_idx}, {time_hand[force_start_idx]}s --- end: {force_end_idx}, {time_hand[force_end_idx]}s')

    has_labels = any(line.get_label()[0] != '_' for line in ax4.get_lines())
    if i % 3 == 2:
        if has_labels: ax4.legend(fontsize=8)
    for ax in axs.flat:
        ax.set(xlabel='time_hand')
        ax.tick_params(axis='both', labelsize=8)

    fig.tight_layout()
    figure_path = os.path.join(folder_path, f'{title}_4x3_dist_ratio.png')
    if saveGraph: plt.savefig(figure_path)


def plot_hand_angle_data_for_3x4(ax, data, time_hand, title_prefix):
    ylims = []
    for i, (col, values) in enumerate(data.items()):
        angle_data = smooth_normalise(values)
        ax[i].plot(time_hand, angle_data, color=colors2(i))
        ax[i].set_title(f'{col}', fontsize=8)
        ylims.append(ax[i].get_ylim())
        ax[3].plot(time_hand, angle_data, color=colors2(i))
    ax[3].set_title(f'{title_prefix} xyz', fontsize=8)

    if ylims:
        min_ylim, max_ylim = min(yl[0] for yl in ylims), max(yl[1] for yl in ylims)
        for i in range(4): ax[i].set_ylim(min_ylim, max_ylim)
    for i in range(4):
        ax[i].set_xlabel('time_hand', fontsize=6)
        ax[i].tick_params(axis='both', labelsize=8)


# Plot force data AND returns start/end idx
def plot_force_data_find_trim(sensor_values, time_hand, ax, title, file_group):
    ax.plot(time_hand, sensor_values, color="black", alpha = 0.8)
    start_idx, end_idx = find_trim_indices_list_noprint(sensor_values, time_hand, file_group, file_path)
    return start_idx, end_idx

#Plots sum data AND returns start/end idx
def plot_sum_data_find_trim(sensors_norm, time_hand, label, df, ax, title, file_group):
    sum_data = np.zeros_like(time_hand)
    for sensor in sensors_norm:
        if sensor in df.columns:
            adjusted_sensor_values = df[sensor].values
            min_length = min(len(sum_data), len(adjusted_sensor_values))
            if min_length != len(time_hand): print('**Error: length mismatch for sum data') # Handle potential length mismatches
            sum_data[:min_length] += adjusted_sensor_values[:min_length]  # Add up to the shorter length
    ax.plot(time_hand, sum_data, color='black', alpha = 0.8)

    sum_start_idx, sum_end_idx = find_trim_indices_list_noprint(sum_data, time_hand, file_group, file_path)
    return sum_start_idx, sum_end_idx




# Section 2: Force Sensor Overview, by trial

# Plot ALL force sensors; Gradient, sec dev, trim lines, (and sum) for relevant sensors for that task
def force_sensor_overview_plots(subject_score_x_force_only, file_group, showLegend, saveGraph):
    num_rows = (len(subject_score_x_force_only) + 3) // 4
    if len(subject_score_x_force_only) % 4 == 0: num_rows += 1
    fig, axs = plt.subplots(num_rows, 4, figsize=(20, num_rows * 4))

    # Iterate over files (trials)
    for i, (title, file_path) in enumerate(subject_score_x_force_only.items()):
        df = pd.read_csv(file_path)
        task = get_task_name(title, task_names)
        if task != "Sphericalgrasp": continue

        row = i // 4
        column = i % 4

        df.columns = [col.strip() for col in df.columns]
        time_hand = df.iloc[:, 0].values
        led = df['led'].values

        present_labels = [col for col in df.columns if col.strip() in sensor_labels]
        sensor_data = {col: df[col].values for col in present_labels}
        current_task_sensors = task_sensor.get(task, [])
        final_start_idx = 0
        final_end_idx = len(time_hand)-1
        first_sensor_alr_plotted = False

        if task == "Sphericalgrasp":
          spherical_sensors = [col for col in df.columns if 'sphere' in col]
          final_start_idx, final_end_idx = plot_sum_data(spherical_sensors, time_hand, 'sphereSum', df, axs[row, column], title, file_group, file_path)
        if task == "Cylindricalgrasp":
          final_start_idx, final_end_idx = plot_sum_data(cylindrical_sensors, time_hand, 'cylSum', df, axs[row, column], title, file_group, file_path)
        if task == "Pincergrasp":
          final_start_idx, final_end_idx = plot_sum_data(pencil_sensors, time_hand, 'pencilSum', df, axs[row, column], title, file_group, file_path)
        if task == "Sphericalgrasp" or task == "Cylindricalgrasp" or task == "Pincergrasp":
            first_sensor_alr_plotted = True

        for j, col in enumerate(sensor_data):
            color = sensor_colors(j)
            sensor_values = df[col].values
            axs[row, column].scatter(time_hand, sensor_values, color=color, label=col, s=5)

            if col not in current_task_sensors: continue

            if not first_sensor_alr_plotted:
                plot_grad_sec_dev(axs[row, column], title, sensor_values, color, time_hand)
                first_sensor_alr_plotted = True
            # else:  plot_grad_sec_dev_hide_axis(axs[row, column], title, sensor_values, color, time_hand)
            start_idx, end_idx = plot_trim_lines(axs[row, column], title, sensor_values, color, time_hand, file_group, file_path)
            if task == "Hookgrasp" or task == "Thumbadduction":
                final_start_idx, final_end_idx = start_idx, end_idx

        axs[row, column].scatter(time_hand, led, color='red', s=3, label='LED')
        axs[row, column].set_title(f'{title}')
        if showLegend == True:
          axs[row, column].legend()

        print(f'{title} --- start: {final_start_idx}, {time_hand[final_start_idx]}s --- end: {final_end_idx}, {time_hand[final_end_idx]}s')
        file_name = os.path.basename(file_path)
        print(f'--> {file_name}')
        axs[row, column].set_axisbelow(False)
        axs[row, column].axvline(x=time_hand[final_start_idx], color="black")
        axs[row, column].axvline(x=time_hand[final_end_idx], color="black")

    for ax in axs.flat:
        ax.set(xlabel='Time', ylabel='Value')
        ax.axhline(y=1030, color="white", alpha=0.0)
        for line in ax.get_lines():
            if line.get_color() == "black": line.set_zorder(100)

    # Plot an empty graph with legend
    axs[num_rows - 1, 3].axis('off')
    handles, labels = axs[0, 0].get_legend_handles_labels()
    legend = axs[num_rows - 1, 3].legend(handles, labels, loc='center')
    for handle in legend.legend_handles:
        handle.set_sizes([30])

    fig.tight_layout()
    if saveGraph:
      file_path = os.path.join(output_folder_path, f'{file_group}_force_overview.png') # Use os.path.join to create file paths
      plt.savefig(file_path)
    plt.show()


#Plot dashed line for gradient, dotted line for second derivative (with axis, for first plot)
def plot_grad_sec_dev(ax, title, sensor_values, color, time_hand):
    gradient = np.gradient(sensor_values, time_hand)
    second_dev = np.gradient(gradient, time_hand)

    ax2 = ax.twinx()
    ax3 = ax.twinx()
    ax2.tick_params(axis='both', labelsize=8)
    ax3.get_yaxis().set_visible(False)
    ax3.spines['right'].set_visible(False)

    ax2.plot(time_hand,gradient, linestyle="dashed", color=color, alpha = 0.6, linewidth = 1)
    ax3.plot(time_hand, second_dev, linestyle=":", color=color, alpha = 0.2, linewidth = 1)


# See above, but without axis, for subsequent plots
def plot_grad_sec_dev_hide_axis(ax, title, sensor_values, color, time_hand):
    gradient = np.gradient(sensor_values, time_hand)
    second_dev = np.gradient(gradient, time_hand)

    ax2 = ax.twinx()
    ax3 = ax.twinx()
    ax2.get_yaxis().set_visible(False)
    ax2.spines['right'].set_visible(False)
    ax3.get_yaxis().set_visible(False)
    ax3.spines['right'].set_visible(False)

    ax2.plot(time_hand,gradient, linestyle="dashed", color=color, alpha = 0.6, linewidth = 1)
    ax3.plot(time_hand, second_dev, linestyle=":", color=color, alpha = 0.2, linewidth = 1)


# Plots sum data, grad, sec dev, trim lines AND returns start/end idx
def plot_sum_data(sensors_norm, time_hand, label, df, ax, title, file_group, file_path):
    sum_data = np.zeros_like(time_hand)
    for sensor in sensors_norm:
        if sensor in df.columns:
            adjusted_sensor_values = df[sensor].values
            min_length = min(len(sum_data), len(adjusted_sensor_values))
            if min_length != len(time_hand): print('**Error: length mismatch for sum data') # Handle potential length mismatches
            sum_data[:min_length] += adjusted_sensor_values[:min_length]  # Add up to the shorter length
    ax.scatter(time_hand, sum_data, color='black', s=3, label=label)

    plot_grad_sec_dev(ax, title, sum_data, 'black', time_hand)
    sum_start_idx, sum_end_idx = plot_trim_lines(ax, title, sum_data, 'black', time_hand, file_group, file_path)
    return sum_start_idx, sum_end_idx


def plot_trim_lines(ax, title, sensor_values, color, time_hand, file_group, file_path):
    start_idx, end_idx = find_trim_indices_list_noprint(sensor_values, time_hand, file_group, file_path)
    ax.axvline(x=time_hand[start_idx], color=color, linestyle="--")
    ax.axvline(x=time_hand[end_idx], color=color, linestyle="--")

    return start_idx, end_idx

def plot_hline_avg_max_value(axs, sensor):
    if loadTendencyData:
        avg_score_two_max_value = np.mean(list(score_two_max_values[sensor].values()))
        axs.hlines(avg_score_two_max_value, 0, 10, linestyles='dashed', alpha = 0.5, colors='black')


# Section 2: Force Sensor TSI (all trials in one plot, compare file groups)

interpolated_duration = 2         # in seconds
interpolated_step = 0.01          # in seconds

# Plots data for one sensors, Trim Scale Interpolate
def plot_combined_force_tsi(files, ax, sensor, curr_task_sensors):
    color = sensor_colors(sensor_labels.index(sensor))
    for file_no, (title, file_path) in enumerate(files):
        df = pd.read_csv(file_path)
        time_hand = df.iloc[:, 0].values

        df.columns = [col.strip() for col in df.columns]
        present_labels = [col for col in df.columns if col in sensor_labels]
        all_sensor_data = {col: df[col].values for col in present_labels}
        sensor_values = df[sensor].values

        force_start_idx, force_end_idx, force_sensor_values = find_trim_idx_force(all_sensor_data, curr_task_sensors, task, time_hand, df, file_group)

        # Trim
        trimmed_data = sensor_values[force_start_idx:force_end_idx]
        trimmed_time = time_hand[force_start_idx:force_end_idx]
        trimmed_time = trimmed_time - trimmed_time[0]

        # scale
        scale_factor = interpolated_duration / max(trimmed_time)
        scaled_time = [scale_factor * t for t in trimmed_time]

        # Interpolate
        interpolated_time = np.linspace(0, interpolated_duration, num=int(interpolated_duration / interpolated_step) + 1)
        interpolated_data = np.interp(interpolated_time, scaled_time, trimmed_data)

        ax.plot(trimmed_time, trimmed_data, color=color, alpha=0.6, linestyle=':')
        ax.plot(interpolated_time, interpolated_data, alpha=0.9, color=color)

        if "unaff" in file_group:
            wh_or_woh = find_wh_or_woh(file_group)
            if wh_or_woh not in unaff_max_values: unaff_max_values[wh_or_woh] = {}
            if sensor not in unaff_max_values[wh_or_woh]: unaff_max_values[wh_or_woh][sensor] = {}
            unaff_max_values[wh_or_woh][sensor][file_no] = max(interpolated_data)

        if "score_two" in file_group:
            if sensor not in score_two_max_values: score_two_max_values[sensor] = {}
            score_two_max_values[sensor][file_no] = max(interpolated_data)

    ax.set(xlabel='Time')
    ax.set_ylim(0, 1030)

# Plots sum data of all sensors for that task, Trim Scale Interpolate
def plot_sum_data_tsi(files, sum_sensors, ax, label):
    for file_no, (title, file_path) in enumerate(files):
        df = pd.read_csv(file_path)
        time_hand = df.iloc[:, 0].values

        df.columns = [col.strip() for col in df.columns]

        sum_data = np.zeros_like(time_hand)
        for sensor in sum_sensors:
            if sensor in df.columns:
                adjusted_sensor_values = df[sensor].values
                sum_data += adjusted_sensor_values
        start_idx, end_idx = find_trim_indices_list_noprint( sum_data, time_hand, file_group, file_path)

        trimmed_data = sum_data[start_idx:end_idx]
        trimmed_time = time_hand[start_idx:end_idx]
        trimmed_time = trimmed_time - trimmed_time[0]

        scale_factor = interpolated_duration / max(trimmed_time)
        scaled_time = [scale_factor * t for t in trimmed_time]

        interpolated_time = np.linspace(0, interpolated_duration, num=int(interpolated_duration / interpolated_step) + 1)
        interpolated_data = np.interp(interpolated_time, scaled_time, trimmed_data)

        sensor = f'{task}Sum'
        if "unaff" in file_group:
            wh_or_woh = find_wh_or_woh(file_group)
            if wh_or_woh not in unaff_max_values: unaff_max_values[wh_or_woh] = {}
            if sensor not in unaff_max_values[wh_or_woh]: unaff_max_values[wh_or_woh][sensor] = {}
            unaff_max_values[wh_or_woh][sensor][file_no] = max(interpolated_data)

        if "score_two" in file_group:
            if sensor not in score_two_max_values: score_two_max_values[sensor] = {}
            score_two_max_values[sensor][file_no] = max(interpolated_data)

        ax.plot(trimmed_time, trimmed_data, color='black', alpha=0.6, linestyle=':')
        ax.plot(interpolated_time, interpolated_data, alpha=0.9, color='black')
    ax.set(xlabel='Time')

# normalize aff using unaff
def plot_combined_force_tsi_norm(files, ax, sensor, curr_task_sensors):
    color = sensor_colors(sensor_labels.index(sensor))
    for file_no, (title, file_path) in enumerate(files):
        df = pd.read_csv(file_path)
        time_hand = df.iloc[:, 0].values

        df.columns = [col.strip() for col in df.columns]
        present_labels = [col for col in df.columns if col in sensor_labels]
        all_sensor_data = {col: df[col].values for col in present_labels}
        sensor_values = df[sensor].values

        force_start_idx, force_end_idx, force_sensor_values = find_trim_idx_force(all_sensor_data, curr_task_sensors, task, time_hand, df, file_group)

        # Trim
        trimmed_data = sensor_values[force_start_idx:force_end_idx]
        trimmed_time = time_hand[force_start_idx:force_end_idx]
        trimmed_time = trimmed_time - trimmed_time[0]

        # scale
        scale_factor = interpolated_duration / max(trimmed_time)
        scaled_time = [scale_factor * t for t in trimmed_time]

        # Interpolate
        interpolated_time = np.linspace(0, interpolated_duration, num=int(interpolated_duration / interpolated_step) + 1)
        interpolated_data = np.interp(interpolated_time, scaled_time, trimmed_data)

        #Normalize with unaff
        if loadExperimentData:
            wh_or_woh = find_wh_or_woh(file_group)
            avg_unaff_max_value = np.mean(list(unaff_max_values[wh_or_woh][sensor].values()))
            trimmed_data = trimmed_data / avg_unaff_max_value * 100
            interpolated_data = interpolated_data / avg_unaff_max_value * 100

        if loadTendencyData:
           avg_score_two_max_value = np.mean(list(score_two_max_values[sensor].values()))
           trimmed_data = trimmed_data / avg_score_two_max_value * 100
           interpolated_data = interpolated_data / avg_score_two_max_value * 100

        ax.plot(trimmed_time, trimmed_data, color=color, alpha=0.6, linestyle=':')
        ax.plot(interpolated_time, interpolated_data, alpha=0.9, color=color)

    ax.set(xlabel='Time')
    ax.set_ylim(0, 120)

# Plots sum data of all sensors for that task, Trim Scale Interpolate, normalize aff using unaff
def plot_sum_data_tsi_norm(files, sum_sensors, ax, label):
    for file_no, (title, file_path) in enumerate(files):
        df = pd.read_csv(file_path)
        df.columns = [col.strip() for col in df.columns]

        time_hand = df.iloc[:, 0].values
        sum_data = np.zeros_like(time_hand)
        for sensor in sum_sensors:
            if sensor in df.columns:
                adjusted_sensor_values = df[sensor].values
                sum_data += adjusted_sensor_values
        start_idx, end_idx = find_trim_indices_list_noprint(sum_data, time_hand, file_group, file_path)

        trimmed_data = sum_data[start_idx:end_idx]
        trimmed_time = time_hand[start_idx:end_idx]
        trimmed_time = trimmed_time - trimmed_time[0]

        scale_factor = interpolated_duration / max(trimmed_time)
        scaled_time = [scale_factor * t for t in trimmed_time]

        interpolated_time = np.linspace(0, interpolated_duration, num=int(interpolated_duration / interpolated_step) + 1)
        interpolated_data = np.interp(interpolated_time, scaled_time, trimmed_data)


        #Normalize with unaff
        sensor = f'{task}Sum'
        if loadExperimentData:
            wh_or_woh = find_wh_or_woh(file_group)
            avg_unaff_max_value = np.mean(list(unaff_max_values[wh_or_woh][sensor].values()))
            trimmed_data = trimmed_data / avg_unaff_max_value * 100
            interpolated_data = interpolated_data / avg_unaff_max_value * 100
        if loadTendencyData:
            avg_score_two_max_value = np.mean(list(score_two_max_values[sensor].values()))
            trimmed_data = trimmed_data / avg_score_two_max_value * 100
            interpolated_data = interpolated_data / avg_score_two_max_value * 100

        ax.plot(trimmed_time, trimmed_data, color='black', alpha=0.6, linestyle=':')
        ax.plot(interpolated_time, interpolated_data, alpha=0.9, color='black')

    ax.set(xlabel='Time')
    ax.set_ylim(0, 120)


def find_wh_or_woh(file_group):
    if "wh" in file_group: return "wh"
    elif "woh" in file_group: return "woh"
    else: return None

### OVERALL TRIMMING FUNCTIONS FOR FORCE SENSOR ------------------------------------------------------------------------------------------------
threshold_percentage = 0.2                  # list of trim indices above cut-off for second derivative (percentage of max second dev)
force_cutoff = 100                          # if force data       all below cutoff, force_start = 0, force_end = end
force_sec_dev_cutoff = 100                  # if sec dev of force all below cutoff, force_start = 0, force_end = end

def find_trim_idx_force(sensor_data, curr_task_sensors, task, time_hand, df, file_group):
    force_start_idx = 0
    force_end_idx = len(time_hand)-1
    returnData = True                     # default always return full data
    force_data = None

    if task == "Hookgrasp":
        force_data = df['hook'].values
        force_start_idx, force_end_idx = find_trim_indices_list_noprint(force_data, time_hand, file_group, file_path)
    if task == "Thumbadduction":
        force_data = df['paper'].values
        force_start_idx, force_end_idx = find_trim_indices_list_noprint(force_data, time_hand, file_group, file_path)
    if task == "Sphericalgrasp":
        spherical_sensors = [col for col in df.columns if 'sphere' in col]
        force_start_idx, force_end_idx, force_data = sum_find_trim_indices_list_noprint(spherical_sensors, time_hand, df, file_group, file_path, returnData)
    if task == "Cylindricalgrasp":
        force_start_idx, force_end_idx, force_data = sum_find_trim_indices_list_noprint(cylindrical_sensors, time_hand, df, file_group, file_path, returnData)
    if task == "Pincergrasp":
        force_start_idx, force_end_idx, force_data = sum_find_trim_indices_list_noprint(pencil_sensors, time_hand, df, file_group, file_path, returnData)

    if returnData: return force_start_idx, force_end_idx, force_data


def find_trim_indices_list(sensor_values, time_hand, file_group, file_path):
    gradient = np.gradient(sensor_values, time_hand)
    second_dev = np.gradient(gradient, time_hand)
    data_array = np.array(second_dev)
    above_threshold = threshold_percentage * max(abs(max(second_dev)), abs(min(second_dev)))
    below_threshold = -above_threshold

    start_gap = file_group_gap[file_group][0]
    end_gap = file_group_gap[file_group][1]

    # Generate a list of possible start and end indices above the second derivative threshold
    start_indices = np.where(data_array > above_threshold)[0] + 1
    end_indices = len(data_array) - np.where(data_array[::-1] < below_threshold)[0] + 1

    # Only consider start indices after search_start_index (set in "Force Trim: Manually adjust start point")
    if subjectID_full in force_trim_search_start_list:
      file_name = os.path.basename(file_path)
      for file_info in force_trim_search_start_list[subjectID_full]:
          if file_name == file_info[0]:
              search_start_time = float(file_info[1])
              search_start_idx = np.argmin(np.abs(time_hand - search_start_time))
              start_indices = start_indices[start_indices >= search_start_idx]

    # Loop through start_indices, validate using check_start
    for start_idx in start_indices:
        valid_start_idx = check_start(start_idx, sensor_values)
        if valid_start_idx is not None: break
    else: valid_start_idx = 0

    # Loop through end_indices in reverse order, validate using check_end
    for end_idx in end_indices:
        valid_end_idx = check_end(end_idx, sensor_values)
        if valid_end_idx is not None: break
    else: valid_end_idx = len(data_array)-1

    # Special cases: Ignore force trimming
    if all(sensor_values < force_cutoff): valid_start_idx, valid_end_idx = 0, len(data_array)-1
    if all(second_dev < force_sec_dev_cutoff): valid_start_idx, valid_end_idx = 0, len(data_array)-1
    if subjectID_full in force_trim_off_list:
        file_name = os.path.basename(file_path)
        if file_name in force_trim_off_list[subjectID_full]: valid_start_idx, valid_end_idx = 0, len(data_array)-1

    return valid_start_idx, valid_end_idx

# See above, but w/o print statements (that were hidden in called functions)
def find_trim_indices_list_noprint(sensor_values, time_hand, file_group, file_path):
    gradient = np.gradient(sensor_values, time_hand)
    second_dev = np.gradient(gradient, time_hand)
    data_array = np.array(second_dev)
    above_threshold = threshold_percentage * max(abs(max(second_dev)), abs(min(second_dev)))
    below_threshold = -above_threshold

    start_gap = file_group_gap[file_group][0]
    end_gap = file_group_gap[file_group][1]

    start_indices = np.where(data_array > above_threshold)[0] + 1
    end_indices = len(data_array) - np.where(data_array[::-1] < below_threshold)[0] + 1

    if subjectID_full in force_trim_search_start_list:
      file_name = os.path.basename(file_path)
      for file_info in force_trim_search_start_list[subjectID_full]:
          if file_name == file_info[0]:
              search_start_time = float(file_info[1])
              search_start_idx = np.argmin(np.abs(time_hand - search_start_time))
              start_indices = start_indices[start_indices >= search_start_idx]

    for start_idx in start_indices:
        valid_start_idx = check_start_noprint(start_idx, sensor_values, start_gap)
        if valid_start_idx is not None: break
    else: valid_start_idx = 0

    for end_idx in end_indices:
        valid_end_idx = check_end_noprint(end_idx, sensor_values, end_gap)
        if valid_end_idx is not None: break
    else: valid_end_idx = len(data_array)-1

    if all(sensor_values < force_cutoff): valid_start_idx, valid_end_idx = 0, len(data_array)-1
    if all(second_dev < force_sec_dev_cutoff): valid_start_idx, valid_end_idx = 0, len(data_array)-1
    if subjectID_full in force_trim_off_list:
        file_name = os.path.basename(file_path)
        if file_name in force_trim_off_list[subjectID_full]: valid_start_idx, valid_end_idx = 0, len(data_array)-1

    return valid_start_idx, valid_end_idx

def sum_find_trim_indices_list_noprint(sensors, time_hand, df, file_group, file_path, returnSumData):
    sum_data = np.zeros_like(time_hand)
    # print(list(df.columns))
    for sensor in sensors:
        adjusted_sensor_values = df[sensor].values
        sum_data += adjusted_sensor_values
    start_idx, end_idx = find_trim_indices_list_noprint(sum_data, time_hand, file_group, file_path)
    if np.all(sum_data == 0): print(f'No sum data')
    if returnSumData: return start_idx, end_idx, sum_data
    else: return start_idx, end_idx

start_threshold = 0.1           # diff at start must be > 10% of maximum force value
end_threshold = 0.1             # diff at end   must be > 10% of maximum force value


# General logic:
# 1. Collate 30 (defined as gap) datapoints before and after
# 2. Find the average of these datapoints (prev_avg and next_avg)
# 3. Calculate difference between prev_avg and next_avg
# 4. Check if difference > than 10% of max value   (i.e. large enough increase / drop)

def check_start(start_idx, values, start_gap):
    threshold = start_threshold * max(values)
    if start_idx >= start_gap and (start_idx + start_gap) < len(values):
        prev_avg = int(sum(values[start_idx - start_gap:start_idx]) / start_gap)
        next_avg = int((sum(values[start_idx + 1:start_idx + 1 + start_gap])) / start_gap)
        print(f'{start_idx} start: {prev_avg}, {values[start_idx]} ,{next_avg}')

        diff_start = next_avg - prev_avg
        if diff_start > threshold:
            final_start_idx = start_idx
            return final_start_idx
        else : return None

def check_end(end_idx, values, end_gap):
    threshold = end_threshold * max(values)
    if end_idx >= end_gap and (end_idx + end_gap) < len(values):
        prev_avg = int(sum(values[end_idx - end_gap:end_idx]) / end_gap)
        next_avg = int((sum(values[end_idx + 1:end_idx + 1 + end_gap])) / end_gap)
        print(f'{end_idx} end: {prev_avg}, {values[end_idx]} ,{next_avg}')

        diff_end = next_avg - prev_avg
        if abs(diff_end) > threshold :
            final_end_idx = end_idx
            return final_end_idx
        else : return None

def check_start_noprint(start_idx, values, start_gap):
    threshold = start_threshold * max(values)
    if start_idx >= start_gap and (start_idx + start_gap) < len(values):
        prev_avg = int(sum(values[start_idx - start_gap:start_idx]) / start_gap)
        next_avg = int((sum(values[start_idx + 1:start_idx + 1 + start_gap])) / start_gap)

        diff_start = next_avg - prev_avg
        if diff_start > threshold:
            final_start_idx = start_idx
            return final_start_idx
        else : return None

def check_end_noprint(end_idx, values, end_gap):
    threshold = end_threshold * max(values)
    if end_idx >= end_gap and (end_idx + end_gap) < len(values):
        prev_avg = int(sum(values[end_idx - end_gap:end_idx]) / end_gap)
        next_avg = int((sum(values[end_idx + 1:end_idx + 1 + end_gap])) / end_gap)

        diff_end = next_avg - prev_avg
        if abs(diff_end) > threshold :
            final_end_idx = end_idx
            return final_end_idx
        else :  return None

# ----------------------------------------------------------------


# Section 4: Hand & Force TSI - trim scale interpolate

force_start_idx_error_global = {}                # if force_start_index = 0  (i.e. untrimmed, usually score zero)
hand_start_before_force_error_global = {}        # if hand_start_index is before force_start_index



def plot_combined_angle_tsi(axs_a, axs_b, title, file_path, file_grp_no, file_group, file_no, ylims_array, hand_trim_indices):
    color_map = plt.get_cmap('Set1')
    global force_start_idx_error_global
    global hand_start_before_force_error_global
    indices_printed = False
    has_force = check_if_force(task)

    df = pd.read_csv(file_path)
    time_hand = df.iloc[:, 0].values
    df.columns = [col.strip() for col in df.columns]
    present_labels = [col for col in df.columns if col in sensor_labels]
    sensor_data = {col: df[col].values for col in present_labels}
    angle_data = {col: df[col].values for col in angle_columns if col in df.columns}
    curr_task_sensors = task_sensor.get(task, [])
    hand_start_idx, hand_end_idx = hand_trim_indices

    df_norm = normalized_dfs[os.path.basename(file_path)]
    angle_data_norm = {col: df_norm[col].values for col in angle_columns if col in df_norm.columns}

    for row_idx, df_col_name in enumerate(angle_columns):
        df_col_name = df_col_name.strip()
        hand_sensor_values = smooth_normalise(angle_data.get(df_col_name, []))
        # flip_or_not_flip(hand_sensor_values)
        hand_sensor_values_norm = angle_data_norm.get(df_col_name, [])
        force_start_idx, force_end_idx, force_sensor_values = find_trim_idx_force(sensor_data, curr_task_sensors, task, time_hand, df, file_group)
        color = color_map(file_no)

        if not indices_printed:
              print(f'{title}: {time_hand[hand_start_idx]}s, {time_hand[force_start_idx]}s, {time_hand[force_end_idx]}s, {time_hand[hand_end_idx]}s')
              indices_printed = True

        if has_force == True:
            tsi_force_seg1_zero_seg2(force_sensor_values, force_start_idx, force_end_idx, time_hand, axs_b[row_idx, file_grp_no], color, file_no, plotGraph = True)

            if hand_start_idx >= force_end_idx: force_end_idx = hand_end_idx  # when hand_start is after force_end

            trimmed_data = hand_sensor_values[hand_start_idx:force_end_idx]
            trimmed_time = time_hand[hand_start_idx:force_end_idx]
            trimmed_data = trimmed_data - trimmed_data[0]
            trimmed_time = trimmed_time - trimmed_time[0]

            if hand_start_idx < force_start_idx: #NORMAL CASE
                hand_tsi_data = tsi_hand_seg1_seg2(hand_sensor_values, hand_start_idx, force_start_idx, force_end_idx, time_hand, color, file_no, df_col_name)
                hand_tsi_data_norm = tsi_hand_seg1_seg2(hand_sensor_values_norm, hand_start_idx, force_start_idx, force_end_idx, time_hand, color, file_no, df_col_name)

            elif force_start_idx == 0:
                hand_tsi_data = tsi_hand_seg1_full_seg2_const(hand_sensor_values, hand_start_idx, force_end_idx, time_hand, color, file_no, df_col_name)
                hand_tsi_data_norm = tsi_hand_seg1_full_seg2_const(hand_sensor_values_norm, hand_start_idx, force_end_idx, time_hand, color, file_no, df_col_name)
                if (file_group, title) not in force_start_idx_error_global:
                    print(f'{file_group} {title} ** ERROR : force_start_idx is 0')
                    force_start_idx_error_global[(file_group, title)] = True

            elif hand_start_idx > force_start_idx:
              if (file_group, title) not in hand_start_before_force_error_global:
                    print(f'{file_group} {title} ** ERROR : hand_start_idx GREATER THAN force_start_idx')
                    hand_start_before_force_error_global[(file_group, title)] = True

            ylims_array[row_idx, file_grp_no, 2] = min(ylims_array[row_idx, file_grp_no, 2], np.min(force_sensor_values))
            ylims_array[row_idx, file_grp_no, 3] = max(ylims_array[row_idx, file_grp_no, 3], np.max(force_sensor_values))

        if has_force == False:
            #Trim w/o scale or interpolate (dotted line)
            trimmed_data = hand_sensor_values[hand_start_idx:force_end_idx]
            trimmed_data = trimmed_data - trimmed_data[0]
            trimmed_time = time_hand[hand_start_idx:force_end_idx]
            if trimmed_time.size > 0: trimmed_time = trimmed_time - trimmed_time[0]

            hand_tsi_data = tsi_hand_combined_seg1and2(hand_sensor_values, hand_start_idx, hand_end_idx, time_hand, color, file_no, df_col_name)
            hand_tsi_data_norm = tsi_hand_combined_seg1and2(hand_sensor_values_norm, hand_start_idx, hand_end_idx, time_hand, color, file_no, df_col_name)

        df_new[f'{df_col_name}'] = hand_tsi_data
        df_new[f'{df_col_name}_Norm'] = hand_tsi_data_norm

        if df_col_name in thumb_columns: df_new['abs_sum_thumb_xyz'] = df_new['abs_sum_thumb_xyz'] + np.abs(hand_tsi_data)
        if df_col_name in chosen_index01_columns: df_new['abs_sum_index01_yz'] = df_new['abs_sum_index01_yz'] + np.abs(hand_tsi_data)
        if df_col_name in nonredundant_degree_cols: df_new['abs_sum_deg'] = df_new['abs_sum_deg'] + np.abs(hand_tsi_data)

        hand_tsi_time = np.linspace(0, hand_tsi_interp_tot_duration, num=hand_tsi_num_elements)
        if plotNorm:
            axs_a[row_idx, file_grp_no].plot(hand_tsi_time, hand_tsi_data_norm, alpha=0.9, color=color, label=f'Trial {file_no+1} hand')
            ylims_array[row_idx, file_grp_no, 0] = min(ylims_array[row_idx, file_grp_no, 0], np.min(hand_tsi_data_norm))
            ylims_array[row_idx, file_grp_no, 1] = max(ylims_array[row_idx, file_grp_no, 1], np.max(hand_tsi_data_norm))
        else:
            axs_a[row_idx, file_grp_no].plot(hand_tsi_time, hand_tsi_data, alpha=0.9, color=color, label=f'Trial {file_no+1} hand')
            axs_a[row_idx, file_grp_no].plot(trimmed_time, trimmed_data, color=color, alpha=0.6, linestyle=':')
            ylims_array[row_idx, file_grp_no, 0] = min(ylims_array[row_idx, file_grp_no, 0], np.min(trimmed_data))
            ylims_array[row_idx, file_grp_no, 1] = max(ylims_array[row_idx, file_grp_no, 1], np.max(trimmed_data))

        if file_no == 0 : axs_a[row_idx, file_grp_no].set_title(f'{df_col_name} ({file_group})')

    for ax in axs_a[:, file_grp_no].flat:
        if showLegend: ax.legend()
        if file_no == 0:
            ax.axvline(x=1, color="black", alpha=0.5, linestyle = "dotted")
            ax.axvline(x=2, color="black", alpha=0.5, linestyle = "dotted")
            ax.set_xlim(0, 4)
            ax.set_xlabel('Time')

    for ax in axs_b[:, file_grp_no].flat:
        if has_force:
          if showLegend: ax.legend()


def plot_combined_dist_tsi(axs_a, axs_b, title, file_path, file_grp_no, file_group, file_no, ylims_array2, hand_start_idx):
    global force_start_idx_error_global
    color_map = plt.get_cmap('Set1')
    has_force = check_if_force(task)

    df = pd.read_csv(file_path)
    time_hand = df.iloc[:, 0].values

    df.columns = [col.strip() for col in df.columns]
    present_labels = [col for col in df.columns if col in sensor_labels]
    sensor_data = {col: df[col].values for col in present_labels}
    curr_task_sensors = task_sensor.get(task, [])

    df_norm = normalized_dfs[os.path.basename(file_path)]
    dist_ratio_data_norm = {col: df_norm[col].values for col in dist_ratio_cols if col in df_norm.columns}

    hand_start_idx, hand_end_idx = hand_trim_indices
    force_start_idx, force_end_idx, force_sensor_values = find_trim_idx_force(sensor_data, curr_task_sensors, task, time_hand, df, file_group)

    for row_index, joint_triple in enumerate(joint_dist_col_triples):
        col1, col2, col3 = joint_triple

        # Compute distances
        dist_joint1_joint2 = joint_dist_2(col1, col2, df)
        dist_joint1_joint3 = joint_dist_2(col1, col3, df)
        ratio = dist_joint1_joint2 / dist_joint1_joint3

        # List of values to plot
        values_list = [dist_joint1_joint2, dist_joint1_joint3, ratio]

        for i, values in enumerate(values_list):
            curr_row_idx = row_index * 3 + i  # 3 rows for each joint triple (dist1-2, dist1-3, ratio)
            df_col_name = joint_dist_titles_2[curr_row_idx]
            hand_sensor_values = smooth_normalise(values)

            hand_sensor_values_norm = dist_ratio_data_norm.get(dist_ratio_cols[curr_row_idx], [])
            color = color_map(file_no)

            if has_force == True:
                tsi_force_seg1_zero_seg2(force_sensor_values, force_start_idx, force_end_idx, time_hand, axs_b[curr_row_idx, file_grp_no], color, file_no, plotGraph = True)

                if hand_start_idx >= force_end_idx: force_end_idx = hand_end_idx  # when hand_start is after force_end

                trimmed_data = hand_sensor_values[hand_start_idx:force_end_idx]
                trimmed_time = time_hand[hand_start_idx:force_end_idx]
                trimmed_data = trimmed_data - trimmed_data[0]
                trimmed_time = trimmed_time - trimmed_time[0]

                if hand_start_idx < force_start_idx: #NORMAL CASE
                    hand_tsi_data = tsi_hand_seg1_seg2(hand_sensor_values, hand_start_idx, force_start_idx, force_end_idx, time_hand, color, file_no, df_col_name)
                    hand_tsi_data_norm = tsi_hand_seg1_seg2(hand_sensor_values_norm, hand_start_idx, force_start_idx, force_end_idx, time_hand, color, file_no, df_col_name)

                elif force_start_idx == 0:
                    hand_tsi_data = tsi_hand_seg1_full_seg2_const(hand_sensor_values, hand_start_idx, force_end_idx, time_hand, color, file_no, df_col_name)
                    hand_tsi_data_norm = tsi_hand_seg1_full_seg2_const(hand_sensor_values_norm, hand_start_idx, force_end_idx, time_hand, color, file_no, df_col_name)

                ylims_array2[curr_row_idx, file_grp_no, 2] = min(ylims_array2[curr_row_idx, file_grp_no, 2], np.min(force_sensor_values))
                ylims_array2[curr_row_idx, file_grp_no, 3] = max(ylims_array2[curr_row_idx, file_grp_no, 3], np.max(force_sensor_values))

            if has_force == False:
                #Trim w/o scale or interpolate (dotted line)
                trimmed_data = hand_sensor_values[hand_start_idx:force_end_idx]
                trimmed_data = trimmed_data - trimmed_data[0]
                trimmed_time = time_hand[hand_start_idx:force_end_idx]
                if trimmed_time.size > 0: trimmed_time = trimmed_time - trimmed_time[0]

                hand_tsi_data = tsi_hand_combined_seg1and2(hand_sensor_values, hand_start_idx, hand_end_idx, time_hand, color, file_no, df_col_name)
                hand_tsi_data_norm = tsi_hand_combined_seg1and2(hand_sensor_values_norm, hand_start_idx, hand_end_idx, time_hand, color, file_no, df_col_name)

            df_new[f'{df_col_name}'] = hand_tsi_data
            df_new[f'{df_col_name}_Norm'] = hand_tsi_data_norm

            hand_tsi_time = np.linspace(0, hand_tsi_interp_tot_duration, num=hand_tsi_num_elements)
            if plotNorm:
                axs_a[curr_row_idx, file_grp_no].plot(hand_tsi_time, hand_tsi_data_norm, alpha=0.9, color=color, label=f'Trial {file_no+1} hand')
                ylims_array2[curr_row_idx, file_grp_no, 0] = min(ylims_array2[curr_row_idx, file_grp_no, 0], np.min(hand_tsi_data_norm))
                ylims_array2[curr_row_idx, file_grp_no, 1] = max(ylims_array2[curr_row_idx, file_grp_no, 1], np.max(hand_tsi_data_norm))
            else:
                axs_a[curr_row_idx, file_grp_no].plot(hand_tsi_time, hand_tsi_data, alpha=0.9, color=color, label=f'Trial {file_no+1} hand')
                axs_a[curr_row_idx, file_grp_no].plot(trimmed_time, trimmed_data, color=color, alpha=0.6, linestyle=':')
                ylims_array2[curr_row_idx, file_grp_no, 0] = min(ylims_array2[curr_row_idx, file_grp_no, 0], np.min(hand_tsi_data))
                ylims_array2[curr_row_idx, file_grp_no, 1] = max(ylims_array2[curr_row_idx, file_grp_no, 1], np.max(hand_tsi_data))

            if file_no == 0 : axs_a[curr_row_idx, file_grp_no].set_title(f'{joint_dist_titles_2[curr_row_idx]} ({file_group})')

    for ax in axs_a[:, file_grp_no].flat:
        if showLegend: ax.legend()
        if file_no == 0:
            ax.axvline(x=1, color="black", alpha= 0.6, linestyle = "dotted")
            ax.axvline(x=2, color="black", alpha= 0.6, linestyle = "dotted")
            ax.set_xlabel('Time')
            ax.set_xlim(0, 4)

    for ax in axs_b[:, file_grp_no].flat:
        if has_force:
          if showLegend: ax.legend()

def initialise_unaff_values(file_path, file_group, file_no):
    df = pd.read_csv(file_path)
    time_hand = df.iloc[:, 0].values

    df.columns = [col.strip() for col in df.columns]
    present_labels = [col for col in df.columns if col in sensor_labels]
    sensor_data = {col: df[col].values for col in present_labels}
    curr_task_sensors = task_sensor.get(task, [])
    curr_task_sensors = [sensor for sensor in curr_task_sensors if sensor in present_labels]

    wh_or_woh = find_wh_or_woh(file_group)
    if wh_or_woh not in unaff_areaAftScale_values:
        unaff_max_values[wh_or_woh] = {}
        unaff_areaAftScale_values[wh_or_woh] = {}

    force_start_idx, force_end_idx, force_sum_data = find_trim_idx_force(sensor_data, curr_task_sensors, task, time_hand, df, file_group)

    # Sum Data TSI
    if task == "Sphericalgrasp" or task == "Cylindricalgrasp" or task == "Pincergrasp":
        force_sum_tsi, area_bef_scale, area_aft_scale = tsi_force_seg1_zero_seg2(force_sum_data, force_start_idx, force_end_idx, time_hand, None, None, file_no, plotGraph = False)
        sensor = f'{task}Sum'
        if sensor not in unaff_max_values[wh_or_woh]:
          unaff_max_values[wh_or_woh][sensor] = {}
          unaff_areaAftScale_values[wh_or_woh][sensor] = {}
        unaff_max_values[wh_or_woh][sensor][file_no] = max(force_sum_tsi)
        unaff_areaAftScale_values[wh_or_woh][sensor][file_no] = area_aft_scale

    # Individual Sensor TSI
    for sensor in curr_task_sensors:
        force_tsi_data, area_bef_scale, area_aft_scale = tsi_force_seg1_zero_seg2(df[sensor].values, force_start_idx, force_end_idx, time_hand, None, None, file_no, plotGraph = False)
        if sensor not in unaff_max_values[wh_or_woh]:
          unaff_max_values[wh_or_woh][sensor] = {}
          unaff_areaAftScale_values[wh_or_woh][sensor] = {}
        unaff_max_values[wh_or_woh][sensor][file_no] = max(force_tsi_data)
        unaff_areaAftScale_values[wh_or_woh][sensor][file_no] = area_aft_scale

def initialise_score_two_values(file_path, file_group, file_no):
    df = pd.read_csv(file_path)
    time_hand = df.iloc[:, 0].values

    df.columns = [col.strip() for col in df.columns]
    present_labels = [col for col in df.columns if col in sensor_labels]
    sensor_data = {col: df[col].values for col in present_labels}
    curr_task_sensors = task_sensor.get(task, [])
    curr_task_sensors = [sensor for sensor in curr_task_sensors if sensor in present_labels]

    force_start_idx, force_end_idx, force_sum_data = find_trim_idx_force(sensor_data, curr_task_sensors, task, time_hand, df, file_group)

    # Sum Data TSI
    if task == "Sphericalgrasp" or task == "Cylindricalgrasp" or task == "Pincergrasp":
        force_sum_tsi, area_bef_scale, area_aft_scale = tsi_force_seg1_zero_seg2(force_sum_data, force_start_idx, force_end_idx, time_hand, None, None, file_no, plotGraph = False)
        sensor = f'{task}Sum'
        if sensor not in score_two_max_values:
          score_two_max_values[sensor] = {}
          score_two_areaAftScale_values[sensor] = {}
        score_two_max_values[sensor][file_no] = max(force_sum_tsi)
        score_two_areaAftScale_values[sensor][file_no] = area_aft_scale

    # Individual Sensor TSI
    for sensor in curr_task_sensors:
        force_tsi_data, area_bef_scale, area_aft_scale = tsi_force_seg1_zero_seg2(df[sensor].values, force_start_idx, force_end_idx, time_hand, None, None, file_no, plotGraph = False)
        if sensor not in score_two_max_values:
          score_two_max_values[sensor] = {}
          score_two_areaAftScale_values[sensor] = {}
        score_two_max_values[sensor][file_no] = max(force_tsi_data)
        score_two_areaAftScale_values[sensor][file_no] = area_aft_scale

def normalise_force_tsi_for_csv(wh_or_woh, curr_task_sensors):
    if loadExperimentData:
        if task == "Sphericalgrasp" or task == "Cylindricalgrasp" or task == "Pincergrasp":
            avg_unaff_max_value = np.mean(list(unaff_max_values[wh_or_woh][f'{task}Sum'].values()))
            df_new[f'{task}Sum_Norm'] = df_new[f'{task}Sum'] / avg_unaff_max_value * 100
            df_new[f'{task}Sum_Avg_Unaff_Max'] = avg_unaff_max_value

        for sensor in curr_task_sensors:
            avg_unaff_max_value = np.mean(list(unaff_max_values[wh_or_woh][sensor].values()))
            df_new[f'{sensor}_Norm'] = df_new[f'{sensor}'] / avg_unaff_max_value * 100
            df_new[f'{sensor}_Avg_Unaff_Max'] = avg_unaff_max_value

    if loadTendencyData:
        if task == "Sphericalgrasp" or task == "Cylindricalgrasp" or task == "Pincergrasp":
            avg_score_two_max_value = np.mean(list(score_two_max_values[f'{task}Sum'].values()))
            df_new[f'{task}Sum_Norm'] = df_new[f'{task}Sum'] / avg_score_two_max_value * 100
            df_new[f'{task}Sum_Avg_Score2_Max'] = avg_score_two_max_value

        for sensor in curr_task_sensors:
            avg_score_two_max_value = np.mean(list(score_two_max_values[sensor].values()))
            df_new[f'{sensor}_Norm'] = df_new[f'{sensor}'] / avg_score_two_max_value * 100
            df_new[f'{sensor}_Avg_Score2_Max'] = avg_score_two_max_value


def normalise_force_area_for_csv(wh_or_woh, curr_task_sensors):
    if loadExperimentData:
        if task == "Sphericalgrasp" or task == "Cylindricalgrasp" or task == "Pincergrasp":
            avg_unaff_areaAftScale_value = np.mean(list(unaff_areaAftScale_values[wh_or_woh][f'{task}Sum'].values()))
            df_new[f'{task}Sum_areaAftScale_Norm'] = df_new[f'{task}Sum_areaAftScale'] / avg_unaff_areaAftScale_value * 100
            df_new[f'{task}Sum_Avg_Unaff_AreaAftScale'] = avg_unaff_areaAftScale_value

        for sensor in curr_task_sensors:
            avg_unaff_areaAftScale_value = np.mean(list(unaff_areaAftScale_values[wh_or_woh][sensor].values()))
            df_new[f'{sensor}_areaAftScale_Norm'] = df_new[f'{sensor}_areaAftScale'] / avg_unaff_areaAftScale_value * 100
            df_new[f'{sensor}_Avg_Unaff_AreaAftScale'] = avg_unaff_areaAftScale_value

    if loadTendencyData:
        if task == "Sphericalgrasp" or task == "Cylindricalgrasp" or task == "Pincergrasp":
            avg_score_two_areaAftScale_value = np.mean(list(score_two_areaAftScale_values[f'{task}Sum'].values()))
            df_new[f'{task}Sum_areaAftScale_Norm'] = df_new[f'{task}Sum_areaAftScale'] / avg_score_two_areaAftScale_value * 100
            df_new[f'{task}Sum_Avg_Score2_AreaAftScale'] = avg_score_two_areaAftScale_value

        for sensor in curr_task_sensors:
            avg_score_two_areaAftScale_value = np.mean(list(score_two_areaAftScale_values[sensor].values()))
            df_new[f'{sensor}_areaAftScale_Norm'] = df_new[f'{sensor}_areaAftScale'] / avg_score_two_areaAftScale_value * 100
            df_new[f'{sensor}_Avg_Score2_AreaAftScale'] = avg_score_two_areaAftScale_value

def add_force_tsi_to_csv(file_path, file_group, file_no, df_new):
    df = pd.read_csv(file_path)
    time_hand = df.iloc[:, 0].values

    df.columns = [col.strip() for col in df.columns]
    present_labels = [col for col in df.columns if col in sensor_labels]
    sensor_data = {col: df[col].values for col in present_labels}
    curr_task_sensors = task_sensor.get(task, [])
    curr_task_sensors = [sensor for sensor in curr_task_sensors if sensor in present_labels]
    wh_or_woh = find_wh_or_woh(file_group)

    force_start_idx, force_end_idx, force_sum_data = find_trim_idx_force(sensor_data, curr_task_sensors, task, time_hand, df, file_group)

    # Force Data TSI
    if task == "Sphericalgrasp" or task == "Cylindricalgrasp" or task == "Pincergrasp":
        force_sum_tsi, sum_area_bef_scale, sum_area_aft_scale = tsi_force_seg1_zero_seg2(force_sum_data, force_start_idx, force_end_idx, time_hand, None, None, file_no, plotGraph = False)
        df_new[f'{task}Sum'] = force_sum_tsi
        df_new[f'{task}Sum_Max'] = np.full(hand_tsi_num_elements, max(force_sum_tsi))

    for sensor in curr_task_sensors:
        force_tsi_data, _ , _ = tsi_force_seg1_zero_seg2(df[sensor].values, force_start_idx, force_end_idx, time_hand, None, None, file_no, plotGraph = False)
        df_new[f'{sensor}'] = force_tsi_data
        df_new[f'{sensor}_Max'] = np.full(hand_tsi_num_elements, max(force_tsi_data))

    # Normalise with unaff / score two            -- separate loops from above so columns are grouped together in df
    normalise_force_tsi_for_csv(wh_or_woh, curr_task_sensors)

    # Area 1 - before scale & interpolate                         (but still after trimming)
    if task == "Sphericalgrasp" or task == "Cylindricalgrasp" or task == "Pincergrasp":
        df_new[f'{task}Sum_areaBefScale'] = np.full(hand_tsi_num_elements, sum_area_bef_scale)

    for sensor in curr_task_sensors:
        _, area_bef_scale, _ = tsi_force_seg1_zero_seg2(df[sensor].values, force_start_idx, force_end_idx, time_hand, None, None, file_no, plotGraph = False)
        df_new[f'{sensor}_areaBefScale'] = np.full(hand_tsi_num_elements, area_bef_scale)

    # Area 2 - after scale & interpolate
    if task == "Sphericalgrasp" or task == "Cylindricalgrasp" or task == "Pincergrasp":
        df_new[f'{task}Sum_areaAftScale'] = np.full(hand_tsi_num_elements, sum_area_aft_scale)

    for sensor in curr_task_sensors:
        _, _, area_aft_scale = tsi_force_seg1_zero_seg2(df[sensor].values, force_start_idx, force_end_idx, time_hand, None, None, file_no, plotGraph = False)
        df_new[f'{sensor}_areaAftScale'] = np.full(hand_tsi_num_elements, area_aft_scale)

    # Area 2, normalize with unaff
    normalise_force_area_for_csv(wh_or_woh, curr_task_sensors)



def check_if_force(task):
    if task == "Hookgrasp" or task == "Thumbadduction" or task == "Sphericalgrasp" or task == "Cylindricalgrasp" or task == "Pincergrasp":
        return True
    elif task == "Massfingerflexion" or task == "Massfingerextension":
        return False



hand_tsi_interp_tot_duration = 2                # in seconds, total for both segements
hand_tsi_num_elements = 200                     # total no. of datapoints, incl. start and end
hand_tsi_interp_step = hand_tsi_interp_tot_duration / (hand_tsi_num_elements - 1)
hand_tsi_interp_seg_duration = (hand_tsi_interp_tot_duration / 2) - (hand_tsi_interp_step / 2)   # for each segement

# HS, HE = hand start index, hand end index
# FS, FE = force start index, force end index

# Hand data: HS-FS in Seg 1, FS-FE in Seg 2
def tsi_hand_seg1_seg2(hand_sensor_values, hand_start_idx, force_start_idx, force_end_idx, time_hand, color, file_no, df_col_name):
    #Trim Seg 1
    trimmed_data_1 = hand_sensor_values[hand_start_idx:force_start_idx]
    trimmed_data_1 = trimmed_data_1 - hand_sensor_values[hand_start_idx]
    trimmed_time_1 = time_hand[hand_start_idx:force_start_idx]
    trimmed_time_1 = trimmed_time_1 - trimmed_time_1[0]

    # scale Seg 1
    scale_factor_1 = hand_tsi_interp_seg_duration / max(trimmed_time_1)
    scaled_time_1 = [scale_factor_1 * t for t in trimmed_time_1]

    # Interpolate Seg 1
    interpolated_time_1 = np.linspace(0, hand_tsi_interp_seg_duration, num=int(hand_tsi_num_elements/2))
    interpolated_data_1 = np.interp(interpolated_time_1, scaled_time_1, trimmed_data_1)

    #Trim Seg 2
    trimmed_data_2 = hand_sensor_values[force_start_idx:force_end_idx]
    trimmed_data_2 = trimmed_data_2 - hand_sensor_values[hand_start_idx]                   # normalize with first value of segment ONE to align both
    trimmed_time_2 = time_hand[force_start_idx:force_end_idx]
    trimmed_time_2 = trimmed_time_2 - trimmed_time_2[0]

    #Scale Seg 2
    scale_factor_2 = hand_tsi_interp_seg_duration / max(trimmed_time_2)
    scaled_time_2 = [scale_factor_2 * t for t in trimmed_time_2]

    # Interpolate Seg 2
    interpolated_time_2 = np.linspace(0, hand_tsi_interp_seg_duration, num=int(hand_tsi_num_elements/2))
    interpolated_data_2 = np.interp(interpolated_time_2, scaled_time_2, trimmed_data_2)

    # Combine Seg 1 and Seg 2
    hand_tsi_data = np.concatenate((interpolated_data_1, interpolated_data_2))
    return hand_tsi_data


# Hand Data (when FS = 0 / score Zero): HS-FE TSI in Seg 1, last value of Seg 1 in Seg 2
def tsi_hand_seg1_full_seg2_const(hand_sensor_values, hand_start_idx, force_end_idx, time_hand, color, file_no, df_col_name):
    # Trim Seg 1
    trimmed_data_1 = hand_sensor_values[hand_start_idx:force_end_idx]
    trimmed_data_1 = trimmed_data_1 - trimmed_data_1[0]

    trimmed_time_1 = time_hand[hand_start_idx:force_end_idx]
    trimmed_time_1 = trimmed_time_1 - trimmed_time_1[0]

    # Scale Seg 1
    scale_factor_1 = hand_tsi_interp_seg_duration / max(trimmed_time_1)
    scaled_time_1 = [scale_factor_1 * t for t in trimmed_time_1]

    # Interpolate Seg 1
    interpolated_time_1 = np.linspace(0, hand_tsi_interp_seg_duration, num=int(hand_tsi_num_elements/2))
    interpolated_data_1 = np.interp(interpolated_time_1, scaled_time_1, trimmed_data_1)

    # Seg 2 (last value of Seg 1)
    constant_data_2 = np.full(int(hand_tsi_num_elements/2), trimmed_data_1[-1])    #last value of Seg 1

    # Combine Seg 1 and Seg 2
    hand_tsi_data = np.concatenate((interpolated_data_1, constant_data_2))
    return hand_tsi_data


# Hand Data: HS-HE over the entire Seg 1 and 2 (for Massfingerextension / Massfingerflexion)
def tsi_hand_combined_seg1and2(hand_sensor_values, hand_start_idx, hand_end_idx, time_hand, color, file_no, df_col_name):
    # Trim
    trimmed_data_1 = hand_sensor_values[hand_start_idx:hand_end_idx]
    trimmed_data_1 = trimmed_data_1 - hand_sensor_values[hand_start_idx]
    trimmed_time_1 = time_hand[hand_start_idx:hand_end_idx]
    trimmed_time_1 = trimmed_time_1 - trimmed_time_1[0]

    # Scale
    scale_factor_1 = hand_tsi_interp_tot_duration / max(trimmed_time_1)
    scaled_time_1 = [scale_factor_1 * t for t in trimmed_time_1]

    # Interpolate
    hand_tsi_time = np.linspace(0, hand_tsi_interp_tot_duration, num=hand_tsi_num_elements)
    hand_tsi_data = np.interp(hand_tsi_time, scaled_time_1, trimmed_data_1)
    return hand_tsi_data


# Force Data: Zero in Seg 1, FS-FE TSI in Seg 2
def tsi_force_seg1_zero_seg2(force_sensor_values, force_start_idx, force_end_idx, time_hand, axs, color, file_no, plotGraph):
    #Seg 1
    zero_data_1 = np.full(int(hand_tsi_interp_seg_duration / hand_tsi_interp_step) + 1, 0)

    #Trim Seg 2
    trimmed_data_2 = force_sensor_values[force_start_idx:force_end_idx]
    trimmed_time_2 = time_hand[force_start_idx:force_end_idx]
    trimmed_time_2 = trimmed_time_2 - trimmed_time_2[0]
    area_bef_scale = np.trapz(trimmed_data_2, trimmed_time_2)

    #Scale Seg 2
    scale_factor_2 = hand_tsi_interp_seg_duration / max(trimmed_time_2)
    scaled_time_2 = [scale_factor_2 * t for t in trimmed_time_2]

    # Interpolate Seg 2
    interpolated_time_2 = np.linspace(0, hand_tsi_interp_seg_duration, num=int(hand_tsi_num_elements/2))
    interpolated_data_2 = np.interp(interpolated_time_2, scaled_time_2, trimmed_data_2)

    # Combine Seg 1 and Seg 2
    force_tsi_time = np.linspace(0, hand_tsi_interp_tot_duration, num=hand_tsi_num_elements)
    force_tsi_data = np.concatenate((zero_data_1, interpolated_data_2))
    area_aft_scale = np.trapz(force_tsi_data, force_tsi_time)

    if plotGraph: axs.plot(force_tsi_time, force_tsi_data, alpha=0.8, color=color, linestyle="dashed", label=f'Trial {file_no+1} force')
    else: return force_tsi_data, area_bef_scale, area_aft_scale     #for add_force_tsi_to_csv()

# Iterate over each Axes in axs_a and create a twin axes for each
def create_twin_axes(axs_a):
    axs_b = np.empty_like(axs_a, dtype=object)

    for i in range(axs_a.shape[0]):
        for j in range(axs_a.shape[1]):
            axs_b[i, j] = axs_a[i, j].twinx()
    return axs_b

def create_new_df(file_path):
    df = pd.read_csv(file_path)
    #df = df.iloc[trim_idxs[0]:trim_idxs[1]]
    df_new = pd.DataFrame()
    df_new['interpolated_time'] = np.linspace(0, hand_tsi_interp_tot_duration, num=hand_tsi_num_elements)
    df_new['abs_sum_deg'] = np.full(hand_tsi_num_elements, float(0))
    df_new['abs_sum_thumb_xyz'] = np.full(hand_tsi_num_elements, float(0))
    df_new['abs_sum_index01_yz'] = np.full(hand_tsi_num_elements, float(0))
    return df_new


def check_aff_or_unaff(file_group):
    if "unaff" in file_group: return "unaff"
    elif "aff" in file_group: return "aff"

def add_therapist_score_to_csv(file_path, file_group, df_new):
    df = pd.read_csv(file_path)
    if loadExperimentData:
        df2 = pd.read_excel('/content/drive/MyDrive/BionicsLab_Colab/FMA_HAND_TASKS_LIST.xlsx', sheet_name='FMA_HAND_SCORE')
        aff_or_unaff = check_aff_or_unaff(file_group)
        # print(subjectID, aff_or_unaff)
        # print(df2[(df2['subjectID'] == subjectID) & (df2['aff_or_unaff'] == aff_or_unaff)])
        row = df2[(df2['subjectID'] == subjectID) & (df2['aff_or_unaff'] == aff_or_unaff)]
        if row.empty: print("Therapist Score Not Found")  # Or raise an exception if appropriate
        else: therapist_score = row[task].iloc[0]

    if loadTendencyData:
        file_name = os.path.basename(file_path)
        if "S2" in file_name: therapist_score = 2
        elif "S1" in file_name: therapist_score = 1
        elif "S0" in file_name: therapist_score = 0

    df_new['therapist_score'] = np.full(hand_tsi_num_elements, therapist_score)
    return therapist_score

def add_extra_hand_cols(file_path, file_group, file_no, df_new):
    df_norm = normalized_dfs[os.path.basename(file_path)]
    for col in angle_columns:
        df_new[f'{col}_Max'] = df_norm[f'{col}_original_max']
        df_new[f'{col}_Min'] = df_norm[f'{col}_original_min']
        df_new[f'{col}_Range'] = df_norm[f'{col}_original_range']

        if loadExperimentData: df_new[f'{col}_Avg_Unaff_Range'] = df_norm[f'{col}_avg_ideal_range']
        if loadTendencyData: df_new[f'{col}_Avg_Score2_Range'] = df_norm[f'{col}_avg_ideal_range']

    for col in dist_ratio_cols:
        df_new[f'{col}_Max'] = df_norm[f'{col}_original_max']
        df_new[f'{col}_Min'] = df_norm[f'{col}_original_min']
        df_new[f'{col}_Range'] = df_norm[f'{col}_original_range']

        if loadExperimentData: df_new[f'{col}_Avg_Unaff_Range'] = df_norm[f'{col}_avg_ideal_range']
        if loadTendencyData: df_new[f'{col}_Avg_Score2_Range'] = df_norm[f'{col}_avg_ideal_range']


def save_new_csv_file(df_new, file_path, new_csv_folder_path, score):
    original_file_name = os.path.basename(file_path)
    new_file_path_to_experiment_folder = os.path.join(new_csv_folder_path, f'S{score}_processed_{subjectID}_{original_file_name}')

    # dir3 = '/content/drive/MyDrive/BionicsLab_Colab/CSV_files_by_task'
    # task_folder_path = os.path.join(dir3, f'{task}')
    # if not os.path.exists(task_folder_path): os.makedirs(task_folder_path)
    # new_file_path_to_task_folder = os.path.join(task_folder_path, f'S{score}_processed_{subjectID}_{original_file_name}')

    df_new.to_csv(new_file_path_to_experiment_folder, index=False)
    # df_new.to_csv(new_file_path_to_task_folder, index=False)

"""## Force Trim: Off"""

# List of files to switch off force trimming
"""
eg. if score_zero but sensor values are still high, so force trimming is not automatically ignored
find_trim_indices_list() will ignore force trimming, start = 0, end = full duration

{ "{subjectID_full}": ["{file_name_1}", "{file_name_2}"] }
"""
force_trim_off_list = { "080624_SY": ["FMA23Sphericalgrasp_RightHand_08_05_2024_21_37_26_S0_5.csv"]}

# List of files to manually adjust force trimming
"""
eg. if hand_start_index is after force_start_index
find_trim_indices_list() will only look for start_indices after search_start_point

 { "{subjectID_full}": [["{file_name_1}", "{search_start_point_1}"], ["{file_name_2}", "{search_start_point_2}"]] }

Run Section 3 to compare hand and force trim points
Choose a search_start_point slightly before the "ideal start" (in seconds)
"""

force_trim_search_start_list = { "080624_SY": [["FMA23Sphericalgrasp_RightHand_08_05_2024_21_38_55_S0_2.csv", 0.75]]}

"""# SECTION 2: Force Sensor

### Experiment Data

unaff_with_hand
"""

force_sensor_overview_plots(unaff_wh_force_only, "unaff_wh", showLegend=False, saveGraph=True)

"""unaff_without"""

force_sensor_overview_plots(unaff_woh_force_only, "unaff_woh", showLegend=False, saveGraph=True)

"""aff_with_hand"""

force_sensor_overview_plots(aff_wh_force_only, "aff_wh", showLegend=False, saveGraph=True)

"""aff_without"""

force_sensor_overview_plots(aff_woh_force_only, "aff_woh", showLegend=False, saveGraph=True)

"""### Tendency Data"""

force_sensor_overview_plots(score_two_force_only, "score_two", showLegend=False, saveGraph=True)

force_sensor_overview_plots(score_one_force_only, "score_one", showLegend=False, saveGraph=True)

#SY - manually adjust force trim for Sphericalgrasp R Trial 14
force_sensor_overview_plots(score_zero_force_only, "score_zero", showLegend=False, saveGraph=True)

#SY - before edit
force_sensor_overview_plots(score_zero_force_only, "score_zero", showLegend=False, saveGraph=True)

"""## Force Sensor T-S-I"""

saveGraph = True
unaff_max_values = {}
score_two_max_values = {}

for task in set(task_sensor.keys()).union(*[d.keys() for d, _ in force_sets]):
    current_task_sensors = task_sensor.get(task, [])
    if not current_task_sensors:  continue

    for sensor in current_task_sensors:
        print(f'{task}, {sensor}')
        fig, axs = plt.subplots(1, len(force_sets), figsize=(21, 4), sharey=True)
        title_text = ["", "", ""]  # Initialize with empty strings for each score
        for i, (task_files, file_group) in enumerate(force_sets):
            if task in task_files:
                files = task_files[task]
                if files: plot_combined_force_tsi(files, axs[i], sensor, current_task_sensors)
                plot_hline_avg_max_value(axs[i], sensor)
                axs[i].set_title(f'{sensor} ({file_group} - {len(files)} files)')

        fig.tight_layout()
        file_path = os.path.join(force_tsi_folder_path, f'{task}_{sensor}_force_TSI.png')
        if saveGraph: plt.savefig(file_path)
        plt.show()
        print("\n")

    if task in {'Cylindricalgrasp', 'Sphericalgrasp','Pincergrasp'}:
        sum_sensors = task_sensor[task]
        fig, axs = plt.subplots(1, len(force_sets), figsize=(21, 4), sharey=True)
        for i, (task_files, file_group) in enumerate(force_sets):
            if task in task_files:
                files = task_files[task]
                if files: plot_sum_data_tsi(files, sum_sensors, axs[i], f'{task}Sum ({file_group})')
                plot_hline_avg_max_value(axs[i], sensor = f'{task}Sum')
                axs[i].set_title(f'{task}Sum ({file_group} - {len(files)} files)')

        print(f'{task}, Sum')
        fig.tight_layout()
        file_path = os.path.join(force_tsi_folder_path, f'{task}_Sum_force_TSI.png')
        if saveGraph: plt.savefig(file_path)
        plt.show()
        print("\n")

if loadExperimentData: print(f'unaff_max_values:\n {unaff_max_values}')
if loadTendencyData: print(f'score_two_max_values:\n {score_two_max_values}')

"""## Force Sensor TSI normalized
Run the section above FIRST to initialize unaff_max_values
"""

saveGraph = True

for task in set(task_sensor.keys()).union(*[d.keys() for d, _ in force_sets]):
    current_task_sensors = task_sensor.get(task, [])
    if not current_task_sensors:  continue

    for sensor in current_task_sensors:
        print(f'{task}, {sensor}_Norm')
        fig, axs = plt.subplots(1, len(force_sets), figsize=(21, 4), sharey=True)
        title_text = ["", "", ""]  # Initialize with empty strings for each score
        for i, (task_files, file_group) in enumerate(force_sets):
            if task in task_files:
                files = task_files[task]
                if files: plot_combined_force_tsi_norm(files, axs[i], sensor, current_task_sensors)
                axs[i].set_title(f'{sensor}_Norm ({file_group} - {len(files)} files)')

        fig.tight_layout()
        file_path = os.path.join(force_tsi_folder_path, f'{task}_{sensor}_force_TSI.png')
        if saveGraph: plt.savefig(file_path)
        plt.show()
        print("\n")

    if task in {'Cylindricalgrasp', 'Sphericalgrasp','Pincergrasp'}:
        sum_sensors = task_sensor[task]
        fig, axs = plt.subplots(1, len(force_sets), figsize=(21, 4), sharey=True)
        for i, (task_files, file_group) in enumerate(force_sets):
            if task in task_files:
                files = task_files[task]
                if files: plot_sum_data_tsi_norm(files, sum_sensors, axs[i], f'{task}Sum ({file_group})')
                axs[i].set_title(f'{task}Sum_Norm ({file_group} - {len(files)} files)')

        print(f'{task}, Sum_Norm')
        fig.tight_layout()
        file_path = os.path.join(force_tsi_folder_path, f'{task}_Sum_force_TSI.png')
        if saveGraph: plt.savefig(file_path)
        plt.show()
        print("\n")

"""# Individual CSV Force vs Degree trimmer plots

#### unstretched, 1x3
"""

warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)

#my_path = dir+'/data/8-04-2024 and 8-05-2024 data/SY/'
#my_path = dir+'/data/8-04-2024 and 8-05-2024 data/AK/'
my_path = '/content/drive/My Drive/BionicsLab_Colab/'+'/080424_SM/SM_Left_Score2/'
#my_path = '/content/drive/My Drive/Bionics Lab Research/Grace/'+'/data/8-04-2024 and 8-05-2024 data/SM/SM_BOTH_Score2/'

import fnmatch

for i in range(19,24):
  example_files = [file for file in (os.listdir(my_path)) if fnmatch.fnmatch(file, '*FMA'+str(i)+'*.csv')]

  for example_file in example_files:
    fig, subplts = plt.subplots(1, 3, figsize=(15, 5))

    # get and process degree trim idx, df, and trim x vals
    deg_df_untrimmed, picked_col, deg_trim_idxes = degree_process_file(my_path+'/'+example_file, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)
    deg_df_untrimmed[picked_col] -= deg_df_untrimmed[picked_col][0]  # normalize:
    deg_trim_vals = [deg_df_untrimmed['Timestamp'][deg_trim_idxes[0]], deg_df_untrimmed['Timestamp'][deg_trim_idxes[1]]]
    # plot them
    subplts[0].axvline(x=deg_trim_vals[0], color='r', linestyle='--', label='Degree Start Index')
    subplts[0].axvline(x=deg_trim_vals[1], color='r', linestyle='--', label='Degree End Index')
    subplts[0].plot(deg_df_untrimmed['Timestamp'], deg_df_untrimmed[picked_col], label=picked_col, color='orange')
    subplts[2].plot(deg_df_untrimmed['Timestamp'], deg_df_untrimmed[picked_col], label=picked_col, color='orange')
    subplts[0].legend()
    subplts[0].title.set_text("Degree-based trim")

    # get and process force trim idx, df, and force x vals
    force_trim_idxes=[None, None]
    force_trim_idxes[0], force_trim_idxes[1], force_df_untrimmed = force_process_file(my_path+'/'+example_file)
    force_trim_vals = [force_df_untrimmed['Timestamp'][force_trim_idxes[0]], force_df_untrimmed['Timestamp'][force_trim_idxes[1]]]
    # plot them
    subplts[1].plot(force_df_untrimmed['Timestamp'], force_df_untrimmed['force'], label='force(s)', color='b')
    subplts[2].plot(force_df_untrimmed['Timestamp'], force_df_untrimmed['force'], label='force(s)', color='b')
    subplts[1].axvline(x=force_trim_vals[0], color='g', linestyle='--', label='Force Start Index')
    subplts[1].axvline(x=force_trim_vals[1], color='g', linestyle='--', label='Force End Index')
    subplts[1].title.set_text("Force-based trim")
    subplts[1].legend()

    # get final trim idx and force x vals
    final_trim_idxes = [None, None]
    final_trim_vals = [None, None]
    testno = i-17
    if testno == 0 or testno == 1: # no force
      final_trim_idxes = deg_trim_idxes
      final_trim_vals = deg_trim_vals
    else:
      final_trim_idxes[1] = force_trim_idxes[1] # always cut end with force
      final_trim_vals[1] = force_trim_vals[1]
      if deg_trim_idxes[0] <= force_trim_idxes[0]: # cut beginning by earliest index
        final_trim_idxes[0] = deg_trim_idxes[0]
        final_trim_vals[0] = deg_trim_vals[0]
      else:
        fig.patch.set_facecolor('yellow')
        final_trim_idxes[0] = force_trim_idxes[0]
        final_trim_vals[0] = force_trim_vals[0]
    # plot final trim decision
    subplts[2].axvline(x=deg_trim_vals[0], color='r', linestyle='--', label='Degree Index', alpha=0.4)
    subplts[2].axvline(x=deg_trim_vals[1], color='r', linestyle='--', label='Degree Index', alpha=0.4)
    subplts[2].axvline(x=force_trim_vals[0], color='g', linestyle='--', label='Force Index', alpha=0.4)
    subplts[2].axvline(x=force_trim_vals[1], color='g', linestyle='--', label='Force Index', alpha=0.4)

    subplts[2].axvline(x=final_trim_vals[0], color='black', linestyle='--', label='Final Index')
    subplts[2].axvline(x=final_trim_vals[1], color='black', linestyle='--', label='Final Index')

    subplts[2].title.set_text("Combined Final trim")
    subplts[2].legend()

    fig.suptitle(example_file)
    plt.show()
    #print(start_idx, end_idx)

"""# Degree/Force Large-scale plots

#### 6x3 degree and score 2 vs score 1 vs score 0
"""

# custom get_dfs for horiz vert sphere and thumb

# fetch and sort all filenames from a subfolder and put in dict with 'Right' and 'Left' info
def get_dfs2(subfolder, threshold_a, threshold_b, window_size=12, percent_range=0.05):
  data_path = dir + subfolder
  file_list = os.listdir(data_path)
  filenames_untrimmed = {}
  filenames_trimmed = {}
  for testname, testno in zip(testnames, range(0,len(testnames))):
    filenames_untrimmed[testno] = {hand: [] for hand in hands}
    filenames_trimmed[testno] = {hand: [] for hand in hands}
    print(file_list)
    for filename in file_list:
      if 'meta' in filename or testname not in filename or not filename.endswith('.csv'):
        continue

      if 'touch' in filename.lower() or re.search(r'_T\d\.csv$', filename) is not None: # skip sensor touched
        continue

      hand = get_hand(filename)
      print(filename)
      #def process_file_combined(path, threshold_a=0.1, threshold_b=0.1, window_size=12):
      df, df_untrimmed,trim_idxes, picked_col = process_file_combined(data_path+'/'+filename, threshold_a=threshold_a, threshold_b=threshold_b, window_size=window_size, percent_range=percent_range)
      #print(df.head)

      filenames_trimmed[testno][hand].append(df)
      filenames_untrimmed[testno][hand].append(df_untrimmed)

  return filenames_trimmed, filenames_untrimmed

warnings.filterwarnings("ignore", category=pd.errors.PerformanceWarning)
import imageio
import re
from IPython.display import Image # Explicitly import Image
#no_scroll()
folder='data/8-04-2024 and 8-05-2024 data/'

initials = "AJ"
subfolders = os.listdir(dir+folder+initials)
all_dicts = {}
for subfolder in subfolders:
  pattern = re.compile(r'_Score(\d+)')
  score = int(pattern.search(subfolder).group(1))

  filenames_trimmed, filenames_untrimmed = get_dfs2(folder+initials+'/'+subfolder, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)

  all_dicts[score] = {'trimmed': filenames_trimmed, 'untrimmed': filenames_untrimmed}

output_folder = dir + 'tendency plots/' + str(today_date) + '/2' + initials
hide_plot = False
print(f'\toutput_folder: {output_folder}')

# Initialize max and min values
deg_min_max = [-100,100]
ratio_min_max = [float('inf'),float('-inf')]
dist_min_max = [float('inf'),float('-inf')]

# Iterate through testnames and filenames
for testno in range(len(testnames)):
  list_of_dfs = all_dicts[2]['trimmed'][testno]['Left'] + all_dicts[2]['trimmed'][testno]['Right']

  for df in list_of_dfs:
    for col in ratio_cols:
      ratio_min_max[0] = min(ratio_min_max[0], df[col].min())
      ratio_min_max[1] = max(ratio_min_max[1], df[col].max())
    for col in dist_cols:
      dist_min_max[0] = min(dist_min_max[0], df[col].min())
      dist_min_max[1] = max(dist_min_max[1], df[col].max())

for testno in range(0,len(testnames)): #input is dict mapping file name to processed df of that file
  output_name = f"{testno+1}. {testnames[testno]} {initials} LeftHand trimmed Thumb"
  graph_all_scores(all_dicts[2]['trimmed'][testno], all_dicts[1]['trimmed'][testno], all_dicts[0]['trimmed'][testno], \
                    all_dicts[2]['untrimmed'][testno], all_dicts[1]['untrimmed'][testno], all_dicts[0]['untrimmed'][testno], \
                    hands[0], output_name, deg_min_max, output_folder, hide_plot=hide_plot)
  output_name = f"{testno+1}. {testnames[testno]} {initials} RightHand trimmed Thumb"
  graph_all_scores(all_dicts[2]['trimmed'][testno], all_dicts[1]['trimmed'][testno], all_dicts[0]['trimmed'][testno], \
                    all_dicts[2]['untrimmed'][testno], all_dicts[1]['untrimmed'][testno], all_dicts[0]['untrimmed'][testno], \
                    hands[1], output_name, deg_min_max, output_folder,hide_plot=hide_plot)
  output_name = f"{testno+1}. {testnames[testno]} {initials} BothHands trimmed Thumb"
  graph_all_scores(all_dicts[2]['trimmed'][testno], all_dicts[1]['trimmed'][testno], all_dicts[0]['trimmed'][testno], \
                    all_dicts[2]['untrimmed'][testno], all_dicts[1]['untrimmed'][testno], all_dicts[0]['untrimmed'][testno], \
                    'Both', output_name, deg_min_max, output_folder, hide_plot=hide_plot)

"""#### 9x4 degree, ratio, dist, force"""

warnings.filterwarnings("ignore", category=pd.errors.PerformanceWarning)
import imageio
import re
from IPython.display import Image # Explicitly import Image
#no_scroll()
folder=''
dir = '/content/drive/My Drive/BionicsLab_Colab/'
initials = 'ID05_MPFL_E20240820/WH_Unaffected_RightHand'
#folder='data/8-04-2024 and 8-05-2024 data/'
print(initials)
subfolders = os.listdir(dir+folder+initials)
for sub in subfolders:
  #print(sub)
  if 'Score2' in sub or 'Score_2' in sub:
    folder=folder+initials+'/'+sub+'/'
    break

filenames_trimmed, filenames_untrimmed = get_dfs2(folder, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)

output_folder = dir + 'tendency plots/' + str(today_date) + '/' + initials + ' both hands/'
print(f'\toutput_folder: {output_folder}')

# Initialize max and min values
deg_min_max = [-100,100]
ratio_min_max = [-100, 100]
dist_min_max = [-100, 100]

# Iterate through testnames and filenames
for testno in range(len(testnames)):
  list_of_dfs = filenames_untrimmed[testno][hands[0]] + filenames_untrimmed[testno][hands[1]]
  for df in list_of_dfs:
    for col in ratio_cols:
      ratio_min_max[0] = min(ratio_min_max[0], df[col].min())
      ratio_min_max[1] = max(ratio_min_max[1], df[col].max())
    for col in dist_cols:
      dist_min_max[0] = min(dist_min_max[0], df[col].min())
      dist_min_max[1] = max(dist_min_max[1], df[col].max())

for testno in range(0,len(testnames)): #input is dict mapping file name to processed df of that file
  output_name = f"{testno+1}. {testnames[testno]} {initials} LeftHand trimmed"
  graph_files(filenames_trimmed, filenames_untrimmed, testno, 'Left', output_name, deg_min_max, ratio_min_max, dist_min_max)

  output_name = f"{testno+1}. {testnames[testno]} {initials} RightHand trimmed"
  graph_files(filenames_trimmed, filenames_untrimmed, testno, 'Right', output_name, deg_min_max, ratio_min_max, dist_min_max)

  output_name = f"{testno+1}. {testnames[testno]} {initials} BothHands trimmed"
  graph_files(filenames_trimmed, filenames_untrimmed, testno, 'both', output_name, deg_min_max, ratio_min_max, dist_min_max)

"""# SECTION 3: Hand & Force - 3x4 and 4x3

## Experiment Data

unaff_with_hand
"""

saveGraph = True

unaff_wh_3x4_4x3_folder_path = os.path.join(hand_3x4_4x3_folder_path, 'unaff_with_hand')
if not os.path.exists(unaff_wh_3x4_4x3_folder_path): os.makedirs(unaff_wh_3x4_4x3_folder_path)
file_group = 'unaff_wh'

for title, file_path in unaff_wh_sorted.items():
    df = pd.read_csv(file_path)
    task = get_task_name(title, task_names)
    if task == "Massfingerextension" or task == "Massfingerflexion": continue

    hand_trim_idxs = degree_process_file(file_path, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)[2]
    hand_start, hand_end = hand_trim_idxs[0], hand_trim_idxs[1]

    plot_joint_angles(task, df, hand_start, hand_end, unaff_wh_3x4_4x3_folder_path, saveGraph)    # Plotting 3x4
    plot_joint_distances(task, df, hand_start, hand_end, unaff_wh_3x4_4x3_folder_path, saveGraph)     # Plotting 4x3

    plt.show()
    print("\n")

"""aff_with_hand"""

saveGraph = True

aff_wh_3x4_4x3_folder_path = os.path.join(hand_3x4_4x3_folder_path, 'aff_with_hand')
if not os.path.exists(aff_wh_3x4_4x3_folder_path): os.makedirs(aff_wh_3x4_4x3_folder_path)
file_group = 'aff_wh'

for title, file_path in aff_wh_sorted.items():
    df = pd.read_csv(file_path)
    task = get_task_name(title, task_names)
    if task == "Massfingerextension" or task == "Massfingerflexion": continue

    hand_trim_idxs = degree_process_file(file_path, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)[2]
    hand_start, hand_end = hand_trim_idxs[0], hand_trim_idxs[1]

    plot_joint_angles(task, df, hand_start, hand_end, aff_wh_3x4_4x3_folder_path, saveGraph)    # Plotting 3x4
    plot_joint_distances(task, df, hand_start, hand_end, aff_wh_3x4_4x3_folder_path, saveGraph)     # Plotting 4x3

    plt.show()
    print("\n")

"""## Tendency Data

score_two
"""

saveGraph = True

score_two_3x4_4x3_folder_path = os.path.join(hand_3x4_4x3_folder_path, 'score_two')
if not os.path.exists(score_two_3x4_4x3_folder_path): os.makedirs(score_two_3x4_4x3_folder_path)
file_group = 'score_two'

for title, file_path in score_two_sorted.items():
    df = pd.read_csv(file_path)
    task = get_task_name(title, task_names)
    if task == "Massfingerextension" or task == "Massfingerflexion": continue

    hand_trim_idxs = degree_process_file(file_path, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)[2]
    hand_start, hand_end = hand_trim_idxs[0], hand_trim_idxs[1]

    plot_joint_angles(task, df, hand_start, hand_end, score_two_3x4_4x3_folder_path, saveGraph)    # Plotting 3x4
    plot_joint_distances(task, df, hand_start, hand_end, score_two_3x4_4x3_folder_path, saveGraph)     # Plotting 4x3

    plt.show()
    print("\n")

#080624_SY
saveGraph = False

file_group = 'score_zero'
score_zero_3x4_4x3_folder_path = os.path.join(hand_3x4_4x3_folder_path, file_group)
if not os.path.exists(score_zero_3x4_4x3_folder_path): os.makedirs(score_zero_3x4_4x3_folder_path)

for title, file_path in score_zero_sorted.items():
    df = pd.read_csv(file_path)
    task = get_task_name(title, task_names)
    if task == "Massfingerextension" or task == "Massfingerflexion": continue
    if title != 'Sphericalgrasp R Trial 14': continue

    hand_trim_idxs = degree_process_file(file_path, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)[2]
    hand_start, hand_end = hand_trim_idxs[0], hand_trim_idxs[1]

    plot_joint_angles(task, df, hand_start, hand_end, score_zero_3x4_4x3_folder_path, saveGraph)    # Plotting 3x4
    plot_joint_distances(task, df, hand_start, hand_end, score_zero_3x4_4x3_folder_path, saveGraph)     # Plotting 4x3

    plt.show()
    print("\n")

"""# SECTION 4: Hand & Force: Trim Scale Interpolate"""

# Intitialize max & areaAftScale values from force sensor, from unaffected / score two datasets, for normalization
unaff_max_values = {}
unaff_areaAftScale_values = {}
score_two_max_values = {}
score_two_areaAftScale_values = {}

for task in set(task_sensor.keys()).union(*[d.keys() for d, _ in force_sets]):
    # print(f'{task}')
    for file_grp_no, (task_files, file_group) in enumerate(force_sets):
        if loadExperimentData and "unaff" not in file_group: continue
        if loadTendencyData and "score_two" not in file_group: continue
        # print(file_group)
        files = task_files[task]
        for file_no, (title, file_path) in enumerate(files):
            if loadExperimentData: initialise_unaff_values(file_path, file_group, file_no)
            if loadTendencyData: initialise_score_two_values(file_path, file_group, file_no)

if loadExperimentData:
    print(f'unaff_max_values: {unaff_max_values}')
    print(f'unaff_areaAftScale_values: {unaff_areaAftScale_values}')
if loadTendencyData:
    print(f'score_two_max_values: {score_two_max_values}')
    print(f'score_two_areaAftScale_values: {score_two_areaAftScale_values}')

#Function defined in Section 5: Function - Unflipped ; will rearrange sections at a later date

normalized_dfs = compute_normalized_cols_unflipped(dir2)
print(normalized_dfs.keys())

#080624_SY - 3m58s

"""Run cell above once before running this, to initialize unaff_max_values and unaff_areaAftScale_values (for normalization)

##HERE
"""

#ID03
saveGraph = False
showLegend = False
plotNorm = True       # True: plot Normalized data, False: plot Unnormalized original data

for task in set(task_sensor.keys()).union(*[d.keys() for d, _ in hand_sets]):
    print(f'{task}')
    has_force = check_if_force(task)
    if task != 'Sphericalgrasp': continue

    # 9 rows, 2 cols of angle data
    fig1, axs_1a = plt.subplots(len(angle_columns), len(hand_sets), figsize=(21, 30))
    ylims_array = np.full((len(angle_columns), len(hand_sets), 4), [np.inf, -np.inf, np.inf, -np.inf])
    axs_1b = create_twin_axes(axs_1a)

    # 12 rows, 2 cols of dist/ratio data
    fig2, axs_2a = plt.subplots(len(joint_dist_col_triples)*3, len(hand_sets), figsize=(21, 35))
    ylims_array2 = np.full((len(joint_dist_col_triples)*3, len(hand_sets), 4), [np.inf, -np.inf, np.inf, -np.inf])
    axs_2b = create_twin_axes(axs_2a)

    for file_grp_no, (task_files, file_group) in enumerate(hand_sets):
        files = task_files[task]
        for file_no, (title, file_path) in enumerate(files):
            hand_trim_indices = degree_process_file(file_path, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)[2]
            df_new = create_new_df(file_path)
            plot_combined_angle_tsi(axs_1a, axs_1b, title, file_path, file_grp_no, file_group, file_no, ylims_array, hand_trim_indices)
            plot_combined_dist_tsi(axs_2a, axs_2b, title, file_path, file_grp_no, file_group, file_no, ylims_array2, hand_trim_indices)
            add_extra_hand_cols(file_path, file_group, file_no, df_new)
            add_force_tsi_to_csv(file_path, file_group, file_no, df_new)
            t_score = add_therapist_score_to_csv(file_path, file_group, df_new)
            save_new_csv_file(df_new, file_path, new_csv_folder_path, t_score)

    for row in range(len(angle_columns)):
        min_ylim_a, max_ylim_a = ylims_array[row, :, 0].min(), ylims_array[row, :, 1].max()
        if has_force: min_ylim_b, max_ylim_b = ylims_array[row, :, 2].min(), ylims_array[row, :, 3].max()
        for col in range(len(hand_sets)):
          axs_1a[row, col].set_ylim(min_ylim_a, max_ylim_a)
          if has_force: axs_1b[row, col].set_ylim(min_ylim_b, max_ylim_b)

    for row in range(len(joint_dist_col_triples)*3):
        min_ylim_a, max_ylim_a = ylims_array2[row, :, 0].min(), ylims_array2[row, :, 1].max()
        if has_force: min_ylim_b, max_ylim_b = ylims_array2[row, :, 2].min(), ylims_array2[row, :, 3].max()
        for col in range(len(hand_sets)):
          axs_2a[row, col].set_ylim(min_ylim_a, max_ylim_a)
          if has_force: axs_2b[row, col].set_ylim(min_ylim_b, max_ylim_b)

    fig1.tight_layout()
    fig2.tight_layout()
    # fig1_path = os.path.join(hand_tsi_folder_path, f'{task}_angle_TSI.png')
    # fig2_path = os.path.join(hand_tsi_folder_path, f'{task}_dist_ratio_TSI.png')
    # if saveGraph: fig1.savefig(fig1_path)
    # if saveGraph: fig2.savefig(fig2_path)
    plt.show()
    print("\n")

#SY
saveGraph = False
showLegend = False

for task in set(task_sensor.keys()).union(*[d.keys() for d, _ in hand_sets]):
    print(f'{task}')
    has_force = check_if_force(task)
    if task != 'Sphericalgrasp': continue

    # 9 rows, 2 cols of angle data
    fig1, axs_1a = plt.subplots(len(angle_columns), len(hand_sets), figsize=(21, 30))
    ylims_array = np.full((len(angle_columns), len(hand_sets), 4), [np.inf, -np.inf, np.inf, -np.inf])
    axs_1b = create_twin_axes(axs_1a)

    # 12 rows, 2 cols of dist/ratio data
    fig2, axs_2a = plt.subplots(len(joint_dist_col_triples)*3, len(hand_sets), figsize=(21, 35))
    ylims_array2 = np.full((len(joint_dist_col_triples)*3, len(hand_sets), 4), [np.inf, -np.inf, np.inf, -np.inf])
    axs_2b = create_twin_axes(axs_2a)

    for file_grp_no, (task_files, file_group) in enumerate(hand_sets):
        files = task_files[task]
        for file_no, (title, file_path) in enumerate(files):
            #df, deg_df_untrimmed, final_trim_idxes, picked_col = process_file_combined(file_path, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)
            hand_trim_indices = degree_process_file(file_path, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)[2]
            df_new = create_new_df(file_path)
            plot_combined_angle_tsi(axs_1a, axs_1b, title, file_path, file_grp_no, file_group, file_no, ylims_array, hand_trim_indices)
            plot_combined_dist_tsi(axs_2a, axs_2b, title, file_path, file_grp_no, file_group, file_no, ylims_array2, hand_trim_indices)
            add_force_tsi_to_csv(file_path, file_group, file_no, df_new)\
            # add_hand_tsi_to_csv
            t_score = add_therapist_score_to_csv(file_path, file_group, df_new)
            # print(df_new)
            save_new_csv_file(df_new, file_path, new_csv_folder_path, t_score)

    for row in range(len(angle_columns)):
        min_ylim_a, max_ylim_a = ylims_array[row, :, 0].min(), ylims_array[row, :, 1].max()
        if has_force: min_ylim_b, max_ylim_b = ylims_array[row, :, 2].min(), ylims_array[row, :, 3].max()
        for col in range(len(hand_sets)):
          axs_1a[row, col].set_ylim(min_ylim_a, max_ylim_a)
          if has_force: axs_1b[row, col].set_ylim(min_ylim_b, max_ylim_b)

    for row in range(len(joint_dist_col_triples)*3):
        min_ylim_a, max_ylim_a = ylims_array2[row, :, 0].min(), ylims_array2[row, :, 1].max()
        if has_force: min_ylim_b, max_ylim_b = ylims_array2[row, :, 2].min(), ylims_array2[row, :, 3].max()
        for col in range(len(hand_sets)):
          axs_2a[row, col].set_ylim(min_ylim_a, max_ylim_a)
          if has_force: axs_2b[row, col].set_ylim(min_ylim_b, max_ylim_b)

    fig1.tight_layout()
    fig2.tight_layout()
    fig1_path = os.path.join(hand_tsi_folder_path, f'{task}_angle_TSI.png')
    fig2_path = os.path.join(hand_tsi_folder_path, f'{task}_dist_ratio_TSI.png')
    if saveGraph: fig1.savefig(fig1_path)
    if saveGraph: fig2.savefig(fig2_path)
    plt.show()
    print("\n")

"""trim using process_file_combined
decide whether to flip
return processed_df with flipped but untrimmed columns
trim using different scenarios for Seg 1 and Seg 2 of HS, FS, FE in plot_combined_angle_tsi and plot_combined_dist_tsi
scale and interpolate

ZE
"""

#ZE
saveGraph = False
showLegend = False

for task in set(task_sensor.keys()).union(*[d.keys() for d, _ in hand_sets]):
    print(f'{task}')
    has_force = check_if_force(task)
    # if task != 'Pincergrasp': continue

    # 9 rows, 2 cols of angle data
    fig1, axs_1a = plt.subplots(len(angle_columns), len(hand_sets), figsize=(21, 30))
    ylims_array = np.full((len(angle_columns), len(hand_sets), 4), [np.inf, -np.inf, np.inf, -np.inf])
    axs_1b = create_twin_axes(axs_1a)

    # 12 rows, 2 cols of dist/ratio data
    fig2, axs_2a = plt.subplots(len(joint_dist_col_triples)*3, len(hand_sets), figsize=(21, 35))
    ylims_array2 = np.full((len(joint_dist_col_triples)*3, len(hand_sets), 4), [np.inf, -np.inf, np.inf, -np.inf])
    axs_2b = create_twin_axes(axs_2a)

    for file_grp_no, (task_files, file_group) in enumerate(hand_sets):
        files = task_files[task]
        for file_no, (title, file_path) in enumerate(files):
            #df, deg_df_untrimmed, final_trim_idxes, picked_col = process_file_combined(file_path, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)
            hand_trim_indices = degree_process_file(file_path, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)[2]
            df_new = create_new_df(file_path)
            plot_combined_angle_tsi(axs_1a, axs_1b, title, file_path, file_grp_no, file_group, file_no, ylims_array, hand_trim_indices)
            plot_combined_dist_tsi(axs_2a, axs_2b, title, file_path, file_grp_no, file_group, file_no, ylims_array2, hand_trim_indices)
            add_force_tsi_to_csv(file_path, file_group, file_no, df_new)
            # add_hand_tsi_to_csv
            t_score = add_therapist_score_to_csv(file_path, file_group, df_new)
            # print(df_new)
            save_new_csv_file(df_new, file_path, new_csv_folder_path, t_score)

    for row in range(len(angle_columns)):
        min_ylim_a, max_ylim_a = ylims_array[row, :, 0].min(), ylims_array[row, :, 1].max()
        if has_force: min_ylim_b, max_ylim_b = ylims_array[row, :, 2].min(), ylims_array[row, :, 3].max()
        for col in range(len(hand_sets)):
          axs_1a[row, col].set_ylim(min_ylim_a, max_ylim_a)
          if has_force: axs_1b[row, col].set_ylim(min_ylim_b, max_ylim_b)

    for row in range(len(joint_dist_col_triples)*3):
        min_ylim_a, max_ylim_a = ylims_array2[row, :, 0].min(), ylims_array2[row, :, 1].max()
        if has_force: min_ylim_b, max_ylim_b = ylims_array2[row, :, 2].min(), ylims_array2[row, :, 3].max()
        for col in range(len(hand_sets)):
          axs_2a[row, col].set_ylim(min_ylim_a, max_ylim_a)
          if has_force: axs_2b[row, col].set_ylim(min_ylim_b, max_ylim_b)

    fig1.tight_layout()
    fig2.tight_layout()
    fig1_path = os.path.join(hand_tsi_folder_path, f'{task}_angle_TSI.png')
    fig2_path = os.path.join(hand_tsi_folder_path, f'{task}_dist_ratio_TSI.png')
    if saveGraph: fig1.savefig(fig1_path)
    if saveGraph: fig2.savefig(fig2_path)
    plt.show()
    print("\n")

"""# SECTION 5: Normalize"""

#initials = 'ID05_MPFL_E20240820'
#initials = 'ID04_ML_E20240815'
initials = 'ID03R'

# Fetch needed dfs to compute avg of abs max values of unaffected arm valu
dir = '/content/drive/My Drive/BionicsLab_Colab/'
# get list of folders in dir
folders = [f for f in os.listdir(dir+initials) if os.path.isdir(os.path.join(dir+initials, f)) and 'WOH' not in f and 'withouthandsensor' not in f.lower() and 'hand' in f.lower()]
# throw exception if folder not 2 elements long:
if len(folders) != 2:
  raise Exception(f"expected two hand sensor folders (affected vs unaffected), got {len(folders)}:\n{folders}")

#print(folders)
if 'unaffected' in folders[0].lower():
  unaff_folder = folders[0]
  aff_folder = folders[1]
else:
  unaff_folder = folders[1]
  aff_folder = folders[0]

print(f"unaffected folder: {unaff_folder}")
print(f"affected folder: {aff_folder}")

unaff_dfs = {i: [] for i in range(7)}
aff_dfs = {i: [] for i in range(7)}
files_untrimmed = {i: {'Unaffected': [], 'Affected': []} for i in range(7)}
for f in [f for f in os.listdir(dir+initials+'/'+unaff_folder) if f.endswith('.csv')]:
  df, _, _ = degree_process_file(dir+initials+'/'+unaff_folder+'/'+f, normalize=True, threshold_a=0, threshold_b=0, window_size=0, percent_range=0)
  df = interpolate_to_0_2(df)
  testno = get_testno(f)
  unaff_dfs[testno].append(df)
  files_untrimmed[testno]['Unaffected'].append(df)
  #print(f"\tfiles_untrimmed[{testno}]['Unaffected'] len is {len(files_untrimmed[testno]['Unaffected'])}")

for f in [f for f in os.listdir(dir+initials+'/'+aff_folder) if f.endswith('.csv')]:
  df, _, _ = degree_process_file(dir+initials+'/'+aff_folder+'/'+f, threshold_a=0, threshold_b=0, window_size=0, percent_range=0)
  #df = smooth_data(df, nonredundant_degree_cols, jump_threshold)
  df = interpolate_to_0_2(df)
  testno = get_testno(f)
  unaff_dfs[testno].append(df)
  files_untrimmed[testno]['Affected'].append(df)

for testno in range(0, len(testnames)):
  fig, subplts = plt.subplots(2, 3)  # Adjusted to 2 rows and 3 columns
  subplts = subplts.ravel()
  output_name = f"{testno+1}. {testnames[testno]} {initials} Both Untrimmed"
  plt.suptitle(output_name, fontsize='xx-large')

  # Loop through each joint and plot
  check_sign = {}

  for i, joint in enumerate(nonredundant_degree_cols):
      subplts[i].set(xlabel='time', ylabel='degrees')  # Adjusted for 2x3 layout
      subplts[i].set_title(joint)
      subplts[i].set_ylim([-100, 100])

      # Plot 'Unaffected'
      for df in files_untrimmed[testno]['Unaffected']:
        label = 'Unaffected'
        color = 'green'
        subplts[i].plot(df['Timestamp'], df[joint], label=label, color=color)
        # Calculate sum of negative and positive values
        sum_neg = df[joint][df[joint] < 0].sum()
        sum_pos = df[joint][df[joint] > 0].sum()
        #CHECK
        if abs(sum_neg) > abs(sum_pos) and joint in check_sign and check_sign[joint] == 1:
          subplts[i].set_facecolor('yellow')
        elif abs(sum_neg) < abs(sum_pos) and joint in check_sign and check_sign[joint] == -1:
          subplts[i].set_facecolor('yellow')
        check_sign[joint] = -1 if abs(sum_neg) > abs(sum_pos) else 1

        #print(f"\tUnaffected plot {joint} on subplot {i}")

      # Plot 'Affected'
      for df in files_untrimmed[testno]['Affected']:
        label = 'Affected'
        color = 'red'
        subplts[i].plot(df['Timestamp'], df[joint], label=label, color=color)
        #print(f"\tAffected plot {joint} on subplot {i}")
        # Calculate sum of negative and positive values
        sum_neg = df[joint][df[joint] < 0].sum()
        sum_pos = df[joint][df[joint] > 0].sum()

  plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust for better layout with title
  plt.show()

  print(testnames[testno] + ": " + str(check_sign))

import pandas as pd

# Initialize dictionary to store average ranges for each joint
avg_joint_range = {testno: {joint: 0 for joint in nonredundant_degree_cols} for testno in range(len(testnames))}

for testno in range(len(testnames)):
    # Initialize sums and counts for each joint
    sum_of_ranges = {joint: 0 for joint in nonredundant_degree_cols}
    count = 0

    # Loop through each joint
    for joint in nonredundant_degree_cols:
        # Loop through each dataframe for 'Unaffected' condition
        for df in files_untrimmed[testno]['Unaffected']:
            max_val = df[joint].max()
            min_val = df[joint].min()
            range_val = max_val - min_val
            sum_of_ranges[joint] += range_val
            count += 1

    # Calculate average range for each joint
    for joint in nonredundant_degree_cols:
        avg_joint_range[testno][joint] = sum_of_ranges[joint] / count

# Print the average ranges
for testno in range(len(testnames)):
    print(f"Test {testno}:")
    for joint, avg_range in avg_joint_range[testno].items():
        print(f"  Joint {joint}: Avg Range = {avg_range:.2f}")

# Example usage
# Assuming you have lists of DataFrames in files_untrimmed for each test case and joint names in nonredundant_degree_cols

import pandas as pd

# Initialize dictionary to store average ranges for each joint
avg_joint_range = {testno: {joint: 0 for joint in nonredundant_degree_cols} for testno in range(len(testnames))}

for testno in range(len(testnames)):
    # Initialize sums and counts for each joint
    sum_of_ranges = {joint: 0 for joint in nonredundant_degree_cols}
    count = 0

    # Loop through each joint
    for joint in nonredundant_degree_cols:
        for df in files_untrimmed[testno]['Affected']:
            max_val = df[joint].max()
            min_val = df[joint].min()
            range_val = max_val - min_val
            sum_of_ranges[joint] += range_val
            count += 1

    # Calculate average range for each joint
    for joint in nonredundant_degree_cols:
        avg_joint_range[testno][joint] = sum_of_ranges[joint] / count if count != 0 else 0

# Print the average ranges
for testno in range(len(testnames)):
    print(f"Test {testno}:")
    for joint, avg_range in avg_joint_range[testno].items():
        print(f"  Joint {joint}: Avg Range = {avg_range:.2f}")

# Example usage
# Assuming you have lists of DataFrames in files_untrimmed for each test case and joint names in nonredundant_degree_cols

"""## Generalized File System Df Processing for Graphers"""

import re

def get_graphable_dfs(folderpath, isTendencyTest=True, verbose=False): # not scaled/interpolated/stretched, not trimmed
  #files[testno][Hand]
  """
  Inputs:
    folderpath: example, '/content/drive/My Drive/FMA_Hand_Data_Collection/AJ/'  or '/content/drive/My Drive/0_Experiment_UCLA/ID04_CDML_E20240815/'
    isTendencyTest: False for affected/unaffected initials (i.e. ID03R), True for rest (i.e. SM)
    normalizeBy: list of specific folder(s) to normalize by. Manually specify (i.e. ['ID03R_LeftHand_Unaffected'], ['080624_SY_Score2']).
       if None, automatically try to detect which subfolder to use based on isTendencyTest
  Output:
    a dictionary of all dfs in 'folderpath/<some_folder>/', w/ original scale and length, thumb-flipped and normalized by the
    specified or auto detected subfolder of folderpath.
    normalized by dividing each csv's joint from avg range for each degree joint, each dist to dist, ratio-to-ratio.
    output dictionary format:  normalized_dfs[csv_filename] = processed df of csv
  """
  subfolders = [f for f in os.listdir(folderpath) if os.path.isdir(os.path.join(folderpath, f)) and 'woh' not in f.lower().split('_') and 'without' not in f.lower()]

  if isTendencyTest: # output format is files[score][testno][hand] = [df1,df2,df3,...]
    files_untrimmed = {score_no: {testno: {'Left': [], 'Right': []} for testno in range(0,7)} for score_no in range(0,3)}
    files_trimmed = {score_no: {testno: {'Left': [], 'Right': []} for testno in range(0,7)} for score_no in range(0,3)}

    for subfolder in subfolders:
      match = re.search(r'score(\d+)', subfolder.lower())
      if not match:
        if verbose: print(f"score not found in {subfolder}")
        continue
      score_no = int(match.group(1))
      if verbose: print(f"score '{score_no}' in {subfolder}")
      for file in [file for file in os.listdir(os.path.join(folderpath,subfolder)) if file.endswith('.csv')]:
        df = pd.read_csv(os.path.join(folderpath,subfolder,file))
        basic_processing(df)
        df = interpolate_to_0_2(df)
        testno = get_testno(file)
        if 'left' in file.lower():
          if verbose: print(f"reading {os.path.join(subfolder,file)} into files[{score_no}][{testno}]['Left']")
          files_untrimmed[score_no][testno]['Left'].append(df)
        elif 'right' in file.lower():
          if verbose: print(f"reading {os.path.join(subfolder,file)} into files[{score_no}][{testno}]['Right']")
          files_untrimmed[score_no][testno]['Right'].append(df)
  else: # output format is files[testno][Hand] = [df1,df2,df3,...]
    files_untrimmed = {testno: {'Unaffected': [], 'Affected': []} for testno in range(0,7)}
    files_trimmed = {testno: {'Unaffected': [], 'Affected': []} for testno in range(0,7)}

    for subfolder in subfolders: # find the "hand" subfolder and go into it
      if 'hand' in subfolder.lower():
        folderpath = os.path.join(folderpath, subfolder)
        if verbose: print(f"path is now {folderpath}")
        break
    subfolders = [f for f in os.listdir(folderpath) if os.path.isdir(os.path.join(folderpath, f)) and 'woh' not in f.lower().split('_') and 'without' not in f.lower()]
    for subfolder in subfolders:
      if 'wh' in subfolder.lower().split('_'): # select hand sensor data only
        hand_type = 'Unaffected' if 'unaffect' in subfolder.lower() else 'Affected'
        for file in [file for file in os.listdir(os.path.join(folderpath,subfolder)) if file.endswith('.csv')]:
          df = pd.read_csv(os.path.join(folderpath,subfolder,file))
          basic_processing(df)
          df = interpolate_to_0_2(df)
          testno = get_testno(file)
          if verbose: print(f"reading {os.path.join(subfolder,file)} into files[{testno}][{hand_type}]")
          files_untrimmed[testno][hand_type].append(df)

  return files_trimmed, files_untrimmed

#
#_, files_untrimmed = get_graphable_dfs('/content/drive/My Drive/0_Experiment_UCLA/ID04_CDML_E20240815/', isTendencyTest=False, verbose=False) # not scaled/interpolated/stretched, not trimmed

def get_min_maxes(deg_min_max=[-100,100], ratio_min_max=[None, None], dist_min_max = [None, None]):
  for scoreno in range(0,3):
    # Iterate through testnames and filenames
    for testno in range(len(testnames)):
      list_of_dfs = files_untrimmed[scoreno][testno]['Left'] + files_untrimmed[scoreno][testno]['Right']
      for df in list_of_dfs:
        for col in ratio_cols:
          if ratio_min_max[0] is None or ratio_min_max[1] is None:
            ratio_min_max[0] = df[col].min()
            ratio_min_max[1] = df[col].max()
          else:
            ratio_min_max[0] = min(ratio_min_max[0], df[col].min())
            ratio_min_max[1] = max(ratio_min_max[1], df[col].max())
        for col in dist_cols:
            if dist_min_max[0] is None or dist_min_max[1] is None:
              dist_min_max[0] = df[col].min()
              dist_min_max[1] = df[col].max()
            else:
              dist_min_max[0] = min(dist_min_max[0], df[col].min())
              dist_min_max[1] = max(dist_min_max[1], df[col].max())

  print(f"deg_min_max: {deg_min_max}")
  print(f"ratio_min_max: {ratio_min_max}")
  print(f"dist_min_max: {dist_min_max}")

  return deg_min_max, ratio_min_max, dist_min_max

def graph_all_9x4(folder, initials, isTendencyTest, verbose=False): # i.e. folder='/content/drive/My Drive/FMA_Hand_Data_Collection/AJ/'
  ## Graphing Tendency Tests Scores together
  _, files_untrimmed = get_graphable_dfs(folder, isTendencyTest, verbose) # not scaled/interpolated/stretched, not trimmed
  deg_min_max, ratio_min_max, dist_min_max = get_min_maxes()

  for scoreno in range(2,-1,-1) if isTendencyTest else ['NA']:
    output_folder = f"{folder}/plots/Score{scoreno}/" if isTendencyTest else f"{folder}/plots/"
    selection_trimmed = files_untrimmed[scoreno] if isTendencyTest else files_untrimmed
    selection_untrimmed = files_untrimmed[scoreno] if isTendencyTest else files_untrimmed
    is_affected = False if isTendencyTest else folder.split('/')[-2].split('-')[1][-1]
    hands = ['Left', 'Right'] if isTendencyTest else ['Unaffected', 'Affected']
    print(is_affected)
    for testno in range(6,-1,-1):
      output_name = f"{initials} {testno+1}. {testnames[testno]} {hands[0]}"
      graph_files(selection_untrimmed, selection_untrimmed,is_affected, testno,hands[0],output_name, deg_min_max, ratio_min_max, dist_min_max, output_folder)
      output_name = f"{initials} {testno+1}. {testnames[testno]} {hands[1]}"
      graph_files(selection_untrimmed, selection_untrimmed,is_affected, testno,hands[1],output_name, deg_min_max, ratio_min_max, dist_min_max, output_folder)
      output_name = f"{initials} {testno+1}. {testnames[testno]} Both"
      graph_files(selection_untrimmed, selection_untrimmed,is_affected, testno,'both',output_name, deg_min_max, ratio_min_max, dist_min_max, output_folder)

graph_all_9x4('/content/drive/My Drive/0_Experiment_UCLA/ID04-CDML-E20240815/', 'ID04', False, False) # ~3m total runtime

graph_all_9x4('/content/drive/My Drive/FMA_Hand_Data_Collection/AJ/', 'AJ', True, False)

## Graphing Tendency Tests Scores together

folder = '/content/drive/My Drive/FMA_Hand_Data_Collection/AJ/' # takes 6m 44s for AJ score0-2
initials = 'AJ'
_, files_untrimmed = get_graphable_dfs(folder, isTendencyTest=True, verbose=False) # not scaled/interpolated/stretched, not trimmed

# Initialize max and min values
deg_min_max = [-100, 100]
ratio_min_max = [None, None]
dist_min_max = [None, None]


for scoreno in range(0,3):
  # Iterate through testnames and filenames
  for testno in range(len(testnames)):
    list_of_dfs = files_untrimmed[scoreno][testno]['Left'] + files_untrimmed[scoreno][testno]['Right']
    for df in list_of_dfs:
      for col in ratio_cols:
        if ratio_min_max[0] is None or ratio_min_max[1] is None:
          ratio_min_max[0] = df[col].min()
          ratio_min_max[1] = df[col].max()
        else:
          ratio_min_max[0] = min(ratio_min_max[0], df[col].min())
          ratio_min_max[1] = max(ratio_min_max[1], df[col].max())
      for col in dist_cols:
          if dist_min_max[0] is None or dist_min_max[1] is None:
            dist_min_max[0] = df[col].min()
            dist_min_max[1] = df[col].max()
          else:
            dist_min_max[0] = min(dist_min_max[0], df[col].min())
            dist_min_max[1] = max(dist_min_max[1], df[col].max())

print(f"deg_min_max: {deg_min_max}")
print(f"ratio_min_max: {ratio_min_max}")
print(f"dist_min_max: {dist_min_max}")

print(files_untrimmed[2].keys())

#def graph_all_scores(score2_files, score1_files, score0_files, score2_files_untrimmed, score1_files_untrimmed, score0_files_untrimmed,
#hand, output_name, deg_min_max, save_path=None, hide_plot=False):

output_folder = f"{folder}/plots/All_Scores/"
for testno in range(6,-1,-1):
  output_name = f"{initials} {testno+1}. {testnames[testno]} Left"
  graph_all_scores(files_untrimmed[2][testno],files_untrimmed[1][testno],files_untrimmed[0][testno],files_untrimmed[2][testno],files_untrimmed[1][testno],files_untrimmed[0][testno], 'Left',output_name, deg_min_max, output_folder)
  output_name = f"{initials} {testno+1}. {testnames[testno]} Right"
  graph_all_scores(files_untrimmed[2][testno],files_untrimmed[1][testno],files_untrimmed[0][testno],files_untrimmed[2][testno],files_untrimmed[1][testno],files_untrimmed[0][testno], 'Right',output_name, deg_min_max, output_folder)
  output_name = f"{initials} {testno+1}. {testnames[testno]} Both"
  graph_all_scores(files_untrimmed[2][testno],files_untrimmed[1][testno],files_untrimmed[0][testno],files_untrimmed[2][testno],files_untrimmed[1][testno],files_untrimmed[0][testno], 'both',output_name, deg_min_max, output_folder)

"""## Function - Unflipped"""

import re
import warnings
import pandas as pd

# Suppress only pandas PerformanceWarning
warnings.filterwarnings("ignore", category=pd.errors.PerformanceWarning)

def compute_normalized_cols_unflipped(folderpath, normalizeBy=None, verbose=False): # not scaled/interpolated/stretched, not trimmed
  """
  Inputs:
    folderpath: example, '/content/drive/My Drive/BionicsLab_Colab/080624_SY/'
    isTendencyTest: False for affected/unaffected initials (i.e. ID03R), True for rest (i.e. SM)
    normalizeBy: list of specific folder(s) to normalize by. Manually specify (i.e. ['ID03R_LeftHand_Unaffected'], ['080624_SY_Score2']).
       if None, automatically try to detect which subfolder to use based on isTendencyTest
  Output:
    a dictionary of all dfs in 'folderpath/<some_folder>/', w/ original scale and length, thumb-flipped and normalized by the
    specified or auto detected subfolder of folderpath.
    normalized by multiply by 100 then dividing each csv's joint from avg range for each degree joint, each dist to dist, ratio-to-ratio.
      so the normalized col's range is equivalent to the percentage of the average ideal range of that person
      for instance: before norm, a col's range=31.65. Average range for that col is 46. After norm, col's range=68.74  (68% of 46)
    output dictionary format:  normalized_dfs[csv_filename] = processed df of csv
  """
  # 0. read in ALL CSVS
  normalized_dfs = {} # will be normalized and outputed in the end
  subfolders = [f for f in os.listdir(folderpath) if os.path.isdir(os.path.join(folderpath, f)) and 'woh' not in f.lower().split('_') and 'without' not in f.lower()]
  if verbose: print(subfolders)
  wanted_cols = degree_cols + ratio_cols + dist_cols

  for f in subfolders:
    if verbose: print(f)
    # loops subfiles in f only if it ends in '.csv'
    for file in [file for file in os.listdir(os.path.join(folderpath,f)) if file.endswith('.csv')]:
      df = pd.read_csv(os.path.join(folderpath,f,file))
      #testno = get_testno(file)
      basic_processing(df)
      df = df.drop(columns=[col for col in df.columns if col not in wanted_cols])
      normalized_dfs[file] = df

  # 1. sets normalizeBy automatically if not specified (is None)
  if normalizeBy is None:
    normalizeBy = []
    for subfolder in subfolders:
      match = re.search(r'score(\d)', subfolder.lower())
      if 'unaffected' in subfolder.lower(): normalizeBy.append(subfolder)
      elif match and match.group(1) == '2': normalizeBy.append(subfolder)
  if verbose: print(f"normalizeBy: {normalizeBy}")

  # 2. compute avg rom from normalizeBy to divide all csv by.
  #avg_range[testno][col] = sum_ranges[testno][col] / count_ranges[testno]

  sum_ranges = {i: {col: 0 for col in wanted_cols} for i in range(7)}
  count_ranges = {i: 0 for i in range(7)} # count_ranges[testno] = int
  for normalize_folder in normalizeBy:
    normalize_folder = os.path.join(folderpath, normalize_folder)
    if verbose: print(normalize_folder)
    for file in [f for f in os.listdir(normalize_folder) if f.endswith('.csv')]:
      #print('\t'+file)
      #df, deg_df_untrimmed, final_trim_idxes, picked_col = process_file_combined(file_path, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)
      testno = get_testno(file)
      df = normalized_dfs[file] # retrieve from step 0    #pd.read_csv(os.path.join(folderpath,normalize_folder,file))
      #basic_processing(df)
      count_ranges[testno] += 1
      for col in wanted_cols:
        #print(f"sum_ranges[{testno}][{col}] += {(df[col].max() - df[col].min())}")
        sum_ranges[testno][col] += (df[col].max() - df[col].min())
  if verbose: print(f"sum_ranges: {sum_ranges}")
  if verbose: print(f"count_ranges: {count_ranges}")
  avg_ranges = {i: {col: 0 for col in wanted_cols} for i in range(7)}
  for testno in range(7):
    for col in wanted_cols:
      avg_ranges[testno][col] = sum_ranges[testno][col] / count_ranges[testno]
  if verbose: print(f"avg_range: {avg_ranges}")

  # 3. normalize each df by dividing all dfs by their corresponding test's col's avg range:
  # loops subfolders in folderpath but checks if it is a directory
  #i = 0
  for f in subfolders:
    if verbose: print(f)
    # loops subfiles in f only if it ends in '.csv'
    for file in [file for file in os.listdir(os.path.join(folderpath,f)) if file.endswith('.csv')]:
      #i+=1
      if verbose: print('\t"'+file+'"')
      df = normalized_dfs[file] #pd.read_csv(os.path.join(folderpath,f,file))
      testno = get_testno(file)
      #basic_processing(df)
      #df = df.drop(columns=[col for col in df.columns if col not in wanted_cols])
      for col in wanted_cols:
        #max,min,range of this csv
        df[col+"_original_max"] = df[col].max()
        df[col+"_original_min"] = df[col].min()
        df[col+"_original_range"] = df[col].max() - df[col].min()
        #avg range of unaffect
        df[col+"_avg_ideal_range"] = avg_ranges[testno][col]
        #normalized col
        df[col+'_norm'] = df[col] * 100 / avg_ranges[testno][col] if avg_ranges[testno][col] != 0 else 0
        if col in ratio_cols: df[col] = df[col] - df[col][0] + 1
        if verbose:
          print("\t"+col)
          print(f"\t\tBEFORE: {df[col].min()} to {df[col].max()}, range={df[col].max()-df[col].min()}")
          print(f"\t\tAVG range={avg_ranges[testno][col]}")
          print(f"\t\tAFTER: {df[col+'_norm'].min()} to {df[col+'_norm'].max()}, range={df[col+'_norm'].max()-df[col+'_norm'].min()}")
          print()

      # 4. then compute any additional columns using col
      thumb1_sum = df['Thumb01x'].abs() + df['Thumb01y'].abs() + df['Thumb01z'].abs()
      index1_sum = df['Index01x'].abs() + df['Index01y'].abs() + df['Index01z'].abs()
      index2_sum = df['Index02x'].abs() + df['Index02y'].abs() + df['Index02z'].abs()
      df['Thumb01_sum'] = thumb1_sum
      df['Index01_sum'] = index1_sum
      df['Index02_sum'] = index2_sum
      df['Index_sum'] = index1_sum + index2_sum
      df['Degree_sum'] = index1_sum + index2_sum + thumb1_sum

      # and normalized col
      thumb1_sum_norm = df['Thumb01x_norm'].abs() + df['Thumb01y_norm'].abs() + df['Thumb01z_norm'].abs()
      index1_sum_norm = df['Index01x_norm'].abs() + df['Index01y_norm'].abs() + df['Index01z_norm'].abs()
      index2_sum_norm = df['Index02x_norm'].abs() + df['Index02y_norm'].abs() + df['Index02z_norm'].abs()

      df['Thumb01_sum_norm'] = thumb1_sum_norm
      df['Index01_sum_norm'] = index1_sum_norm
      df['Index02_sum_norm'] = index2_sum_norm
      df['Index_sum_norm'] = index1_sum_norm + index2_sum_norm
      df['Degree_sum_norm'] = index1_sum_norm + index2_sum_norm + thumb1_sum_norm

      normalized_dfs[file] = df


  return normalized_dfs

normalized_dfs = compute_normalized_cols_unflipped('/content/drive/My Drive/BionicsLab_Colab/ID04_CDML_E20240815/', verbose=True)

allow_scroll()
# set display max columns as none
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 5)
for key in normalized_dfs.keys():
  print(f"{key}:")
  display((normalized_dfs[key]))

  # Create a DataFrame to display the min and max values (range) for each column
  min_max_df = pd.DataFrame({
      'range': normalized_dfs[key].max()-normalized_dfs[key].min(),
  }).T  # Transpose to have 'min' and 'max' as rows and columns as headers

  # Display the min-max DataFrame in the same format
  #display(min_max_df)

"""## Function - Flipped"""

import re
import warnings
import pandas as pd

# Suppress only pandas PerformanceWarning
warnings.filterwarnings("ignore", category=pd.errors.PerformanceWarning)

def compute_normalized_cols_flipped(folderpath, normalizeBy=None, verbose=False): # not scaled/interpolated/stretched, not trimmed
  """
  Inputs:
    folderpath: example, '/content/drive/My Drive/BionicsLab_Colab/080624_SY/'
    isTendencyTest: False for affected/unaffected initials (i.e. ID03R), True for rest (i.e. SM)
    normalizeBy: list of specific folder(s) to normalize by. Manually specify (i.e. 'ID03R_LeftHand_Unaffected', '080624_SY_Score0').
       if None, automatically try to detect which subfolder to use based on isTendencyTest
  Output:
    a dictionary of all dfs in 'folderpath/<some_folder>/', w/ original scale and length, thumb-flipped and normalized by the
    specified or auto detected subfolder of folderpath.
    normalized by dividing each csv's joint from avg range for each degree joint, each dist to dist, ratio-to-ratio.
    output dictionary format:  normalized_dfs[csv_filename] = processed df of csv
  """
  # 0. read in ALL CSVS
  normalized_dfs = {} # will be normalized and outputed in the end
  subfolders = [f for f in os.listdir(folderpath) if os.path.isdir(os.path.join(folderpath, f)) and 'woh' not in f.lower().split('_') and 'without' not in f.lower()]
  if verbose: print(subfolders)
  wanted_cols = degree_cols + ratio_cols + dist_cols

  for f in subfolders:
    if verbose: print(f)
    # loops subfiles in f only if it ends in '.csv'
    for file in [file for file in os.listdir(os.path.join(folderpath,f)) if file.endswith('.csv')]:
      _, df, final_trim_idxes, _ = process_file_combined(os.path.join(folderpath,f,file), 0.05, 0.05, 12)
      df = df.drop(columns=[col for col in df.columns if col not in wanted_cols])
      normalized_dfs[file] = df

  # 1. sets normalizeBy automatically if not specified (is None)
  if normalizeBy is None:
    normalizeBy = []
    for subfolder in subfolders:
      match = re.search(r'score(\d)', subfolder.lower())
      if 'unaffected' in subfolder.lower(): normalizeBy.append(subfolder)
      elif match and match.group(1) == '2': normalizeBy.append(subfolder)
  if verbose: print(f"normalizeBy: {normalizeBy}")

  # 2. compute avg rom from normalizeBy to divide all csv by.
  #avg_range[testno][col] = sum_ranges[testno][col] / count_ranges[testno]

  sum_ranges = {i: {col: 0 for col in wanted_cols} for i in range(7)}
  count_ranges = {i: 0 for i in range(7)} # count_ranges[testno] = int
  for normalize_folder in normalizeBy:
    normalize_folder = os.path.join(folderpath, normalize_folder)
    if verbose: print(normalize_folder)
    for file in [f for f in os.listdir(normalize_folder) if f.endswith('.csv')]:
      #print('\t'+file)
      #df, deg_df_untrimmed, final_trim_idxes, picked_col = process_file_combined(file_path, threshold_a=0.05, threshold_b=0.05, window_size=12, percent_range=0.05)
      testno = get_testno(file)
      df = normalized_dfs[file] # retrieve from step 0    #pd.read_csv(os.path.join(folderpath,normalize_folder,file))
      #basic_processing(df)
      count_ranges[testno] += 1
      for col in wanted_cols:
        #print(f"sum_ranges[{testno}][{col}] += {(df[col].max() - df[col].min())}")
        sum_ranges[testno][col] += (df[col].max() - df[col].min())
  if verbose: print(f"sum_ranges: {sum_ranges}")
  if verbose: print(f"count_ranges: {count_ranges}")
  avg_ranges = {i: {col: 0 for col in wanted_cols} for i in range(7)}
  for testno in range(7):
    for col in wanted_cols:
      avg_ranges[testno][col] = sum_ranges[testno][col] / count_ranges[testno]
  if verbose: print(f"avg_range: {avg_ranges}")

  # 3. normalize each df by dividing all dfs by their corresponding test's col's avg range:
  # loops subfolders in folderpath but checks if it is a directory
  #i = 0
  for f in subfolders:
    if verbose: print(f)
    # loops subfiles in f only if it ends in '.csv'
    for file in [file for file in os.listdir(os.path.join(folderpath,f)) if file.endswith('.csv')]:
      #i+=1
      if verbose: print('\t"'+file+'"')
      df = normalized_dfs[file] #pd.read_csv(os.path.join(folderpath,f,file))
      testno = get_testno(file)
      #basic_processing(df)
      #df = df.drop(columns=[col for col in df.columns if col not in wanted_cols])
      for col in wanted_cols:
        #max,min,range of this csv
        df[col+"_original_max"] = df[col].max()
        df[col+"_original_min"] = df[col].min()
        df[col+"_original_range"] = df[col].max() - df[col].min()
        #avg range of unaffect
        df[col+"_avg_ideal_range"] = avg_ranges[testno][col]
        #normalized col
        if verbose:
          print("\t"+col)
          print(f"\t\tBEFORE: {df[col].min()} to {df[col].max()}, range={df[col].max()-df[col].min()}")
          print(f"\t\tAVG range={avg_ranges[testno][col]}")
        df[col] = df[col] / avg_ranges[testno][col] if avg_ranges[testno][col] != 0 else 0
        if col in ratio_cols: df[col] = df[col] - df[col][0] + 1
        if verbose:
          print(f"\t\tAFTER: {df[col].min()} to {df[col].max()}, range={df[col].max()-df[col].min()}")
          #print()

      # 4. then compute any additional columns using normalized col
      thumb1_sum = df['Thumb01x'].sum() + df['Thumb01y'].sum() + df['Thumb01z'].sum()
      index1_sum = df['Index01x'].sum() + df['Index01y'].sum() + df['Index01z'].sum()
      index2_sum = df['Index02x'].sum() + df['Index02y'].sum() + df['Index02z'].sum()
      df[['Thumb01_sum', 'Index01_sum', 'Index02_sum', 'Index_sum', 'Degree_sum']] = thumb1_sum, index1_sum, index2_sum, index1_sum + index2_sum, index1_sum + index2_sum + thumb1_sum
      normalized_dfs[file] = df

  return normalized_dfs

normalized_dfs = compute_normalized_cols_flipped('/content/drive/My Drive/BionicsLab_Colab/ID04_CDML_E20240815/', verbose=True)

