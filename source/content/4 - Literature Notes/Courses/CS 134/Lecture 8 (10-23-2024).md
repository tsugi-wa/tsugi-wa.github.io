---
Slides: https://drive.google.com/file/d/1aYCf-azsK4b73yitnoY5pC2_GnOFrUGb/edit
Recording: https://www.youtube.com/watch?v=qpfmF4g24Oo&feature=youtu.be
---
https://youtu.be/qpfmF4g24Oo?si=NJk30Ar8mXGXkzTR&t=1546

- consistency models:
	- network (async/sync)
	- fault/failure (RPC)
	- ordering models (causal)
	- delivery models (crash, omission)
- **TOTAL ORDER DELIVERY**
	- if m1 delivered before m2 on ONE mode, same for ALL nodes
	- only a property of ONE run, 
	- not enough - need **DETERMINISM** (every run same)
		- here: only 1 replica R so guarantees total order, but two possibilities not deterministic
		- [[b89c8100f38c27da99b4abd331e3532f_MD5.jpeg|Open: Pasted image 20241122111438.png]]
	- 
![[b89c8100f38c27da99b4abd331e3532f_MD5.jpeg]]
- consistency violations among replicas
	- ==Eventual consistency==: one of weakest
		- "stale" data? device showing old msg as speed > consistency (more important), eventually see update (common in NoSQL, big data stores/sys, etc.)
		- i.e. ML reading slightly outdated weights to speed up training
	- ==Read your writes==: writes to R1, reads from R2 (either load balance or R1 crash)
		- client writes 5, gets ACK, reads a 4?!??
		- solution: R1 replicates new written value before ACKing to client (**sync. replication**)
	- ==FIFO consistency==: client deposits $50 to R1, gets ACK, R1
		- R2 gets in wrong order
		- [[948c62f0a4eabf003a5d6d8f02ed63ab_MD5.jpeg|Open: Pasted image 20241122112025.png]]
![[948c62f0a4eabf003a5d6d8f02ed63ab_MD5.jpeg]]
	- ==Causal consistency==: know deposit -->withdrawal (happens-before relation) but other replication doedsn't see this relation
		- soln: vector clocks, causal broadcast, see prev. lecture
		- [[6aa5ff5fabda8928728da5f1df7ee6bb_MD5.jpeg|Open: Pasted image 20241122112421.png]]
![[6aa5ff5fabda8928728da5f1df7ee6bb_MD5.jpeg]]
- [[aa3be14964dc07fdf7d886e7234c429b_MD5.jpeg|Open: Pasted image 20241122112531.png]]
![[aa3be14964dc07fdf7d886e7234c429b_MD5.jpeg]]
	- causal is usually good enough in practice
	- strong: \$\$\$\$, network I/O and time to ensure eplication + ACKs
	- ==**CAP theorem** (Consistency, Availability, and Partition Tolerance)==
		- distrib. system can only support two of the three desired properties
		- partition tolerance: system runs even if partitioned (aka each group of nodes cannot talk to the other)
	-  if partition failure: sacrifice either availiability (fast) or consistency (right), otherwise prioritize one or the other 
		- i.e. partition failure + availability: give stale answers
		- i.e. partition failure + consistency: smaller partition rejects all requests until back online
## GFS:
- prioritize bandwidth storing and accessing of massive data
- distributed across tons of low commodity old hard disk hardware
- expose simple API to users (abstracting away physical location to user)
- features
	- **performance** - throughput >> latency (i.e. mapreduce set and forget)
	- **scalability** - easily add/drop nodes automatically
	- **reliability** - more-or-less consistent data (looser consistency model)
	- **availability** - high uptime (NOT CAP's def. of always get response)
- hard disk -> tracks -> sectors -> blocks of data
	- want large files stored contiguous/sequential, why? faster:
		- seek time + # blocks read + time to transfer block < random access
	- small files imply random access, less well supported but is. 
- two modes of reading & writing
	- large stream read, large seq. appends (optimized)
	- small random read/writes (ignore)
- handle concurrent clients (atomic appends) less hard than replaces

architecture
- **master node**: coordinate access w/ multiple **chunkservers** hosting 3 copies of data chunk/blocks
- master creates file handle for new files
- master:
	- returns replica locations of chunk wrt nodes 
	- file names --> chunks
	- coordinates migration, replication (if node dies)
- master tells client which replica to write to
- master advantages
	- simplier engineering
	- full picture of entire state
	- use complex alg for locating chunks instead of consistent masters
	- no bottleneck, only handles metadata
1. client converts file's byte offset --> chunk index (given chunk size)
2. requests file+chunk index to master
3. master gives client chunk handle and its replica locations
4. client requests specific byte range within chunk to repliac
5. chunkservers give data to client
[[c014d48fbfcd60719f0e76d40ff5bd59_MD5.jpeg|Open: Pasted image 20241122124117.png]]
![[c014d48fbfcd60719f0e76d40ff5bd59_MD5.jpeg]]
- ==Read-ahead==: master anticipate client may need later chunks and give handler
- if master dies? 
	- when master back online, loses all metadata
	- sends msg to all chunk servers
	- chunk servers respond with full index of chunks (heartbeat msgs)
	- so each write updates master (as client tells master to write)
	- periodic snapshots (**edit logs**) too? in case of corruption (cheaper + infrequent changes)
- larger chunks: less requests, less metadata, set up less TCP connections to access the chunk for multiple operations
- mutation: append/reate/write/delete: 
	- client asks master "which replica now holds mutation lease?"
		- master creates one or tels client which one
	- "primary replica" - mutation lease authoritative ordering
	- [[3f6633f75962467fb2cdbdd5d10d621d_MD5.jpeg|Open: Pasted image 20241122125103.png]]
![[3f6633f75962467fb2cdbdd5d10d621d_MD5.jpeg]]
	1. client asks master
	2. master gives them primary and secondary chunkservers
	3. client sends data to write to all chunkservers
	4. chunkservers store data in BUFFERs and ACKs client saying received
	5. client says to "commit" and primary buffer orders the operations so all consistent
	6. primary forwards ordered operation to secondary and it commits
	7. secondary confirms to primary
	8. primary confirms to client
- atomic appends (i.e. group msg queues)
	- each client assigned byte offset in last chunk by primary replica to avoid conflicts
	- primary applies append on its copy and forwards append to secondary
	- secondary sends ack
	- primary sends ack
- relaxed "at-least-once" model tolerated, inconsistency fine with log msgs

## VS HDSF
- gfs's master node vs hdfs' namenode
-  slightly bigger chunksize of hdfs (hdfs is newer)
- datanodes = chunkservers also 3 replicas but in blocks not data chunks
- master knows exact physical location of data blocks in datanodes (hdfs) vs gfs master node doesn't
- secondary name node in hdfs snapshots op log + system state for higher availability
- HDFS has NO APPEND OPTION, instead delete/create (easier to implement)
	- used for big data more often than gfs
- separation of concerns in GFS (master stores metadata), replicas in charge of writes not client 
	- GFS heavy lifting of client
	- chunk size importance
	- concurrency writes 
	- hdfs longer if master fails, has to update exact physical location to master
- why hdfs and gfs different decision?
	- gfs: streaming data, powering live data, log files, not really batch processing
	- hdfs: lots blob data unstructured for long time, mainly to analyze/batch process later for big data tools (spark, pig)
		- not worried about concurrent writes, just one client dumps data and multiple simultaneously read
		- if two writers need to write: create two diff files, no concurrent writes

