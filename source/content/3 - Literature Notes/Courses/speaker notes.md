

### GARM Overview

- **Introduction**:  
    GARM (Global Alliance for Responsible Media) unites marketers, agencies, and platforms to reduce harmful content in digital media.
    
- **Purpose**:  
    Develop shared standards for defining harmful content to ensure safe and responsible advertising.
    
- **Key Frameworks**:
    
    - **Content Categories**: Identify and categorize harmful content (e.g., illegal drugs, tobacco, alcohol).
    - **Brand Safety Floor**: Content unsuitable for any advertising.
    - **Brand Suitability Framework**: Guides risk levels for sensitive content.
- **Focus Areas**:
    
    - Stop monetization of harmful content.
    - Ensure clarity and consistency across platforms.
    - Promote responsible marketing while supporting free and safe speech.
- **Impact**:  
    Helps advertisers, agencies, and platforms make informed, ethical decisions to create a safer online ecosystem.

### ### Speaker Notes:

- **Batch Sizes**: Impact training speed and stability—smaller sizes are precise, larger sizes are faster.
- **Epochs**: Define how thoroughly the model passes over, aka learns from the dataset—too few risks underfitting, too many risks overfitting.
- **Learning Rates**: Control the pace of learning—crucial for balancing speed and accuracy.
- **Weight Decays**: Prevent overfitting by discouraging overly complex models with penalties.