---
Slides: https://drive.google.com/file/d/1w3fBX7dyLy0eOzcEUvBNvnX1pUtx0kfT/view
Recording: https://www.youtube.com/watch?v=ueRwfeC_VRc
---
replication started at 55:57 

Recommend some papers
What is good list of papers? Canonical 
- 2024 - most important list
- Hackernews list older
- Consensus
- Industrial papers vs original maybe easier for you to understand, more practical

All Cloud service have some Data processing library (i.e. mapreduce ) 
- distributed replicated file system (GFS, HDFS/Hadoop, Azure’s, AWS) 
  - In all large companies ,  distrib. Replicated file sys, databases, storage, querying layers, cluster manager, job scheduler, etc.
  - Workflow essential to grasp
- Data processing
  - Batch processing
  - Stream processing (not on disk too fast)
  - Storage layer
  - Orchestration layer

Previously : reliable delivery ORDER (total order, causal, etc.)
- now we focus on if delivered at all
- Enforce properties how? Causal examples tedious (1. Hr vector clocks)
- Total order delivery - for future
- RELAIBLE delivery:
  - a liveness property: what needs guaranteeing
  - Crash failure: specific omission failure 
    - Process/node crashes forever, what to do? 
  - Omission failure: A —> B,  B never sends response to A
    - Either Ack from B to A lost
    - Or B never got it (can’t tell which)
    - Or B crashed/stops responding entirely
- not all ___ fail so we can lose transmission but not message and eventually deliver upon retries 9:40 if neither node crashes and not all msgs lost
- Keep retrying until get Ack —> then unbuffer the msg (like a commit)
  - What is the timeout period? We need to learn it eventually over time from experience? Realistically just fixed value
  - If timeout period too small: tons of msgs but minuscule difference as to outcome (if not receive email reply in 1 hr, unlikely in 2 hr etc)
  - Too long: very little progress lots of blocking less working 
- If Acks from B lost
  - Keep retrying - problem? Depends if idempotent
  - Considering two generals ex. “Attack at dawn” received twice no problem
  - Idempotent operation: “write x=2”. Vs not (increment x)
    - F(x)==f(f(f(f(f(…f(x)))))
    - I.e. abs value, x, sign(x) identity matrix, etc.
- Cannot assume reliable like in FIFO example
- Reliable = at-least-once delivery (so needs to be idempotent)
- At-most-once: only sends it once no matter what happens don’t retry
- Exactly once: unrealistic on real async system i.e. latent
  - Some however guarantees this: LIE marketing hopefully get away with it
  - Tradeoffs too or trackings in wording KAFKA (msg broker), BEAM
  - Actually: assume 2 things to guanrantee these
    - Msgs are idempotent (at-least-once)
    - Server de-duplicates messages (drop the rest), at most once
    - Combined: exactly once SIMULATION not exactly.          

## Reliable Broadcast 
Broadcast: to everyone. Including itself (ignore) 
- Causal broadcast to avoid order anomaly (use buffer to avoid showing out of order message first carol dumb bob example )
- ![[Pasted image 20241121143900.png]]
- ==If a correct process delivers m, then all correct processes delivered m.==
- Reliable delivery by what definition of "correct"? (i.e. "safety" by what threat model?): 
	- crash model = as long as no crash okay, not care message model. 
	- Omission model: cares about message model 
	- Byzantine model: corruption. Snooping etc man middle attacks  safety definition depends on threat model

Crash model—>reliable broadcast
"delivered" = all msgs broadcast not care about ACK
- if original sender of broadcast fails before sending to everyone, solution=B also broadcasts to everyone (all recipients broadcast again)
	- only considered "delivered" when m received by everyone in group
- If a broadcasts to b and c and c crashes at any time, a is “correct”, b is “correct”, c is not because it crashed
	- doesn't violate def. of reliable delivery bc A delivers m, both A and B are correct and received m. 
	- ![[Pasted image 20241121145045.png]]
- if a crashes before it can broadcast to C?
	- violates def. bc C is correct but couldn't deliver m because it never got m![[Pasted image 20241121145011.png]]
- what if b also crashed before sending to C?
	- doesn't violate because never fulfills if condition (no correct processes delievered m, only C correct and never got m)
	- ![[Pasted image 20241121145554.png]]
- what if b crashes AFTER sending to C?
	  - doesn't violate because C receives msg and sends to A,B,C (hence delivers msg)
  - if nobody crashes (esp A)
	  - ![[Pasted image 20241121150023.png]] (dash = redundant sends)
	  - lots of duplicates. "broadcast storm" crashes router
		  - each proc tracks which msg delivered & forwarded, if sees again drops & doesnt broadcast
	  - 
## Replication 
- pros: locality, load distribution, redundancy
- cons: cost/complexity, consistency, network IO (so often on same network)
- strongest type of consistency
- full transparency - client can't tell its replicated (data always consistent no bad copies)
- assuming crash model (node won't come back online)
- ==Primary-Backup replication== 1976
	- i.e. mongoDB, MySQL, PostgreSQL, Redis, HDFS, RabbitMQ, ZooKeeper, etcd, job schedulers, distrib. databases, etc.
	- pick primary node P and n backup nodes
	- when client writes on P:
		- broadcast to all replicas in parallel
		- each replica gets write committed and ACKs to primary
		- if all replicas ACK received, considered **committed** and **delivered** on primary
		- primary sends ACK to client
	- if replica fails (no ACK)
		- kicks replica forever (untrustworthy)
	- if primary fails
		- heartbeat between primary and replicas
		- no heartbeat (consensus) replicas detect and vote new leader
		- i.e. Raft leader election
			- most up-to-date replica wins vote (i.e. WAL=write-ahead log tracks all requests, their ids, and results, and replay when primary receives request)
			- request id = client token (hash timestamp etc.)
			- must store WAL on another node and replicated backup WAL node
		- if prioritize availability over correctness (client doesn't care if inconsistent/old data, just wants response)
			- then okay to omit WAL, CAP theorem

	- when client reads --> backups not used, primary only
	- if anything fails, client retries entire process
		- variations in alg: primary retries to replicas (as long as idempotent), accepts some % of replicas ACKS received, etc.)
	- pros/cons? 
		- **fault tolerance:** decent recovery
		- **data locality**: bad. no locality just 1 primary
		- **load balancing**: bad. primary does all requests
		- primary is bottleneck esp if bandwidth, cpu-intensive
- ==chain replication== 2004
	- less common, more niche/research, DynamoDB
	- no primary/replicas, now head (writes), tail (reads), middle
	- when client writes
		1. client writes to head (which receives all requests)
		2. head sends to next in chain (M1)
		3. M2->M3->....->T (tail)
		4. once tail receives, considered committed (all replicas received)
		5. T--ACK-->client 
	- when client reads
		- directly reads from tail, and tail responds with 3
	- pros/cons?
		 - **fault tolerance:** decent recovery
		- **data locality**: bad. no locality just 1 primary
		- **load balancing**: better, one node reads, one node writes
	- if node fails, like removal from linked list. 
		- ![[Pasted image 20241103123203.png]]
		- if head dies: ![[Pasted image 20241103123253.png]]
			- elect new head from middle nodes, M2
			- redirect M1 --> T   and redirect new head H* --> M1
			- ![[Pasted image 20241103123322.png]]
		- if tail dies: same idea, elect tail, i.e. M1
			- ![[Pasted image 20241103123504.png]]
			- ![[Pasted image 20241103123615.png]] 
		- if middle node dies, simply skip over the missing link
			- ![[Pasted image 20241103123708.png]]
- ==chain vs primary-backup==
	- both use 2 RTT 
	- if constant latency & all nodes same network:
		- L = one-way time from A-->B
		- Primary-Backup:  
			- writes = 4L:  L(client->P) + 2L(all parallel replicas + ACKs) + L (P--ACK-->client)
			- reads = 2L:  L(client->P) + L(P->client)
		- Chain:
			- writes = (N+2)L:  L(client->H) + NL(sequential chain) + L(T--ACK-->client) 
			- reads = 2L: L(client->T) + L(T->client)
			- the more nodes, the more latency, the more redundancy


https://youtu.be/qpfmF4g24Oo?si=HOqYlNJe8QhTJkKy&t=287
## CDNs 
- are example of replication
- caching: copies everywhere around world for quick access
	- first lvl replication for locality ![[Pasted image 20241103124616.png]]
- failover: if local node crash, CDN schedules backup takeover
	- ![[Pasted image 20241103124541.png]]
	- second lvl of replication just for backups
	- also used for load-balancing among edge servers
	- ![[Pasted image 20241103124710.png]]
	- re-routing (CS 118) to avoid congested areas
- **replication + sharding**
	- replication: exact copies (roughly)
	- sharding: diff data on diff nodes (\$\$\$\$)
		- spanish local publisher related vids - only replicate nodes within region
		- when out of region wants - latency at first, then cache on local server 
	- i.e. Facebook mostly USA friends in USA
		- cached for a while if look at europe guy outside usa
		- TTL cache? depends, look at logs yourself


## CloudFront AWS
- CDN solution for web content with **edge servers** (not entire network) in a 4-region network ![[Pasted image 20241121171123.png]]
- all edge servers connected to attractively fast AWS backbone network (instead of over internet)
- aws charges with data going out of it to storage egress/S3 when ppl view site, etc. 
	- limit amt of results being queried from aws to limit charges
- when user requests content
	1. cdn picks closest/fastest edge server
	2. if requested content already in this server, easily return 
	3. otherwise, CloudFront retrieves from specified origin (i.e. S3 bucket, HTTP/EC2 server)
		- HTTP only on first request, rest is cached on edge server? 
	- E edge servers, N users, E << N
- workflow
	1. origin server specified as definitive/authoratitve copy
	2. i.e. upload website on HTTP server 
	3. create configured cloudfront distrib.
	4. cloudfront creates ugly subdomain for those files' urls
	5. cloudfront sends edge server config info (not data itself, unlike other CDNs)
- cons
	- for static content (php script, change content by execution, dynamic content requests --> origin server (inefficient))
	- as well as PUT, POST, PATCH, DELETE, OPTIONS routed directly to origin server
- uses
	- mp4 (static)
	- live video (dynamic) cache small-time segments
	- accessible static website content (designed for this)
	- encryption/customization
	- private content (i.e. paywalls, designed for this)